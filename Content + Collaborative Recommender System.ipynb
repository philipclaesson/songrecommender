{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse as sps\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n",
    "#train_final.csv - the training set of interactions\n",
    "train_final = pd.read_csv('input/train_final.csv', delimiter = \"\\t\");\n",
    "\n",
    "#tracks_final.csv - supplementary information about the items\n",
    "tracks_final = pd.read_csv('input/tracks_final.csv', delimiter = \"\\t\");\n",
    "\n",
    "#playlists_final.csv - supplementary information about the users\n",
    "playlists_final = pd.read_csv('input/playlists_final.csv', delimiter = \"\\t\");\n",
    "\n",
    "#target_playlists.csv - the set of target playlists that will receive recommendations\n",
    "target_playlists = pd.read_csv('input/target_playlists.csv');\n",
    "\n",
    "#target_tracks.csv - the set of target items (tracks) to be recommended\n",
    "target_tracks = pd.read_csv('input/target_tracks.csv');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Algorithm still not as good as it should be. \n",
    "#\n",
    "#Bug hunting: \n",
    "#    - Bad content tags? Yes, alNone was a tag. Removed but still not improved. \n",
    "#    - Bad URM. The URM was only trained with 50% of data. Now fixed, improved a lot. \n",
    "#    - \n",
    "#    - \n",
    "#    - \n",
    "#    - \n",
    "#    - \n",
    "#    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_final now contains 945579 interactions. \n",
      "Tracks_final now contains 74542 tracks. \n"
     ]
    }
   ],
   "source": [
    "#This step is not needed yet, will make ratings worse! \n",
    "\n",
    "def get_relevant_tracks():\n",
    "    #Now we want to remove some redundant stuff. \n",
    "\n",
    "    #We will remove all songs which are not occurring more than 10 times in train_final\n",
    "    #Nevertheless, we still want to keep all tracks which are in the target tracks.  \n",
    "\n",
    "    popularity = train_final.groupby(by=\"track_id\").playlist_id.nunique().to_frame()\n",
    "\n",
    "    #remove index name\n",
    "    popularity.reset_index(level = 0, inplace = True)\n",
    "\n",
    "    #Rename the columns\n",
    "    popularity.columns = ['track_id','occurrences']\n",
    "\n",
    "    #Remove all targeted tracks - TESTED, working as expected\n",
    "    tracks_relevant = popularity[~popularity['track_id'].isin(target_tracks['track_id'])]\n",
    "\n",
    "    #Remove tracks occurring less than 10 times\n",
    "    tracks_relevant = tracks_relevant[tracks_relevant['occurrences'] > 4]\n",
    "\n",
    "    #Add the targeteted tracks back again\n",
    "    tracks_relevant = pd.concat([tracks_relevant, target_tracks])\n",
    "\n",
    "    return(tracks_relevant)\n",
    "\n",
    "    print(\"Removed %s redundant tracks which occured less than 10 times.\" %(tracks_final-tracks_relevant))\n",
    "\n",
    "tracks_relevant = get_relevant_tracks()\n",
    "\n",
    "#Remove irrelevant tracks from train_final and tracks_final\n",
    "train_final = train_final[train_final['track_id'].isin(tracks_relevant['track_id'])]\n",
    "\n",
    "print(\"Train_final now contains %s interactions. \" %(train_final.shape[0]))\n",
    "\n",
    "tracks_final = tracks_final[tracks_final['track_id'].isin(tracks_relevant['track_id'])]\n",
    "\n",
    "print(\"Tracks_final now contains %s tracks. \"%(tracks_final.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>duration</th>\n",
       "      <th>playcount</th>\n",
       "      <th>album</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2972914</td>\n",
       "      <td>144</td>\n",
       "      <td>224000</td>\n",
       "      <td>49.0</td>\n",
       "      <td>[7]</td>\n",
       "      <td>[54087, 1757, 1718, 116712, 189631]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2750239</td>\n",
       "      <td>246</td>\n",
       "      <td>157000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[8]</td>\n",
       "      <td>[189631, 3424, 177424, 46208, 205245]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1550729</td>\n",
       "      <td>144</td>\n",
       "      <td>217000</td>\n",
       "      <td>554.0</td>\n",
       "      <td>[9]</td>\n",
       "      <td>[54087, 109806, 46869, 183258, 54337]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2169950</td>\n",
       "      <td>144</td>\n",
       "      <td>207000</td>\n",
       "      <td>200.0</td>\n",
       "      <td>[9]</td>\n",
       "      <td>[54087, 70618, 207003, 109806, 116712]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2256817</td>\n",
       "      <td>144</td>\n",
       "      <td>218000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[9]</td>\n",
       "      <td>[54087, 109806, 189631, 49166, 116712]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   track_id  artist_id  duration  playcount album  \\\n",
       "0   2972914        144    224000       49.0   [7]   \n",
       "1   2750239        246    157000        1.0   [8]   \n",
       "2   1550729        144    217000      554.0   [9]   \n",
       "3   2169950        144    207000      200.0   [9]   \n",
       "5   2256817        144    218000        2.0   [9]   \n",
       "\n",
       "                                     tags  \n",
       "0     [54087, 1757, 1718, 116712, 189631]  \n",
       "1   [189631, 3424, 177424, 46208, 205245]  \n",
       "2   [54087, 109806, 46869, 183258, 54337]  \n",
       "3  [54087, 70618, 207003, 109806, 116712]  \n",
       "5  [54087, 109806, 189631, 49166, 116712]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now lets take a look at the tags.\n",
    "tracks_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Translating all content ids into indexes.\n",
    "\n",
    "#We need to create buckets for the playcount and duration. \n",
    "#Lets create buckets and a help function for the duration. \n",
    "\n",
    "n_duration_buckets = 3\n",
    "def duration_to_bucket(duration, alternative = 2):\n",
    "    if (alternative == 1):\n",
    "        n_duration_buckets = 8\n",
    "        if duration <= 0:\n",
    "            print(\"Null duration reached bucket function. \")\n",
    "            return None\n",
    "        elif duration < 90000: #not a song\n",
    "            return 1\n",
    "        elif duration < 140000: #short song\n",
    "            return 2\n",
    "        elif duration < 220000: #radio song\n",
    "            return 3\n",
    "        elif duration < 340000: #normal song\n",
    "            return 4\n",
    "        elif duration < 480000: #long song\n",
    "            return 5\n",
    "        elif duration < 720000: #really long\n",
    "            return 6\n",
    "        elif duration < 1200000: #super long\n",
    "            return 7\n",
    "        elif duration >= 1200000: #mixtape/compilation\n",
    "            return 8\n",
    "    elif(alternative == 2):\n",
    "        n_duration_buckets = 3\n",
    "        if duration <= 0:\n",
    "            print(\"Null duration reached bucket function. \")\n",
    "            return None\n",
    "        elif duration <= 150000: #very short\n",
    "            return 1\n",
    "        elif duration > 150000 and duration < 720000: #very long\n",
    "            return 2\n",
    "        elif duration >= 720000: #mixtape/compilation\n",
    "            return 3\n",
    "        else: \n",
    "            return 0\n",
    "        \n",
    "\n",
    "n_playcount_buckets = 7\n",
    "def playcount_to_bucket(playcount):\n",
    "    if playcount <= 0 or playcount is None:\n",
    "        print(\"Null playcount reached bucket function. \")\n",
    "        return None\n",
    "    elif playcount < 254: #0,4 percentile not popular\n",
    "        return 1\n",
    "    elif playcount < 881: #0,6 perc: known\n",
    "        return 2\n",
    "    elif playcount < 1560: #0,7 popular\n",
    "        return 3\n",
    "    elif playcount < 2808: #0,8 very popular\n",
    "        return 4\n",
    "    elif playcount < 5900: #0,9 hits\n",
    "        return 5\n",
    "    elif playcount < 10494: #0,95 super hits\n",
    "        return 6\n",
    "    elif playcount >= 10494: # mega hits\n",
    "        return 7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58358\n",
      "21661 albums. 27607 expected.\n",
      "13915 artists. 17537 expected.\n"
     ]
    }
   ],
   "source": [
    "tracks_final['tags'].head()\n",
    "\n",
    "content_to_index = {}\n",
    "content_to_id = {}\n",
    "content_counter = 0\n",
    "\n",
    "#Lets translate the tags to indexes.\n",
    "for row in tracks_final['tags']:\n",
    "    tags = row.strip('[ ]').split(', ')\n",
    "    for tag in tags:\n",
    "        if len(tag) > 0: \n",
    "            tag = \"t\"+tag\n",
    "            if not(tag in content_to_index):\n",
    "                content_to_index[tag] = content_counter\n",
    "                content_to_id[content_counter] = tag\n",
    "                content_counter += 1;\n",
    "                \n",
    "#Lets translate album into indexes\n",
    "albumcount = 0 # 27607\n",
    "for album in tracks_final['album']:\n",
    "    album = album.strip('[ ]')\n",
    "    if album != None and album != \"None\" and len(album) > 0: #None should not be considered content\n",
    "        album = \"al\"+album\n",
    "        if album == \"alNone\":\n",
    "            print(album)\n",
    "        if not(album in content_to_index):\n",
    "            content_to_index[album] = content_counter\n",
    "            content_to_id[content_counter] = album\n",
    "            content_counter += 1\n",
    "            albumcount += 1\n",
    "\n",
    "#Lets translate artist_id into indexes \n",
    "artistcount = 0 #17537\n",
    "for artist in tracks_final['artist_id']:\n",
    "    artist = str(artist)\n",
    "    if artist != None and artist != \"None\" and len(artist) > 0: #None should not be considered content\n",
    "        artist = \"ar\"+artist\n",
    "        if not(artist in content_to_index):\n",
    "            content_to_index[artist] = content_counter\n",
    "            content_to_id[content_counter] = artist\n",
    "            content_counter += 1\n",
    "            artistcount += 1\n",
    "        \n",
    "\"\"\"\n",
    "#Lets translate the duration buckets into indexes. \n",
    "for bucket in range(n_duration_buckets): \n",
    "    bucket = \"d\"+str(bucket+1)\n",
    "    content_to_index[bucket] = content_counter\n",
    "    content_to_id[content_counter] = bucket\n",
    "    print(\"added %s\" %(bucket))\n",
    "    content_counter += 1\n",
    "\n",
    "#Lets translate the playcount buckets into indexes. \n",
    "for playcount in range(n_playcount_buckets): \n",
    "    playcount = \"p\"+str(playcount+1)\n",
    "    content_to_index[playcount] = content_counter\n",
    "    content_to_id[content_counter] = playcount\n",
    "    \n",
    "    content_counter += 1\n",
    "\n",
    "\n",
    "## Alternative 2: Just one content type per continous variable. \n",
    "#Fun thing to try: can I add all duration/playcounts in one col, normalizing from 0-1? \n",
    "\n",
    "\n",
    "content_to_index[\"duration\"] = content_counter\n",
    "content_to_id[content_counter] = \"duration\"\n",
    "content_counter += 1\n",
    "\n",
    "content_to_index[\"playcount\"] = content_counter\n",
    "content_to_id[content_counter] = \"playcount\"\n",
    "content_counter += 1\n",
    "\"\"\"\n",
    "\n",
    "print(len(content_to_index))\n",
    "print(\"%s albums. 27607 expected.\" %albumcount)\n",
    "print(\"%s artists. 17537 expected.\" %artistcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 57561 playlists with 74542 unique tracks with 58358 unique content types. \n"
     ]
    }
   ],
   "source": [
    "#If we translate each track_id to a track_index which will serve as matrix index, we can save a lot of time. \n",
    "\n",
    "\n",
    "#We need a way to get from track_id to index in O(1).\n",
    "#Let's create a dictionary\n",
    "\n",
    "track_to_id = {}\n",
    "track_to_index = {}\n",
    "track_ids = tracks_final['track_id']\n",
    "\n",
    "counter = 0;\n",
    "for track_id in tracks_final['track_id']:\n",
    "    track_id = int(track_id)\n",
    "    track_to_index[track_id] = counter\n",
    "    track_to_id[counter] = track_id\n",
    "    counter += 1;\n",
    "    \n",
    "#and a way to get from playlist_id to index in O(1)\n",
    "\n",
    "\n",
    "playlist_to_index = {}\n",
    "playlist_to_id = {}\n",
    "counter = 0; \n",
    "for playlist_id in playlists_final['playlist_id']:\n",
    "    playlist_id = int(playlist_id)\n",
    "    playlist_to_index[playlist_id] = counter\n",
    "    playlist_to_id[counter] = playlist_id\n",
    "    counter += 1;\n",
    "    \n",
    "print(\"We have {} playlists with {} unique tracks with {} unique content types. \".format(len(playlist_to_index), len(track_to_index), len(content_to_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now we can create an Item Content Matrix. \n",
    "\n",
    "#ICM_all = np.zeros((len(tracks_indexes), len(tags_indexes)), int)\n",
    "#ICM_all = sps.coo_matrix((len(track_to_index), len(content_to_index)), int)\n",
    "#print(ICM_all.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>duration</th>\n",
       "      <th>playcount</th>\n",
       "      <th>album</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2972914</td>\n",
       "      <td>144</td>\n",
       "      <td>224000</td>\n",
       "      <td>49.0</td>\n",
       "      <td>[7]</td>\n",
       "      <td>[54087, 1757, 1718, 116712, 189631]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2750239</td>\n",
       "      <td>246</td>\n",
       "      <td>157000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[8]</td>\n",
       "      <td>[189631, 3424, 177424, 46208, 205245]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1550729</td>\n",
       "      <td>144</td>\n",
       "      <td>217000</td>\n",
       "      <td>554.0</td>\n",
       "      <td>[9]</td>\n",
       "      <td>[54087, 109806, 46869, 183258, 54337]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2169950</td>\n",
       "      <td>144</td>\n",
       "      <td>207000</td>\n",
       "      <td>200.0</td>\n",
       "      <td>[9]</td>\n",
       "      <td>[54087, 70618, 207003, 109806, 116712]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2256817</td>\n",
       "      <td>144</td>\n",
       "      <td>218000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[9]</td>\n",
       "      <td>[54087, 109806, 189631, 49166, 116712]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>474864</td>\n",
       "      <td>928</td>\n",
       "      <td>193000</td>\n",
       "      <td>73.0</td>\n",
       "      <td>[22]</td>\n",
       "      <td>[205245, 81223, 11056, 267, 3982]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1523190</td>\n",
       "      <td>928</td>\n",
       "      <td>206000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[22]</td>\n",
       "      <td>[205245, 11056, 81223, 4425, 189631]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1373492</td>\n",
       "      <td>928</td>\n",
       "      <td>237000</td>\n",
       "      <td>2896.0</td>\n",
       "      <td>[22]</td>\n",
       "      <td>[81223, 11056, 205245, 189631, 3982]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3387498</td>\n",
       "      <td>928</td>\n",
       "      <td>245000</td>\n",
       "      <td>9622.0</td>\n",
       "      <td>[31]</td>\n",
       "      <td>[81223, 189631, 205245, 4425, 50764]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>699524</td>\n",
       "      <td>928</td>\n",
       "      <td>294000</td>\n",
       "      <td>22.0</td>\n",
       "      <td>[26]</td>\n",
       "      <td>[11056, 205245, 81223, 4425, 189631]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    track_id  artist_id  duration  playcount album  \\\n",
       "0    2972914        144    224000       49.0   [7]   \n",
       "1    2750239        246    157000        1.0   [8]   \n",
       "2    1550729        144    217000      554.0   [9]   \n",
       "3    2169950        144    207000      200.0   [9]   \n",
       "5    2256817        144    218000        2.0   [9]   \n",
       "7     474864        928    193000       73.0  [22]   \n",
       "9    1523190        928    206000       10.0  [22]   \n",
       "10   1373492        928    237000     2896.0  [22]   \n",
       "11   3387498        928    245000     9622.0  [31]   \n",
       "12    699524        928    294000       22.0  [26]   \n",
       "\n",
       "                                      tags  \n",
       "0      [54087, 1757, 1718, 116712, 189631]  \n",
       "1    [189631, 3424, 177424, 46208, 205245]  \n",
       "2    [54087, 109806, 46869, 183258, 54337]  \n",
       "3   [54087, 70618, 207003, 109806, 116712]  \n",
       "5   [54087, 109806, 189631, 49166, 116712]  \n",
       "7        [205245, 81223, 11056, 267, 3982]  \n",
       "9     [205245, 11056, 81223, 4425, 189631]  \n",
       "10    [81223, 11056, 205245, 189631, 3982]  \n",
       "11    [81223, 189631, 205245, 4425, 50764]  \n",
       "12    [11056, 205245, 81223, 4425, 189631]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks_final[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track 0 of 74542. 0.0 s sec.\n",
      "Track 5000 of 74542. 0.11 s sec.\n",
      "Track 10000 of 74542. 0.22 s sec.\n",
      "Track 15000 of 74542. 0.33 s sec.\n",
      "Track 20000 of 74542. 0.45 s sec.\n",
      "Track 25000 of 74542. 0.56 s sec.\n",
      "Track 30000 of 74542. 0.68 s sec.\n",
      "Track 35000 of 74542. 0.8 s sec.\n",
      "Track 40000 of 74542. 0.91 s sec.\n",
      "Track 45000 of 74542. 1.03 s sec.\n",
      "Track 50000 of 74542. 1.17 s sec.\n",
      "Track 55000 of 74542. 1.29 s sec.\n",
      "Track 60000 of 74542. 1.4 s sec.\n",
      "Track 65000 of 74542. 1.52 s sec.\n",
      "Track 70000 of 74542. 1.63 s sec.\n",
      "Built ICM matrix with 492756 content values.\n",
      "21661 albums. 27607 expected.\n",
      "13915 artists. 17537 expected.\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#So let's fill the ICM with our data.\n",
    "import math\n",
    "\n",
    "def build_ICM():\n",
    "    \n",
    "    no_interactions = train_final.shape[0]\n",
    "    \n",
    "    tracks_matrix = tracks_final.as_matrix()\n",
    "    rows = np.zeros((no_interactions,), dtype = int)\n",
    "    cols = np.zeros((no_interactions,), dtype = int)\n",
    "    val = np.zeros((no_interactions,), dtype = int)\n",
    "    #val[i] = value of row[i] col[i]\n",
    "    #val = []\n",
    "    counter = 0\n",
    "    starttime = time.time()\n",
    "    lasttime = starttime\n",
    "    trackno = 0\n",
    "    addedalbums = {} #for testing\n",
    "    addedartists = {} # for testing\n",
    "    for track in tracks_matrix: \n",
    "        track_id, artist_id, duration, playcount, album, tags = np.split(track, 6)\n",
    "\n",
    "        #Get track index\n",
    "        track_index = track_to_index[int(track_id[0])]\n",
    "\n",
    "        \n",
    "        #add artist\n",
    "        \n",
    "        artist_index = content_to_index[\"ar\"+str(artist_id[0])]\n",
    "        addedartists[artist_index] = 1\n",
    "        \n",
    "        rows[counter] = track_index\n",
    "        cols[counter] = artist_index\n",
    "        val[counter] = 1\n",
    "        counter += 1\n",
    "\n",
    "        #add album\n",
    "        album = album[0].strip(\"[ ]\")\n",
    "\n",
    "        if album != None and len(album) > 0 and not album == \"None\":\n",
    "            album_index = content_to_index[\"al\"+album]\n",
    "            addedalbums[album_index] = 1 #testing\n",
    "            \n",
    "            rows[counter] = track_index\n",
    "            cols[counter] = album_index\n",
    "            val[counter] = 1\n",
    "            counter += 1\n",
    "\n",
    "        #add tags\n",
    "        tags = tags[0].strip('[ ]').split(', ')\n",
    "\n",
    "        for tag in tags: \n",
    "            if len(tag) > 0:\n",
    "                tag = \"t\"+tag\n",
    "                tag_index = content_to_index[tag]\n",
    "\n",
    "                rows[counter] = track_index\n",
    "                cols[counter] = tag_index\n",
    "                val[counter] = 1\n",
    "                \n",
    "                counter+=1\n",
    "        \"\"\"\n",
    "        ## ALT 1: Continuous variables in different content types. \n",
    "        \n",
    "        #add duration\n",
    "        duration = int(duration)\n",
    "        if duration > 0:\n",
    "            duration_bucket = duration_to_bucket(duration)\n",
    "            if duration_bucket > 0:   \n",
    "                duration_index = content_to_index[\"d\"+str(duration_bucket)]\n",
    "\n",
    "                rows[counter] = track_index\n",
    "                cols[counter] = duration_index\n",
    "\n",
    "                counter+=1\n",
    "        \n",
    "        #add playcount\n",
    "        if playcount is not None and playcount != \"None\" and not math.isnan(playcount):\n",
    "            playcount = int(playcount)\n",
    "            if playcount > 0: \n",
    "                playcount_bucket = playcount_to_bucket(playcount)\n",
    "                playcount_index = content_to_index[\"p\"+str(playcount_bucket)]\n",
    "\n",
    "                rows[counter] = track_index\n",
    "                cols[counter] = playcount_index\n",
    "                counter+=1\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        ## ALT 2: Continuous variables in one content type. \n",
    "        \n",
    "        #add duration\n",
    "        duration = int(duration)\n",
    "        if duration > 0:\n",
    "            duration_bucket = duration_to_bucket(duration)\n",
    "            duration_index = content_to_index[\"duration\"]\n",
    "\n",
    "            rows[counter] = track_index\n",
    "            cols[counter] = duration_index\n",
    "            val[counter] = duration_bucket/n_duration_buckets\n",
    "            \n",
    "            counter+=1\n",
    "\n",
    "        #add playcount\n",
    "        if playcount is not None and playcount != \"None\" and not math.isnan(playcount):\n",
    "            playcount = int(playcount)\n",
    "            if playcount > 0: \n",
    "                playcount_bucket = playcount_to_bucket(playcount)\n",
    "                playcount_index = content_to_index[\"playcount\"]\n",
    "\n",
    "                rows[counter] = track_index\n",
    "                cols[counter] = playcount_index\n",
    "                val[counter] = playcount_bucket/n_playcount_buckets\n",
    "\n",
    "                \n",
    "                counter+=1\n",
    "        \"\"\"\n",
    "        if trackno%5000 == 0:\n",
    "            print(\"Track %s of %s. %s s sec.\" %(trackno, tracks_matrix.shape[0], round(time.time()-starttime, 2)))  \n",
    "        trackno += 1\n",
    "\n",
    "    #Implicit ratings: all ratings are 1.             \n",
    "    \n",
    "    rows = rows[:counter]\n",
    "    cols = cols[:counter]\n",
    "    val = val[:counter]\n",
    "    #val = np.ones(rows.shape, dtype = int)\n",
    "\n",
    "    #Build ICM matrix. \n",
    "    ICM_all = sps.coo_matrix((val, (rows, cols)), dtype = int)\n",
    "    \n",
    "    print(\"Built ICM matrix with %s content values.\" %(val.shape[0]))\n",
    "    \n",
    "    print(\"%s albums. 27607 expected.\" %len(addedalbums))\n",
    "    print(\"%s artists. 17537 expected.\" %len(addedartists))\n",
    "    \n",
    "    return ICM_all\n",
    "\n",
    "\n",
    "#Build new ICM\n",
    "ICM_all = build_ICM()\n",
    "print(\"Done!\")\n",
    "\n",
    "\n",
    "\n",
    "#Get old ICM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/philipclaesson/anaconda3/lib/python3.6/site-packages/matplotlib/cbook.py:136: MatplotlibDeprecationWarning: The axisbg attribute was deprecated in version 2.0. Use facecolor instead.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n",
      "/Users/philipclaesson/anaconda3/lib/python3.6/site-packages/matplotlib/figure.py:403: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  \"matplotlib is currently using a non-GUI backend, \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAL8AAADuCAYAAABoONZUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsTQF/5Qmlqbgn9LE0hT8U5pY+v/uMp2WgrTOlgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a13bc78d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "def plot_coo_matrix(m):\n",
    "    if not isinstance(m, coo_matrix):\n",
    "        m = coo_matrix(m)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, axisbg='black')\n",
    "    ax.plot(m.col, m.row, 's', color='white', ms=1)\n",
    "    ax.set_xlim(0, m.shape[1])\n",
    "    ax.set_ylim(0, m.shape[0])\n",
    "    ax.set_aspect('equal')\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(False)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    return ax\n",
    "\n",
    "\n",
    "ax = plot_coo_matrix(ICM_all)\n",
    "ax.figure.show()\n",
    "\n",
    "#ax = plot_coo_matrix(d.URM_train)\n",
    "#ax.figure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ICM!\n"
     ]
    }
   ],
   "source": [
    "#Save the ICM\n",
    "\n",
    "sps.save_npz(\"Saved Matrixes/ICM_all_coo\", ICM_all)\n",
    "print(\"Saved ICM!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted\n"
     ]
    }
   ],
   "source": [
    "#Let's convert to csr. \n",
    "ICM_all = ICM_all.tocsr()\n",
    "print(\"Converted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1316175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3885714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3091270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>226759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   track_id\n",
       "0   1316175\n",
       "1   3885714\n",
       "2   3091270\n",
       "3    226759\n",
       "4    230596"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_tracks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_target_item_filter(indices):\n",
    "    target_filter = np.zeros((indices), dtype = bool)\n",
    "    for track in target_tracks.values:\n",
    "        track_id = track[0]\n",
    "        track_index = track_to_index[track_id]\n",
    "        target_filter[track_index] = True\n",
    "    print(\"Created filter preserving %s out of %s \" %(np.count_nonzero(target_filter),target_filter.shape[0]))\n",
    "    return target_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 4])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= np.array([1, 2, 3, 4])\n",
    "f = [True, False, True, True]\n",
    "a[f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t0.598770238311\n",
      "  (0, 1)\t0.0\n",
      "  (0, 2)\t0.885810777292\n",
      "  (1, 0)\t0.0\n",
      "  (1, 1)\t0.624662621931\n",
      "  (1, 2)\t0.911821380389\n",
      "  (2, 0)\t0.718729019772\n",
      "  (2, 1)\t0.839026527157\n",
      "  (2, 2)\t0.503687937963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/philipclaesson/anaconda3/lib/python3.6/site-packages/scipy/sparse/compressed.py:274: SparseEfficiencyWarning: Comparing a sparse matrix with a scalar greater than zero using <= is inefficient, try using > instead.\n",
      "  warn(bad_scalar_msg, SparseEfficiencyWarning)\n"
     ]
    }
   ],
   "source": [
    "a = sps.csr_matrix(np.random.rand(3,3))\n",
    "a[0.5 >= a] = 0\n",
    "\n",
    "#print(sps.csr_matrix(a.todense()))\n",
    "print(a)\n",
    "\n",
    "# Vi har en csr.\n",
    "\n",
    "# om vi loopar igenom den och plockar bort noise, sedan skapar ny matrix. \n",
    "\n",
    "\n",
    "#print(sps.csr_matrix(a.toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_URM(k = 5): \n",
    "    \n",
    "    playlistList = train_final['playlist_id'].values\n",
    "    itemList = train_final['track_id'].values\n",
    "    \n",
    "    #Translate ids\n",
    "    playlistList_translated = np.zeros(playlistList.shape)\n",
    "    itemList_translated = np.zeros(itemList.shape)\n",
    "    ratingList = np.ones((playlistList.shape), int)\n",
    "    for i in range(train_final.shape[0]):\n",
    "        playlistList_translated[i] = playlist_to_index[playlistList[i]]\n",
    "        itemList_translated[i] = track_to_index[itemList[i]]\n",
    "    \n",
    "    ## Build URM_full. \n",
    "    URM_full = sps.coo_matrix((ratingList, (playlistList_translated, itemList_translated)))\n",
    "    URM_full = URM_train.tocsr()\n",
    "    \n",
    "    ## Build URM_train & URM_test as zeros.\n",
    "    URM_train = URM_full.copy()\n",
    "    URM_test = sps.csr_matrix(np.zeros(URM_full.shape, dtype = int))\n",
    "\n",
    "    # If the data should be splitted. \n",
    "    if k> 0:\n",
    "        ## for each pl\n",
    "        for i, row in enumerate(URM_full): \n",
    "            ## get indexes of tracks\n",
    "            \n",
    "            ## randomly remove k tracks\n",
    "            indices = row.nonzero()[0]\n",
    "            for j in range(2): \n",
    "                removed_index = int(np.floor(np.random.rand()*indices.shape[0]))\n",
    "                removed_track = indices[removed_index]\n",
    "                indices = np.delete(indices,removed_index) #Deletes the int on index removed_index\n",
    "                \n",
    "                #Removes the track from the row\n",
    "                URM_train[i,removed_track] = 0\n",
    "                URM_test[i,removed_track] = 1\n",
    "                \n",
    "    else: \n",
    "        return URM_full, URM_test\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "row = np.array([1, 0, 1, 0,1,0,1,0])\n",
    "\n",
    "\n",
    "indices = row.nonzero()[0]\n",
    "for j in range(2): \n",
    "    removed_index = int(np.floor(np.random.rand()*indices.shape[0]))\n",
    "    removed_track = indices[removed_index]\n",
    "    indices = np.delete(indices,removed_index) #Deletes the int on index removed_index\n",
    "    row[removed_track] = 0\n",
    "\n",
    "print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7541312, 5550682]\n"
     ]
    }
   ],
   "source": [
    "# Get an owned_by_playlist_dictionary\n",
    "playlist_owned_by = {}\n",
    "for created_at, playlist_id, title, numtracks, duration, owner in playlists_final.as_matrix():\n",
    "    if owner not in playlist_owned_by:\n",
    "        playlist_owned_by[owner] = [playlist_id]\n",
    "    else:\n",
    "        playlist_owned_by[owner].append(playlist_id)\n",
    "        \n",
    "print(playlist_owned_by[40123])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: 756743. False: 188836. Tot: 945579\n",
      "Built URM_test\n",
      "Total datapoints: 945579. Expected: 945579\n",
      "(57560, 74542)\n",
      "(57560, 74542)\n"
     ]
    }
   ],
   "source": [
    "def build_URM(train_test_split = 0.80):\n",
    "    #Builds urm \n",
    "    \n",
    "    #train_test_split = 1\n",
    "    \n",
    "    numInteractions = train_final.shape[0]\n",
    "\n",
    "    train_mask = np.random.choice(a = [True,False], size = numInteractions, p = [train_test_split, 1-train_test_split])\n",
    "    \n",
    "    playlistList = train_final['playlist_id'].values\n",
    "    itemList = train_final['track_id'].values\n",
    "\n",
    "    #Translate ids\n",
    "    playlistList_translated = np.zeros(playlistList.shape)\n",
    "    itemList_translated = np.zeros(itemList.shape)\n",
    "    ratingList = np.ones((playlistList.shape), int)\n",
    "    \n",
    "    tru = train_mask[train_mask == True].shape[0]\n",
    "    fal = (train_mask[train_mask == False].shape[0])\n",
    "    \n",
    "    print(\"True: %s. False: %s. Tot: %s\" %(tru, fal, (tru+fal)))\n",
    "\n",
    "    \n",
    "    for i in range(train_final.shape[0]):\n",
    "        playlistList_translated[i] = playlist_to_index[playlistList[i]]\n",
    "        itemList_translated[i] = track_to_index[itemList[i]]\n",
    "    #print(\"Translated ids to indexes.\")\n",
    "    \n",
    "    \n",
    "    #Build URM matrix. \n",
    "    URM_train = sps.coo_matrix((ratingList[train_mask], (playlistList_translated[train_mask], itemList_translated[train_mask])))\n",
    "    URM_train = URM_train.tocsr()\n",
    "    #print(\"Built URM_train with shape %s,%s\" %(URM_train.shape[0],URM_train.shape[1]))\n",
    "    \n",
    "    if train_test_split < 1: \n",
    "        #Build URM_test\n",
    "        test_mask = np.logical_not(train_mask)\n",
    "        URM_test = sps.coo_matrix((ratingList[test_mask], (playlistList_translated[test_mask], itemList_translated[test_mask])))\n",
    "        URM_test = URM_test.tocsr()\n",
    "        print(\"Built URM_test\")\n",
    "        testsize = (test_mask[test_mask == True].shape[0])\n",
    "\n",
    "    else: \n",
    "        URM_test = sps.csc_matrix((10, 10), dtype=np.int8)\n",
    "        testsize = 0\n",
    "    \n",
    "    trainsize = train_mask[train_mask == True].shape[0]\n",
    "    totsize = trainsize + testsize\n",
    "    print(\"Total datapoints: %s. Expected: %s\" %(totsize,numInteractions))\n",
    "\n",
    "    \n",
    "    print(URM_train.shape)\n",
    "    print(URM_test.shape)\n",
    "    \n",
    "    return URM_train, URM_test\n",
    "\n",
    "URM_train, URM_test = build_URM(0.8)\n",
    "\n",
    "#Problem: The number of true/false values is not consistent.. Gives problems when testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/philipclaesson/anaconda3/lib/python3.6/site-packages/matplotlib/cbook.py:136: MatplotlibDeprecationWarning: The axisbg attribute was deprecated in version 2.0. Use facecolor instead.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n",
      "/Users/philipclaesson/anaconda3/lib/python3.6/site-packages/matplotlib/figure.py:403: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  \"matplotlib is currently using a non-GUI backend, \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAS4AAADuCAYAAACH3+pDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuIBw/gWt/8fiIOnG1wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a142ea438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plot_coo_matrix(URM_train)\n",
    "ax.figure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 1)\t1\n",
      "[[1 0]\n",
      " [0 0]\n",
      " [0 2]]\n"
     ]
    }
   ],
   "source": [
    "a = sps.coo_matrix(([1,1,1], ([0, 2, 2], [0, 1, 1])))\n",
    "print(a)\n",
    "print(a.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's take \"secondary\" ratings into account. \n",
    "#start_time = time.time()\n",
    "## For owner in owners\n",
    "#for count, owner in enumerate(playlist_owned_by):\n",
    "#    playlists = playlist_owned_by[owner]\n",
    "#    for i, playlist_id in enumerate(playlists):\n",
    "#        for j, playlist_id in enumerate(playlists): \n",
    "#            if i != j: \n",
    "#                URM_train[i, :] += 0.3 * URM_train[j, :]\n",
    "#    if count % 500 == 0 or count == 50:\n",
    "#        print(\"owned %s of %s. %s sec.\" %(count, len(playlist_owned_by), time.time()-start_time))\n",
    "#\n",
    "## playlist 1 = playlist 1 + 0.3 * playlist 2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URM_train contains 756743 interactions. Expected 1040422\n",
      "Train: 0.8056. Test: 0.1944\n"
     ]
    }
   ],
   "source": [
    "#Testing the URM builder.\n",
    "print(\"URM_train contains %s interactions. Expected 1040422\" %URM_train.nnz)\n",
    "testcount = 0\n",
    "traincount = 0\n",
    "itr = 10000\n",
    "for playlist_id, track_id in train_final[0:itr].values: \n",
    "    if (URM_train[playlist_to_index[playlist_id],track_to_index[track_id]]) > 0: \n",
    "        #print(\"Playlist %s with index %s and track %s with index %s was not in URM_train.\" %(playlist_id, playlist_to_index[playlist_id],track_id, track_to_index[track_id]))\n",
    "        traincount += 1\n",
    "    elif (URM_test[playlist_to_index[playlist_id],track_to_index[track_id]]) > 0:\n",
    "        testcount += 1\n",
    "        \n",
    "print(\"Train: %s. Test: %s\"%(traincount/itr, testcount/itr))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asd\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "class Recommender(object):\n",
    "    def __init__(self, URM, target_items, item_ids, k=50, shrinkage=100, similarity='cosine', filter_method = 'content', topK = 100):\n",
    "        self.dataset = URM\n",
    "        self.target_items = target_items\n",
    "        self.target_item_filter = get_target_item_filter(tracks_final.shape[0])\n",
    "        self.item_ids = item_ids\n",
    "        self.k = k\n",
    "        self.shrinkage = shrinkage\n",
    "        self.similarity_name = similarity\n",
    "        self.filter_method = filter_method\n",
    "        self.topK = topK\n",
    "        \n",
    "        self.UIM = None\n",
    "        \n",
    "        if similarity == 'cosine':\n",
    "            self.distance = Cosine(shrinkage=self.shrinkage)\n",
    "        elif similarity == 'pearson':\n",
    "            self.distance = Pearson(shrinkage=self.shrinkage)\n",
    "        elif similarity == 'adj-cosine':\n",
    "            self.distance = AdjustedCosine(shrinkage=self.shrinkage)\n",
    "        else:\n",
    "            raise NotImplementedError('Distance {} not implemented'.format(similarity))\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"Recommender(similarity={},k={},shrinkage={})\".format(self.similarity_name, self.k, self.shrinkage)\n",
    "\n",
    "    def fit_old(self, X, noise = 0.1):\n",
    "        ## GET ISM MATRIX (I X I)\n",
    "        cp = time.time()\n",
    "        #Calculate cosine similarity    \n",
    "        \n",
    "        ISM = self.distance.compute(X)\n",
    "        print(\"Computed content based similarity matrix. %s \" %(time.time()-cp))\n",
    "        cp = time.time()\n",
    "        \n",
    "        \n",
    "        ##GET URM (U X I)\n",
    "        \n",
    "        URM = self.dataset\n",
    "        \n",
    "        ## GET item_ids (1 x I)\n",
    "        \n",
    "        #self.item_ids\n",
    "        \n",
    "        ## FILTER item_ids INTO target_item_ids (1 x tI)\n",
    "        \n",
    "        self.target_item_ids = track_ids[self.target_item_filter]\n",
    "        print(URM.nnz)\n",
    "        print(ISM.nnz)\n",
    "        \n",
    "        ## FILTER TARGETED TRACKS\n",
    "        #Maybe this is not working as expected - are we filtering the right tracks? \n",
    "        \n",
    "        ISM = ISM[:,self.target_item_filter]\n",
    "        print(\"Filtered targeted tracks in ISM. %s \" %(time.time()-cp))\n",
    "        cp = time.time()\n",
    "        \n",
    "        #self.ISM = sps.csr_matrix(self.ISM)\n",
    "        \n",
    "        cp = time.time()  \n",
    "        print(URM.nnz)\n",
    "        #ISM = sps.csr_matrix(ISM)\n",
    "        print(ISM.nnz)\n",
    "        \n",
    "        ## CONVERT URM TO CSR\n",
    "        URM = check_matrix(URM, 'csr')\n",
    "        print(\"Checked URM csr %s \" %(time.time()-cp))\n",
    "        cp = time.time()\n",
    "        \n",
    "        ##Print dimension\n",
    "        print(URM.shape)\n",
    "        print(ISM.shape)\n",
    "        \n",
    "        ## MULTIPLY URM (U x I) * ISM (I x I)\n",
    "        UIM = URM.dot(ISM)\n",
    "        print(\"Computed URM * ISM %s \" %(time.time()-cp))\n",
    "        cp = time.time()\n",
    "        \n",
    "\n",
    "        \n",
    "        ## MAKE NOT SPARSE\n",
    "        #UIM_dense = UIM.todense()\n",
    "        \n",
    "        ## FILTER UIM into (U x tI) (not needed since I already filtered!)\n",
    "        #UIM_dense = UIM_dense[:,self.target_item_filter]\n",
    "        \n",
    "        ## THIS IS OUR FITTED MODEL\n",
    "        self.UIM = UIM\n",
    "        \n",
    "        return self.UIM\n",
    "  \n",
    "    def fit_new(self, X, noise = 0.1, CF_ratio = 0.5):\n",
    "        ## GET ISM MATRIX (I X I)\n",
    "        cp = time.time()\n",
    "        #Calculate cosine similarity\n",
    "        print(\"Using %s filtering with TopK = %s to compute distance.\" %(self.filter_method, self.topK))\n",
    "        \n",
    "        cosine_cython = Cosine_Similarity(URM_train, TopK=self.topK)\n",
    "        ISM_cf = cosine_cython.compute_similarity()\n",
    "        \n",
    "        print(\"Computed collaborative similarity matrix. %s \" %(time.time()-cp))\n",
    "        cp = time.time()\n",
    "        \n",
    "        ISM_cont = self.distance.compute(X)\n",
    "        print(\"Computed content based similarity matrix. %s \" %(time.time()-cp))\n",
    "        cp = time.time()\n",
    "        \n",
    "        w1 = CF_ratio\n",
    "        w2 = 1-CF_ratio\n",
    "        ISM = w1 * ISM_cf + w2 * ISM_cont\n",
    "        print(\"Combined similarity matrices with ratio %s. %s \" %(CF_ratio, time.time()-cp))\n",
    "        cp = time.time()\n",
    "        \n",
    "        ##GET URM (U X I)\n",
    "        \n",
    "        URM = self.dataset\n",
    "        \n",
    "        ## GET item_ids (1 x I)\n",
    "        \n",
    "        #self.item_ids\n",
    "        \n",
    "        ## FILTER item_ids INTO target_item_ids (1 x tI)\n",
    "        \n",
    "        self.target_item_ids = track_ids[self.target_item_filter]\n",
    "        print(URM.nnz)\n",
    "        print(ISM.nnz)\n",
    "        \n",
    "        ## FILTER TARGETED TRACKS\n",
    "        #Maybe this is not working as expected - are we filtering the right tracks? \n",
    "        \n",
    "        ISM = ISM[:,self.target_item_filter]\n",
    "        print(\"Filtered targeted tracks in ISM. %s \" %(time.time()-cp))\n",
    "        cp = time.time()\n",
    "        \n",
    "        #self.ISM = sps.csr_matrix(self.ISM)\n",
    "        \n",
    "        cp = time.time()  \n",
    "        print(URM.nnz)\n",
    "        #ISM = sps.csr_matrix(ISM)\n",
    "        print(ISM.nnz)\n",
    "        \n",
    "        ## CONVERT URM TO CSR\n",
    "        URM = check_matrix(URM, 'csr')\n",
    "        print(\"Checked URM csr %s \" %(time.time()-cp))\n",
    "        cp = time.time()\n",
    "        \n",
    "        ##Print dimension\n",
    "        print(URM.shape)\n",
    "        print(ISM.shape)\n",
    "        \n",
    "        ## MULTIPLY URM (U x I) * ISM (I x I)\n",
    "        UIM = URM.dot(ISM)\n",
    "        print(\"Computed URM * ISM %s \" %(time.time()-cp))\n",
    "        cp = time.time()\n",
    "        \n",
    "\n",
    "        \n",
    "        ## MAKE NOT SPARSE\n",
    "        #UIM_dense = UIM.todense()\n",
    "        \n",
    "        ## FILTER UIM into (U x tI) (not needed since I already filtered!)\n",
    "        #UIM_dense = UIM_dense[:,self.target_item_filter]\n",
    "        \n",
    "        ## THIS IS OUR FITTED MODEL\n",
    "        self.UIM = UIM\n",
    "        \n",
    "        return self.UIM\n",
    "\n",
    "        \n",
    "    def recommend_new(self, user_id, at = 5):\n",
    "        ## GET USER_INDEX\n",
    "        user_index = playlist_to_index[user_id]\n",
    "        \n",
    "        # Convert to np.array (why wasn't it before?!)\n",
    "        self.target_item_ids = np.array(self.target_item_ids)\n",
    "        \n",
    "        ## GET ROW CORRESPONDING TO USER (1 x tI)\n",
    "        user_weights = self.UIM[user_index,:].toarray()\n",
    "             \n",
    "        ## ARGSORT BASED ON AXIS = 0, GET [1,0:at]\n",
    "        top_indexes = np.argsort(user_weights)#[-at:]\n",
    "        top_k_indexes = top_indexes[0, -at:]\n",
    "\n",
    "        ## Translate to indexes\n",
    "        recommendations = self.target_item_ids[top_k_indexes]\n",
    "        \n",
    "        ## RETURN RECOMMENDATIONS\n",
    "        return(recommendations)\n",
    "    \n",
    "    def recommend_dev(self, user_id, at = 5):\n",
    "        print(\"Recommend %s items for user %s!\" %(at, user_id))\n",
    "        ## GET USER_INDEX\n",
    "        user_index = playlist_to_index[user_id]\n",
    "        \n",
    "        # Convert to np.array (why wasn't it before?!)\n",
    "        self.target_item_ids = np.array(self.target_item_ids)\n",
    "        \n",
    "        ## GET ROW CORRESPONDING TO USER (1 x tI)\n",
    "        user_weights = self.UIM[user_index,:].toarray()\n",
    "             \n",
    "        ## ARGSORT BASED ON AXIS = 0, GET [1,0:at]\n",
    "        top_indexes = np.argsort(user_weights)#[-at:]\n",
    "        print(top_indexes.shape)\n",
    "        top_k_indexes = top_indexes[0, -at:]\n",
    "        print(top_k_indexes.shape)\n",
    "\n",
    "        ## Translate to indexes\n",
    "        recommendations = self.target_item_ids[top_k_indexes]\n",
    "        \n",
    "        ## RETURN RECOMMENDATIONS\n",
    "        return(recommendations)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def recommend(self, user_id, at=None, exclude_seen=True):\n",
    "        # compute the scores using the dot product\n",
    "        user_profile = self.dataset[user_id]\n",
    "        print(\"User profile: %s\" %(user_profile))\n",
    "        scores = user_profile.dot(self.W_sparse).toarray().ravel()\n",
    "        print(\"Scores: %s\" %(scores))\n",
    "        # rank items\n",
    "        ranking = scores.argsort()[::-1]\n",
    "        if exclude_seen:\n",
    "            ranking = self._filter_seen(user_id, ranking)\n",
    "        \n",
    "        print(\"Ranking: %s\" %(ranking))\n",
    "        \n",
    "        export = [0,0,0,0,0]\n",
    "        for i in range(5):\n",
    "            t_id = track_to_id[ranking[i]]\n",
    "            export[i] = t_id\n",
    "            \n",
    "        return export\n",
    "    def _filter_seen(self, user_id, ranking):\n",
    "        user_profile = self.dataset[user_id]\n",
    "        seen = user_profile.indices\n",
    "        unseen_mask = np.in1d(ranking, seen, assume_unique=True, invert=True)\n",
    "        return ranking[unseen_mask]\n",
    "\n",
    "print(\"asd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 5 4]\n",
      "[4 6 7]\n"
     ]
    }
   ],
   "source": [
    "##TESTING\n",
    "\n",
    "\n",
    "user_weights = [1,2,4,3,7,6,1]\n",
    "target_item_ids = np.array([1,2,4,3,7,6,1])\n",
    "at = 3\n",
    "## ARGSORT BASED ON AXIS = 0, GET [1,0:at]\n",
    "top_indexes = np.argsort(user_weights)[-at:]\n",
    "print(top_indexes)\n",
    "## Translate to indexes\n",
    "recommendations = target_item_ids[top_indexes]\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created filter preserving 32195 out of 74542 \n",
      "(74542,)\n",
      "(74542,)\n"
     ]
    }
   ],
   "source": [
    "target_item_filter = get_target_item_filter(tracks_final.shape[0])\n",
    "print(target_item_filter.shape)\n",
    "print(track_ids.shape)\n",
    "target_item_ids = track_ids[target_item_filter]\n",
    "\n",
    "#print(target_item_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_matrix(X, format='csc', dtype=np.float32):\n",
    "    if format == 'csc' and not isinstance(X, sps.csc_matrix):\n",
    "        return X.tocsc().astype(dtype)\n",
    "    elif format == 'csr' and not isinstance(X, sps.csr_matrix):\n",
    "        return X.tocsr().astype(dtype)\n",
    "    elif format == 'coo' and not isinstance(X, sps.coo_matrix):\n",
    "        return X.tocoo().astype(dtype)\n",
    "    elif format == 'dok' and not isinstance(X, sps.dok_matrix):\n",
    "        return X.todok().astype(dtype)\n",
    "    elif format == 'bsr' and not isinstance(X, sps.bsr_matrix):\n",
    "        return X.tobsr().astype(dtype)\n",
    "    elif format == 'dia' and not isinstance(X, sps.dia_matrix):\n",
    "        return X.todia().astype(dtype)\n",
    "    elif format == 'lil' and not isinstance(X, sps.lil_matrix):\n",
    "        return X.tolil().astype(dtype)\n",
    "    else:\n",
    "        return X.astype(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class ISimilarity(object):\n",
    "    \"\"\"Abstract interface for the similarity metrics\"\"\"\n",
    "\n",
    "    def __init__(self, shrinkage=10):\n",
    "        self.shrinkage = shrinkage\n",
    "\n",
    "    def compute(self, X):\n",
    "        pass\n",
    "\n",
    "\n",
    "class Cosine(ISimilarity):\n",
    "    def compute(self, X):\n",
    "        # convert to csc matrix for faster column-wise operations\n",
    "        X = check_matrix(X, 'csc', dtype=np.float32)\n",
    "        print(\"Converted to csc.\")\n",
    "        # 1) normalize the columns in X\n",
    "        # compute the column-wise norm\n",
    "        # NOTE: this is slightly inefficient. We must copy X to compute the column norms.\n",
    "        # A faster solution is to  normalize the matrix inplace with a Cython function.\n",
    "        Xsq = X.copy()\n",
    "        Xsq.data **= 2\n",
    "        norm = np.sqrt(Xsq.sum(axis=0))\n",
    "        norm = np.asarray(norm).ravel()\n",
    "        norm += 1e-6\n",
    "        # compute the number of non-zeros in each column\n",
    "        # NOTE: this works only if X is instance of sparse.csc_matrix\n",
    "        col_nnz = np.diff(X.indptr)\n",
    "        # then normalize the values in each column\n",
    "        X.data /= np.repeat(norm, col_nnz)\n",
    "        print(\"Normalized\")\n",
    "\n",
    "        # 2) compute the cosine similarity using the dot-product\n",
    "        dist = X * X.T\n",
    "        print(\"Computed\")\n",
    "        \n",
    "        # zero out diagonal values\n",
    "        dist = dist - sps.dia_matrix((dist.diagonal()[scipy.newaxis, :], [0]), shape=dist.shape)\n",
    "        print(\"Removed diagonal\")\n",
    "        \n",
    "        # and apply the shrinkage\n",
    "        if self.shrinkage > 0:\n",
    "            dist = self.apply_shrinkage(X, dist)\n",
    "            print(\"Applied shrinkage\")    \n",
    "        \n",
    "        return dist\n",
    "\n",
    "    def apply_shrinkage(self, X, dist):\n",
    "        # create an \"indicator\" version of X (i.e. replace values in X with ones)\n",
    "        X_ind = X.copy()\n",
    "        X_ind.data = np.ones_like(X_ind.data)\n",
    "        # compute the co-rated counts\n",
    "        co_counts = X_ind * X_ind.T\n",
    "        # remove the diagonal\n",
    "        co_counts = co_counts - sps.dia_matrix((co_counts.diagonal()[scipy.newaxis, :], [0]), shape=co_counts.shape)\n",
    "        # compute the shrinkage factor as co_counts_ij / (co_counts_ij + shrinkage)\n",
    "        # then multiply dist with it\n",
    "        co_counts_shrink = co_counts.copy()\n",
    "        co_counts_shrink.data += self.shrinkage\n",
    "        co_counts.data /= co_counts_shrink.data\n",
    "        dist.data *= co_counts.data\n",
    "        return dist\n",
    "    \n",
    "    def remove_noise(self, X, noise):\n",
    "        X = check_matrix(X, 'csc', dtype=np.float32)\n",
    "        i = 0\n",
    "        for row in X:\n",
    "            r = row\n",
    "            row[row > noise] = 1\n",
    "            row[row <= noise] = 0\n",
    "\n",
    "            X[i,:] = r[row]\n",
    "            i += 1\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.33231863  0.14936473  0.57144247]]\n",
      "0.332318629903\n",
      "[[ 0.23395409  0.72268481  0.40700839]]\n",
      "0.407008387297\n",
      "[[ 0.95577023  0.28316002  0.59058255]]\n",
      "0.590582550065\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def kkeep_k_largest(X, k):\n",
    "    \n",
    "    M = X.todense()\n",
    "    for row in M: \n",
    "        top_k_idx = np.argsort(row)\n",
    "        print(row)\n",
    "        print(row[0,top_k_idx[0,-k]])\n",
    "        \n",
    "    \n",
    "    \n",
    "a = sps.csr_matrix(np.random.rand(3,3))\n",
    "print(kkeep_k_largest(a,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Creating a Item-Item Similarity Matrix based on Collaborative Filtering. \n",
    "class CF(object): \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def Item_Similarity(self, URM, k = 100, shrinkage = 10):\n",
    "        #Takes a URM (U x I), returns ISM (I x I)\n",
    "        \n",
    "        self.shrinkage = shrinkage\n",
    "        \n",
    "        # We explore the matrix column-wise\n",
    "        URM = check_matrix(URM, 'csc')\n",
    "\n",
    "        n_items = URM.shape[1]\n",
    "\n",
    "        values = []\n",
    "        rows = []\n",
    "        cols = []\n",
    "\n",
    "        start_time = time.time()\n",
    "        processedItems = 0\n",
    "\n",
    "        # Compute all similarities for each item using vectorization\n",
    "        for itemIndex in range(n_items):\n",
    "\n",
    "            processedItems += 1\n",
    "\n",
    "            if processedItems % 100==0:\n",
    "\n",
    "                itemPerSec = processedItems/(time.time()-start_time)\n",
    "\n",
    "                print(\"Similarity item {}, {:.2f} item/sec, required time {:.2f} min\".format(\n",
    "                    processedItems, itemPerSec, n_items/itemPerSec/60))\n",
    "\n",
    "            # All ratings for a given item\n",
    "            item_ratings = URM[:,itemIndex]\n",
    "            item_ratings = item_ratings.toarray().squeeze()\n",
    "            #print(item_ratings)\n",
    "\n",
    "            # Compute item similarities\n",
    "            this_item_weights = URM.T.dot(item_ratings)\n",
    "            \n",
    "            #print(this_item_weights)\n",
    "\n",
    "            # Sort indices and select TopK\n",
    "            top_k_idx = np.argsort(this_item_weights) [-k:]\n",
    "\n",
    "            # Incrementally build sparse matrix\n",
    "            #print(top_k_idx)\n",
    "            values.extend(this_item_weights[top_k_idx])\n",
    "            rows.extend(np.arange(URM.shape[1])[top_k_idx])\n",
    "            cols.extend(np.ones(k) * itemIndex)\n",
    "          \n",
    "            \n",
    "        W_sparse = sps.csc_matrix((values, (rows, cols)),\n",
    "                                shape=(n_items, n_items),\n",
    "                                dtype=np.float32)\n",
    "        \n",
    "        # zero out diagonal values\n",
    "        W_sparse = W_sparse - sps.dia_matrix((W_sparse.diagonal()[scipy.newaxis, :], [0]), shape=W_sparse.shape)\n",
    "        print(\"Removed diagonal\")\n",
    "        \n",
    "        W_sparse.data /= np.repeat(norm, col_nnz)\n",
    "        print(\"Normalized\")\n",
    "        \n",
    "        # and apply the shrinkage\n",
    "        if shrinkage > 0:\n",
    "            W_sparse = self.apply_shrinkage(URM, W_sparse)\n",
    "            print(\"Applied shrinkage\") \n",
    "\n",
    "        return W_sparse\n",
    "\n",
    "    def apply_shrinkage(self, X, dist):\n",
    "        # create an \"indicator\" version of X (i.e. replace values in X with ones)\n",
    "        X_ind = X.copy()\n",
    "        X_ind.data = np.ones_like(X_ind.data)\n",
    "        # compute the co-rated counts\n",
    "        co_counts = X_ind * X_ind.T\n",
    "        # remove the diagonal\n",
    "        co_counts = co_counts - sps.dia_matrix((co_counts.diagonal()[scipy.newaxis, :], [0]), shape=co_counts.shape)\n",
    "        # compute the shrinkage factor as co_counts_ij / (co_counts_ij + shrinkage)\n",
    "        # then multiply dist with it\n",
    "        co_counts_shrink = co_counts.copy()\n",
    "        co_counts_shrink.data += self.shrinkage\n",
    "        co_counts.data /= co_counts_shrink.data\n",
    "        dist.data *= co_counts.data\n",
    "        return dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 0 0 1]\n",
      " [0 0 1 0 1 1]\n",
      " [1 0 1 0 1 0]]\n",
      "Removed diagonal\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'norm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-11a0d91352a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mISM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mItem_Similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mURM_sparse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshrinkage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mISM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnnz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mISM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-44-d33ee41652a7>\u001b[0m in \u001b[0;36mItem_Similarity\u001b[0;34m(self, URM, k, shrinkage)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Removed diagonal\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mW_sparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_nnz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Normalized\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'norm' is not defined"
     ]
    }
   ],
   "source": [
    "URM = np.matrix([[1, 0, 1, 0, 0, 1], [0, 0, 1, 0, 1, 1], [1, 0, 1, 0, 1, 0]])\n",
    "print(URM)\n",
    "cf = CF()\n",
    "URM_sparse = sps.csc_matrix(URM, dtype = int)\n",
    "\n",
    "\n",
    "ISM = cf.Item_Similarity(URM_sparse, k = 4, shrinkage = 0)\n",
    "print(ISM.nnz)\n",
    "print(ISM.todense())\n",
    "print(ISM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cython extension is already loaded. To reload it, use:\n",
      "  %reload_ext Cython\n"
     ]
    }
   ],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "from cpython.array cimport array, clone\n",
    "\n",
    "import scipy.sparse as sps\n",
    "\n",
    "\n",
    "cdef class Cosine_Similarity:\n",
    "\n",
    "    cdef int TopK\n",
    "    cdef long n_items\n",
    "\n",
    "    # Arrays containing the sparse data\n",
    "    cdef int[:] user_to_item_row_ptr, user_to_item_cols\n",
    "    cdef int[:] item_to_user_rows, item_to_user_col_ptr\n",
    "    cdef double[:] user_to_item_data, item_to_user_data\n",
    "\n",
    "    # In case you select no TopK\n",
    "    cdef double[:,:] W_dense\n",
    "\n",
    "    \n",
    "    def __init__(self, URM, TopK = 100):\n",
    "        \"\"\"\n",
    "        Dataset must be a matrix with items as columns\n",
    "        :param dataset:\n",
    "        :param TopK:\n",
    "        \"\"\"\n",
    "\n",
    "        super(Cosine_Similarity, self).__init__()\n",
    "\n",
    "        self.n_items = URM.shape[1]\n",
    "\n",
    "        self.TopK = min(TopK, self.n_items)\n",
    "\n",
    "        URM = URM.tocsr()\n",
    "        self.user_to_item_row_ptr = URM.indptr\n",
    "        self.user_to_item_cols = URM.indices\n",
    "        self.user_to_item_data = np.array(URM.data, dtype=np.float64)\n",
    "\n",
    "        URM = URM.tocsc()\n",
    "        self.item_to_user_rows = URM.indices\n",
    "        self.item_to_user_col_ptr = URM.indptr\n",
    "        self.item_to_user_data = np.array(URM.data, dtype=np.float64)\n",
    "\n",
    "        if self.TopK == 0:\n",
    "            self.W_dense = np.zeros((self.n_items,self.n_items))\n",
    "\n",
    "\n",
    "\n",
    "    cdef int[:] getUsersThatRatedItem(self, long item_id):\n",
    "        return self.item_to_user_rows[self.item_to_user_col_ptr[item_id]:self.item_to_user_col_ptr[item_id+1]]\n",
    "\n",
    "    cdef int[:] getItemsRatedByUser(self, long user_id):\n",
    "        return self.user_to_item_cols[self.user_to_item_row_ptr[user_id]:self.user_to_item_row_ptr[user_id+1]]\n",
    "\n",
    "    \n",
    "    \n",
    "    cdef double[:] computeItemSimilarities(self, long item_id_input):\n",
    "        \"\"\"\n",
    "        For every item the cosine similarity against other items depends on whether they have users in common. \n",
    "        The more common users the higher the similarity.\n",
    "        \n",
    "        The basic implementation is:\n",
    "        - Select the first item\n",
    "        - Loop through all other items\n",
    "        -- Given the two items, get the users they have in common\n",
    "        -- Update the similarity considering all common users\n",
    "        \n",
    "        That is VERY slow due to the common user part, in which a long data structure is looped multiple times.\n",
    "        \n",
    "        A better way is to use the data structure in a different way skipping the search part, getting directly\n",
    "        the information we need.\n",
    "        \n",
    "        The implementation here used is:\n",
    "        - Select the first item\n",
    "        - Initialize a zero valued array for the similarities\n",
    "        - Get the users who rated the first item\n",
    "        - Loop through the users\n",
    "        -- Given a user, get the items he rated (second item)\n",
    "        -- Update the similarity of the items he rated\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        # Create template used to initialize an array with zeros\n",
    "        # Much faster than np.zeros(self.n_items)\n",
    "        cdef array[double] template_zero = array('d')\n",
    "        cdef array[double] result = clone(template_zero, self.n_items, zero=True)\n",
    "\n",
    "\n",
    "        cdef long user_index, user_id, item_index, item_id_second\n",
    "\n",
    "        cdef int[:] users_that_rated_item = self.getUsersThatRatedItem(item_id_input)\n",
    "        cdef int[:] items_rated_by_user\n",
    "\n",
    "        cdef double rating_item_input, rating_item_second\n",
    "\n",
    "        # Get users that rated the items\n",
    "        for user_index in range(len(users_that_rated_item)):\n",
    "\n",
    "            user_id = users_that_rated_item[user_index]\n",
    "            rating_item_input = self.item_to_user_data[self.item_to_user_col_ptr[item_id_input]+user_index]\n",
    "\n",
    "            # Get all items rated by that user\n",
    "            items_rated_by_user = self.getItemsRatedByUser(user_id)\n",
    "\n",
    "            for item_index in range(len(items_rated_by_user)):\n",
    "\n",
    "                item_id_second = items_rated_by_user[item_index]\n",
    "\n",
    "                # Do not compute the similarity on the diagonal\n",
    "                if item_id_second != item_id_input:\n",
    "                    # Increment similairty\n",
    "                    rating_item_second = self.user_to_item_data[self.user_to_item_row_ptr[user_id]+item_index]\n",
    "\n",
    "                    result[item_id_second] += rating_item_input*rating_item_second\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "    def compute_similarity(self):\n",
    "\n",
    "        cdef int itemIndex, innerItemIndex\n",
    "        cdef long long topKItemIndex\n",
    "\n",
    "        cdef long long[:] top_k_idx\n",
    "\n",
    "        # Declare numpy data type to use vetor indexing and simplify the topK selection code\n",
    "        cdef np.ndarray[long, ndim=1] top_k_partition, top_k_partition_sorting\n",
    "        cdef np.ndarray[np.float64_t, ndim=1] this_item_weights_np\n",
    "\n",
    "        #cdef long[:] top_k_idx\n",
    "        cdef double[:] this_item_weights\n",
    "\n",
    "        cdef long processedItems = 0\n",
    "\n",
    "        # Data structure to incrementally build sparse matrix\n",
    "        # Preinitialize max possible length\n",
    "        cdef double[:] values = np.zeros((self.n_items*self.TopK))\n",
    "        cdef int[:] rows = np.zeros((self.n_items*self.TopK,), dtype=np.int32)\n",
    "        cdef int[:] cols = np.zeros((self.n_items*self.TopK,), dtype=np.int32)\n",
    "        cdef long sparse_data_pointer = 0\n",
    "\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Compute all similarities for each item\n",
    "        for itemIndex in range(self.n_items):\n",
    "\n",
    "            processedItems += 1\n",
    "\n",
    "            if processedItems % 10000==0 or processedItems==self.n_items:\n",
    "\n",
    "                itemPerSec = processedItems/(time.time()-start_time)\n",
    "\n",
    "                print(\"Similarity item {} ( {:2.0f} % ), {:.2f} item/sec, required time {:.2f} min\".format(\n",
    "                    processedItems, processedItems*1.0/self.n_items*100, itemPerSec, (self.n_items-processedItems) / itemPerSec / 60))\n",
    "\n",
    "            this_item_weights = self.computeItemSimilarities(itemIndex)\n",
    "\n",
    "            if self.TopK == 0:\n",
    "\n",
    "                for innerItemIndex in range(self.n_items):\n",
    "                    self.W_dense[innerItemIndex,itemIndex] = this_item_weights[innerItemIndex]\n",
    "\n",
    "            else:\n",
    "\n",
    "                # Sort indices and select TopK\n",
    "                # Using numpy implies some overhead, unfortunately the plain C qsort function is even slower\n",
    "                # top_k_idx = np.argsort(this_item_weights) [-self.TopK:]\n",
    "\n",
    "                # Sorting is done in three steps. Faster then plain np.argsort for higher number of items\n",
    "                # because we avoid sorting elements we already know we don't care about\n",
    "                # - Partition the data to extract the set of TopK items, this set is unsorted\n",
    "                # - Sort only the TopK items, discarding the rest\n",
    "                # - Get the original item index\n",
    "\n",
    "                this_item_weights_np = - np.array(this_item_weights)\n",
    "                \n",
    "                # Get the unordered set of topK items\n",
    "                top_k_partition = np.argpartition(this_item_weights_np, self.TopK-1)[0:self.TopK]\n",
    "                # Sort only the elements in the partition\n",
    "                top_k_partition_sorting = np.argsort(this_item_weights_np[top_k_partition])\n",
    "                # Get original index\n",
    "                top_k_idx = top_k_partition[top_k_partition_sorting]\n",
    "\n",
    "\n",
    "\n",
    "                # Incrementally build sparse matrix\n",
    "                for innerItemIndex in range(len(top_k_idx)):\n",
    "\n",
    "                    topKItemIndex = top_k_idx[innerItemIndex]\n",
    "\n",
    "                    values[sparse_data_pointer] = this_item_weights[topKItemIndex]\n",
    "                    rows[sparse_data_pointer] = topKItemIndex\n",
    "                    cols[sparse_data_pointer] = itemIndex\n",
    "\n",
    "                    sparse_data_pointer += 1\n",
    "\n",
    "\n",
    "        if self.TopK == 0:\n",
    "\n",
    "            return np.array(self.W_dense)\n",
    "\n",
    "        else:\n",
    "\n",
    "            values = np.array(values[0:sparse_data_pointer])\n",
    "            rows = np.array(rows[0:sparse_data_pointer])\n",
    "            cols = np.array(cols[0:sparse_data_pointer])\n",
    "\n",
    "            W_sparse = sps.csr_matrix((values, (rows, cols)),\n",
    "                                    shape=(self.n_items, self.n_items),\n",
    "                                    dtype=np.float32)\n",
    "\n",
    "            return W_sparse\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 0 0 1]\n",
      " [0 0 1 0 1 1]\n",
      " [1 0 1 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "URM = np.matrix([[1, 0, 1, 0, 0, 1], [0, 0, 1, 0, 1, 1], [1, 0, 1, 0, 1, 0]])\n",
    "print(URM)\n",
    "cf = CF()\n",
    "URM_sparse = sps.csc_matrix(URM, dtype = int)\n",
    "\n",
    "\n",
    "#ISM = cf.Item_Similarity(URM_sparse, k = 4, shrinkage = 0)\n",
    "#print(ISM.nnz)\n",
    "#print(ISM.todense())\n",
    "#print(ISM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#URM_train, URM_test = build_URM(0.8)\n",
    "\n",
    "#cosine_cython = Cosine_Similarity(URM_train, TopK=50)\n",
    "\n",
    "#start_time = time.time()\n",
    "\n",
    "#ISM = cosine_cython.compute_similarity()\n",
    "\n",
    "#print(\"Similarity computed in {:.2f} seconds\".format(time.time()-start_time))\n",
    "#print(ISM.shape)\n",
    "#print(ISM.nnz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with train_rate 1\n",
      "True: 945579. False: 0. Tot: 945579\n",
      "Total datapoints: 945579. Expected: 945579\n",
      "(57560, 74542)\n",
      "(10, 10)\n",
      "Created filter preserving 32195 out of 74542 \n",
      "Loaded ICM!\n",
      "Converted to csc.\n",
      "Normalized\n",
      "Computed\n"
     ]
    }
   ],
   "source": [
    "### This is the main script ###\n",
    "\n",
    "\n",
    "#1. Fitting the model. \n",
    "\n",
    "#If export is true, the recommendations will be written to file. \n",
    "#If false, evaluation method can be used. \n",
    "\n",
    "## PARAMS\n",
    "\n",
    "export = True\n",
    "filter_method = 'content'\n",
    "topK = 100\n",
    "shrinkage=40.0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if export:\n",
    "    train_rate = 1\n",
    "else:\n",
    "    train_rate = 0.8\n",
    "    \n",
    "print(\"Running with train_rate %s\" %(train_rate))\n",
    "\n",
    "URM_train, URM_test = build_URM(train_rate)\n",
    "\n",
    "import time\n",
    "starttime = time.time()\n",
    "rec = Recommender(URM=URM_train, \n",
    "                  target_items = target_tracks, \n",
    "                  item_ids = track_ids, \n",
    "                  shrinkage = shrinkage, \n",
    "                  filter_method = filter_method,\n",
    "                  topK = topK)\n",
    "\n",
    "ICM_all = sps.load_npz(\"Saved Matrixes/ICM_perfect.npz\")\n",
    "print(\"Loaded ICM!\")\n",
    "\n",
    "#ax = plot_coo_matrix(ICM_all)\n",
    "#ax.figure.show()\n",
    "\n",
    "rec.fit_old(ICM_all)\n",
    "\n",
    "print(\"Model fitted in %s seconds\" %(time.time()-starttime))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 10000 playlists, 0.0030820369720458984 sec.\n",
      "1000 out of 10000 playlists, 2.35654616355896 sec.\n",
      "2000 out of 10000 playlists, 4.799052000045776 sec.\n",
      "3000 out of 10000 playlists, 7.241843938827515 sec.\n",
      "4000 out of 10000 playlists, 9.69197702407837 sec.\n",
      "5000 out of 10000 playlists, 12.148226022720337 sec.\n",
      "6000 out of 10000 playlists, 14.586225271224976 sec.\n",
      "7000 out of 10000 playlists, 17.026612043380737 sec.\n",
      "8000 out of 10000 playlists, 19.382423162460327 sec.\n",
      "9000 out of 10000 playlists, 21.738813161849976 sec.\n",
      "Saved to file \n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#2. Creating recommendations. \n",
    "zeros = np.zeros((target_playlists.size, 6), dtype = int)\n",
    "recommendations = pd.DataFrame(zeros)\n",
    "recommendations.columns = ['playlist_id', 1, 2, 3, 4, 5]\n",
    "\n",
    "counter = 0\n",
    "starttime = time.time()\n",
    "for playlist_id in target_playlists['playlist_id']:\n",
    "\n",
    "    if counter % 1000 == 0: \n",
    "        print (\"%s out of 10000 playlists, %s sec.\" %(counter, time.time()-starttime))\n",
    "\n",
    "    playlist_id_translated = playlist_to_index[int(playlist_id)]\n",
    "    recommendations.iloc[counter, 1:6] = rec.recommend_new(playlist_id, 5)\n",
    "    recommendations.iloc[counter, 0] = playlist_id\n",
    "    counter += 1\n",
    "\n",
    "if export:\n",
    "    filename = \"recommendations_6/11_\"\n",
    "    np.savetxt(\"output/rec_%s_k_%s_shrink_%s.csv\" %(filter_method, topK, shrinkage),recommendations, fmt = '%s,%s %s %s %s %s', header = \"playlist_id,track_ids\", newline = \"\\n\")\n",
    "    print(\"Saved to file \")\n",
    "\n",
    "#print(recommendations)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10)\n",
      "(57560, 74542)\n"
     ]
    }
   ],
   "source": [
    "# 3. Want to evaluate? \n",
    "print(URM_test.shape)\n",
    "print(URM_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 0 of 10000, 0 sec.\n",
      "[2079443 1764559  814732 1242583 1672852 3577226 2761193 2479330 3027673]\n",
      "1    3236144\n",
      "2    3705881\n",
      "3    1510434\n",
      "4    1174456\n",
      "5    3679249\n",
      "Name: 0, dtype: int64\n",
      "User 500 of 10000, 0 sec.\n",
      "[ 263574  128519 2956150  373698 3261645 1230481 3641917 3491239 1661373\n",
      " 3704012  901965 1730105 2841469   21156 2855232 3303573  463525 2636872\n",
      " 2329963  284358  697895 1073547 3748268  571588]\n",
      "1    3598647\n",
      "2     143307\n",
      "3    1420964\n",
      "4    3426348\n",
      "5    2942274\n",
      "Name: 500, dtype: int64\n",
      "User 1000 of 10000, 1 sec.\n",
      "[3566519]\n",
      "1    1800651\n",
      "2     557466\n",
      "3    3230543\n",
      "4    3219648\n",
      "5    2034790\n",
      "Name: 1000, dtype: int64\n",
      "User 1500 of 10000, 1 sec.\n",
      "[2756968]\n",
      "1    3251862\n",
      "2    2607833\n",
      "3     722457\n",
      "4     848569\n",
      "5     656735\n",
      "Name: 1500, dtype: int64\n",
      "User 2000 of 10000, 1 sec.\n",
      "[2729231 1577185]\n",
      "1     869098\n",
      "2     281021\n",
      "3     416339\n",
      "4    2871432\n",
      "5    2711020\n",
      "Name: 2000, dtype: int64\n",
      "User 2500 of 10000, 1 sec.\n",
      "[2074175 1117747]\n",
      "1    2974620\n",
      "2    1231659\n",
      "3    3518093\n",
      "4     416692\n",
      "5     522200\n",
      "Name: 2500, dtype: int64\n",
      "User 3000 of 10000, 2 sec.\n",
      "[1728512 3667166 3779619 1813538 1136360 1921901  687363]\n",
      "1    3452073\n",
      "2    1272404\n",
      "3     309933\n",
      "4     217009\n",
      "5    2923910\n",
      "Name: 3000, dtype: int64\n",
      "User 3500 of 10000, 2 sec.\n",
      "[2989722 1969782 2490194]\n",
      "1    1609693\n",
      "2     642667\n",
      "3    3194380\n",
      "4    2153004\n",
      "5    3875981\n",
      "Name: 3500, dtype: int64\n",
      "User 4000 of 10000, 2 sec.\n",
      "[ 283983 3063654 3057836 2664361 1212835 2575778 2215792 3101788 2163523\n",
      "  824067  265510 3745961  654048  639543 2715027 1990351 1589626 2063857\n",
      " 2041967]\n",
      "1     282620\n",
      "2    3293665\n",
      "3      64211\n",
      "4    1046541\n",
      "5    2621174\n",
      "Name: 4000, dtype: int64\n",
      "User 4500 of 10000, 2 sec.\n",
      "[]\n",
      "1      47331\n",
      "2    3689789\n",
      "3    2989670\n",
      "4     246102\n",
      "5    4474831\n",
      "Name: 4500, dtype: int64\n",
      "User 5000 of 10000, 3 sec.\n",
      "[ 331672 2535154 2391862  395518 2062051 2938083  416401 1895135 3005474\n",
      " 2690938  611370 3228453 2111361  467051 2273858 1561483 1941119 2303390]\n",
      "1      94083\n",
      "2    3288627\n",
      "3    3789763\n",
      "4     170846\n",
      "5    2802723\n",
      "Name: 5000, dtype: int64\n",
      "User 5500 of 10000, 3 sec.\n",
      "[1053247  792877 1290322 2394626 2166626 2259637]\n",
      "1    2652441\n",
      "2    1372484\n",
      "3    1515935\n",
      "4     221825\n",
      "5    1834839\n",
      "Name: 5500, dtype: int64\n",
      "User 6000 of 10000, 3 sec.\n",
      "[2785283 3324550 3349944]\n",
      "1    2346294\n",
      "2     157531\n",
      "3    3066710\n",
      "4    2712232\n",
      "5    3036158\n",
      "Name: 6000, dtype: int64\n",
      "User 6500 of 10000, 3 sec.\n",
      "[3869194 3642056 3661694 2229471 1756012]\n",
      "1    2779440\n",
      "2    1605486\n",
      "3    2089016\n",
      "4    1062077\n",
      "5     103960\n",
      "Name: 6500, dtype: int64\n",
      "User 7000 of 10000, 4 sec.\n",
      "[2337928    7217 1881423 1710448 2285149  177116  714256  911279 3413275]\n",
      "1    2586461\n",
      "2    1807375\n",
      "3     660853\n",
      "4    3210463\n",
      "5    2673648\n",
      "Name: 7000, dtype: int64\n",
      "User 7500 of 10000, 4 sec.\n",
      "[1604597 4557520 3345033 1758488  486659 1651080  219962  531685 3682516\n",
      " 3603100 3007719  622476 3168292 1321053 1188811 1201170  381811  852761\n",
      " 2190582 3522321   12758 3723214 2473083  846374  299780  383252 1691638\n",
      " 3358180  491074 3067010 2303166 2258414 3231943 1062375 1527919 1715211\n",
      " 1209415  672126 2293446 2673687]\n",
      "1    1527919\n",
      "2    1227320\n",
      "3    2419222\n",
      "4    1297735\n",
      "5    1702782\n",
      "Name: 7500, dtype: int64\n",
      "User 8000 of 10000, 4 sec.\n",
      "[3674375 4799513 2378119 3076552 2907515  159814 1624430]\n",
      "1    4690384\n",
      "2    1843142\n",
      "3     878761\n",
      "4    3166665\n",
      "5    2367577\n",
      "Name: 8000, dtype: int64\n",
      "User 8500 of 10000, 4 sec.\n",
      "[3164168 2146870 3382671 2204395 2692619]\n",
      "1    3629399\n",
      "2    2234183\n",
      "3     160211\n",
      "4    2008454\n",
      "5     830237\n",
      "Name: 8500, dtype: int64\n",
      "User 9000 of 10000, 5 sec.\n",
      "[3885267 1977253 3512227]\n",
      "1    2557632\n",
      "2    2488901\n",
      "3     287201\n",
      "4    3272533\n",
      "5      15117\n",
      "Name: 9000, dtype: int64\n",
      "User 9500 of 10000, 5 sec.\n",
      "[3025308]\n",
      "1    1751699\n",
      "2    2902912\n",
      "3     170791\n",
      "4     701922\n",
      "5    2809387\n",
      "Name: 9500, dtype: int64\n",
      "Recommender performance is: Precision = 0.0271, Recall = 0.0307, MAP = 0.0174\n"
     ]
    }
   ],
   "source": [
    "evaluate_algorithm(URM_test, recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 out of 50000 were in the target.\n"
     ]
    }
   ],
   "source": [
    "# Does the recommender rec just targeted tracks? \n",
    "def test_all_rec_in_target(recommendations):\n",
    "    tt = target_tracks.values\n",
    "    recommendations = recommendations.as_matrix()\n",
    "    notcount = 0\n",
    "    count = 0\n",
    "    for row in recommendations: \n",
    "        for item in row[1:6]: \n",
    "            count += 1\n",
    "            if item in tt: \n",
    "                notcount += 1\n",
    "                #print(\"Rec not in target! %s\" %item)\n",
    "    print(\"%s out of %s were in the target.\" %(notcount, count))\n",
    "    \n",
    "test_all_rec_in_target(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TESTING THE REC FUNCTION - SHOULD WORK\n",
    "#Fitted in 172.8 seconds\n",
    "\n",
    "rec_dev = Recommender(URM=URM_train, target_items = target_tracks, item_ids = track_ids, shrinkage=0.0)\n",
    "rec_dev.UIM = rec.UIM\n",
    "rec_dev.target_item_ids = rec.target_item_ids\n",
    "\n",
    "zeros = np.zeros((1, 6), dtype = int)\n",
    "recommendations = pd.DataFrame(zeros)\n",
    "recommendations.columns = ['playlist_id', 1, 2, 3, 4, 5]\n",
    "recommendations.iloc[counter, 1:6] = rec_dev.recommend_dev(playlist_to_id[30680], 5)\n",
    "recommendations.iloc[counter, 0] = playlist_to_id[30680]\n",
    "\n",
    "print(recommendations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "starttime = time.time()\n",
    "rec = Recommender(URM=URM_train, shrinkage=0.0)\n",
    "rec.fit(ICM_all)\n",
    "print(\"Done in %s seconds\" %(time.time()-starttime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ICM_add_IDF(ICM): \n",
    "    num_tot_items = ICM_all.shape[0]\n",
    "\n",
    "    # let's count how many items have a certain feature\n",
    "    items_per_feature = (ICM_all > 0).sum(axis=0)\n",
    "\n",
    "    IDF = np.array(np.log(num_tot_items / items_per_feature))[0]\n",
    "\n",
    "    print(ICM_all.shape)\n",
    "    print(IDF.shape)\n",
    "    ICM_idf = sps.csr_matrix(ICM_all, dtype=np.float64)\n",
    "    # compute the number of non-zeros in each col\n",
    "    # NOTE: this works only if X is instance of sparse.csc_matrix\n",
    "    col_nnz = np.diff(check_matrix(ICM_idf, 'csc').indptr)\n",
    "    print(col_nnz.shape)\n",
    "    print(ICM_idf.shape)\n",
    "    print(IDF.shape)\n",
    "    # then normalize the values in each col\n",
    "    ICM_idf.data *= np.repeat(IDF, col_nnz)\n",
    "    return ICM_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rec_idf = BasicItemKNNRecommender(URM=URM_train, shrinkage=0.0, k=50)\n",
    "rec_idf.fit(ICM_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluate_algorithm(URM_test, rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_to_file():\n",
    "    #Saves the recommendations dataframe to the .csv-file. \n",
    "    np.savetxt(\"output/recommendations_more_content.csv\",recommendations, fmt = '%s,%s %s %s %s %s', header = \"playlist_id,track_ids\", newline = \"\\n\")\n",
    "    \n",
    "    \n",
    "def test():\n",
    "    #Do something\n",
    "    print(\"Result: \")\n",
    "    pass\n",
    "\n",
    "\n",
    "save_to_file()\n",
    "print(recommendations.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
