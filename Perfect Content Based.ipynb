{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libs imported.\n"
     ]
    }
   ],
   "source": [
    "# Do all relevant imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse as sps\n",
    "import time\n",
    "%matplotlib inline\n",
    "print(\"Libs imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "def plot_coo_matrix(m):\n",
    "    if not isinstance(m, sps.coo_matrix):\n",
    "        m = sps.coo_matrix(m)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, facecolor='green')\n",
    "    ax.plot(m.col, m.row, 's', color='black', ms=0.004)\n",
    "    ax.set_xlim(0, m.shape[1])\n",
    "    ax.set_ylim(0, m.shape[0])\n",
    "    ax.set_aspect('equal')\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(False)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    return ax\n",
    "\n",
    "def check_matrix(X, format='csc', dtype=np.float32):\n",
    "    if format == 'csc' and not isinstance(X, sps.csc_matrix):\n",
    "        return X.tocsc().astype(dtype)\n",
    "    elif format == 'csr' and not isinstance(X, sps.csr_matrix):\n",
    "        return X.tocsr().astype(dtype)\n",
    "    elif format == 'coo' and not isinstance(X, sps.coo_matrix):\n",
    "        return X.tocoo().astype(dtype)\n",
    "    elif format == 'dok' and not isinstance(X, sps.dok_matrix):\n",
    "        return X.todok().astype(dtype)\n",
    "    elif format == 'bsr' and not isinstance(X, sps.bsr_matrix):\n",
    "        return X.tobsr().astype(dtype)\n",
    "    elif format == 'dia' and not isinstance(X, sps.dia_matrix):\n",
    "        return X.todia().astype(dtype)\n",
    "    elif format == 'lil' and not isinstance(X, sps.lil_matrix):\n",
    "        return X.tolil().astype(dtype)\n",
    "    else:\n",
    "        return X.astype(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Translator(object):\n",
    "    def __init__(self, tracks_final = [], playlists_final = []): \n",
    "        self.track_to_id = {}\n",
    "        self.track_to_idx = {}\n",
    "        self.content_to_id = {}\n",
    "        self.content_to_idx = {}\n",
    "        self.playlist_to_id = {}\n",
    "        self.playlist_to_idx = {}     \n",
    "        \n",
    "    def rand_index(self, high):\n",
    "        idx = np.random.rand() * high\n",
    "        while idx in self.content_to_id: \n",
    "            idx += 1\n",
    "            if (idx == high): \n",
    "                idx = 0\n",
    "        return idx\n",
    "        \n",
    "    def create_content_translations(self, tracks_final):\n",
    "        c_count = 0\n",
    "        c_idxcount = 0\n",
    "        \n",
    "        t_count = 0\n",
    "        t_idxcount = 0\n",
    "        for track_id, artist_id, duration, playcount, album_id, tags in tracks_final.values:\n",
    "\n",
    "            if (track_id > 0): \n",
    "                if track_id not in self.track_to_idx:\n",
    "                    self.track_to_idx[track_id] = t_idxcount\n",
    "                    self.track_to_id[t_idxcount] = track_id\n",
    "                    t_idxcount += 1\n",
    "            t_count += 1\n",
    "            \n",
    "            \n",
    "            \n",
    "            if (artist_id > 0): \n",
    "                artist = 'ar'+str(artist_id)\n",
    "                if artist not in self.content_to_idx: \n",
    "                    idx = self.rand_index(77042)\n",
    "                    self.content_to_idx[artist] = idx\n",
    "                    self.content_to_id[idx] = artist\n",
    "                    c_idxcount += 1\n",
    "            c_count += 1\n",
    "\n",
    "                    \n",
    "                    \n",
    "            album_id.strip('[ ]')\n",
    "            if (len(album_id) > 0 and album_id is not None and album_id != 'None'): \n",
    "                album = 'al'+str(album_id)\n",
    "                if album not in self.content_to_idx: \n",
    "                    idx = self.rand_index(77042)\n",
    "                    self.content_to_idx[album] = idx\n",
    "                    self.content_to_id[idx] = album\n",
    "                    c_idxcount += 1\n",
    "            c_count += 1\n",
    "            \n",
    "            tags = tags.strip('[ ]').split(', ')\n",
    "            for tag in tags:\n",
    "                if (len(tag) > 0 and tag is not None and tag != 'None'): \n",
    "                    tag = 'ta'+str(tag)\n",
    "                    if tag not in self.content_to_idx: \n",
    "                        idx = self.rand_index(77042)\n",
    "                        self.content_to_idx[tag] = idx\n",
    "                        self.content_to_id[idx] = tag\n",
    "                        c_idxcount += 1\n",
    "                c_count += 1\n",
    "        try:\n",
    "            #content_to_idx['alNone']\n",
    "            #content_to_idx['taNone']\n",
    "            #content_to_idx['arNone']\n",
    "            #content_to_idx['ar']\n",
    "            #content_to_idx['ta']\n",
    "            #content_to_idx['al']\n",
    "            pass\n",
    "            \n",
    "        except:\n",
    "            print(\"Test passed!\")\n",
    "\n",
    "            \n",
    "        print(\"Created %s indexes for %s tracks.\"%(len(self.track_to_idx), tracks_final.shape[0]))\n",
    "        print(\"Created %s indexes for %s contents.\"%(len(self.content_to_idx), c_count))\n",
    "        print(\"Total content size: %s\" %c_idxcount)\n",
    "\n",
    "    def create_playlist_translations(self, playlists_final):\n",
    "        # It would be easy to also create translations for users in this method. Choosing not to implement now. \n",
    "        p_idxcount = 0\n",
    "        p_count = 0\n",
    "        for playlist_id in playlists_final['playlist_id'].values:\n",
    "            if (playlist_id > 0): \n",
    "                if playlist_id not in self.playlist_to_idx: \n",
    "                    self.playlist_to_idx[playlist_id] = p_idxcount\n",
    "                    self.playlist_to_id[p_idxcount] = playlist_id\n",
    "                    p_idxcount += 1\n",
    "            p_count += 1\n",
    "        \n",
    "        print(\"Created %s indexes for %s playlists.\"%(len(self.playlist_to_idx), playlists_final.shape[0]))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    #\n",
    "    def get_track_id(self, idx):\n",
    "        return self.track_to_id[idx]#\n",
    "    def get_track_idx(self, id):\n",
    "        return self.track_to_idx[id]#\n",
    "    def get_content_id(self, idx):\n",
    "        return self.content_to_id[idx]#\n",
    "    def get_content_idx(self, id):\n",
    "        return self.content_to_idx[id]#\n",
    "    def get_playlist_id(self, idx):\n",
    "        return self.playlist_to_id[idx]#\n",
    "    def get_playlist_idx(self, id):\n",
    "        return self.playlist_to_idx[id]\n",
    "T = Translator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(object): \n",
    "    def __init__(self):\n",
    "        #train_final.csv - the training set of interactions\n",
    "        self.train_final = pd.read_csv('input/train_final.csv', delimiter = \"\\t\");\n",
    "\n",
    "        #tracks_final.csv - supplementary information about the items\n",
    "        self.tracks_final = pd.read_csv('input/tracks_final.csv', delimiter = \"\\t\");\n",
    "        \n",
    "        #playlists_final.csv - supplementary information about the users\n",
    "        self.playlists_final = pd.read_csv('input/playlists_final.csv', delimiter = \"\\t\");\n",
    "\n",
    "        #target_playlists.csv - the set of target playlists that will receive recommendations\n",
    "        self.target_playlists = pd.read_csv('input/target_playlists.csv');\n",
    "\n",
    "        #target_tracks.csv - the set of target items (tracks) to be recommended\n",
    "        self.target_tracks = pd.read_csv('input/target_tracks.csv');\n",
    "\n",
    "        #self.tracks_relevant = self.get_relevant_tracks(self.train_final, self.target_tracks)\n",
    "        #\n",
    "        ##Remove irrelevant tracks from train_final and tracks_final\n",
    "        #self.train_final = self.train_final[self.train_final['track_id'].isin(self.tracks_relevant['track_id'])]\n",
    "\n",
    "        #print(\"Train_final now contains %s interactions. \" %(self.train_final.shape[0]))\n",
    "\n",
    "        #self.tracks_final = self.tracks_final[self.tracks_final['track_id'].isin(self.tracks_relevant['track_id'])]\n",
    "\n",
    "        #print(\"Tracks_final now contains %s tracks. \"%(self.tracks_final.shape[0]))\n",
    "        \n",
    "        T.create_content_translations(self.tracks_final)\n",
    "        T.create_playlist_translations(self.playlists_final)\n",
    "        \n",
    "    def get_relevant_tracks(self, train_final, target_tracks):\n",
    "        #Now we want to remove some redundant stuff. \n",
    "\n",
    "        #We will remove all songs which are not occurring more than 10 times in train_final\n",
    "        #Nevertheless, we still want to keep all tracks which are in the target tracks.  \n",
    "\n",
    "        popularity = train_final.groupby(by=\"track_id\").playlist_id.nunique().to_frame()\n",
    "\n",
    "        #remove index name\n",
    "        popularity.reset_index(level = 0, inplace = True)\n",
    "\n",
    "        #Rename the columns\n",
    "        popularity.columns = ['track_id','occurrences']\n",
    "\n",
    "        #Remove all targeted tracks - TESTED, working as expected\n",
    "        tracks_relevant = popularity[~popularity['track_id'].isin(target_tracks['track_id'])]\n",
    "\n",
    "        #Remove tracks occurring less than 10 times\n",
    "        tracks_relevant = tracks_relevant[tracks_relevant['occurrences'] > 7]\n",
    "\n",
    "        #Add the targeteted tracks back again\n",
    "        tracks_relevant = pd.concat([tracks_relevant, target_tracks])\n",
    "\n",
    "        print(\"Removed redundant > 7\")\n",
    "        \n",
    "        return(tracks_relevant)\n",
    "\n",
    "    def build_target_filter(self): \n",
    "        target_filter = np.ones((self.tracks_final.shape[0]), dtype = bool)\n",
    "        \n",
    "        for track_id in self.target_tracks['track_id'].values: \n",
    "            track_idx = T.get_track_idx(track_id)\n",
    "            target_filter[track_idx] = False\n",
    "        self.ttf = target_filter\n",
    "        print(\"Built target filter with shape %s \"%(target_filter.shape))\n",
    "        return target_filter\n",
    "\n",
    "    def build_URMs(self,k = 4): \n",
    "        # Creates a self.URM_train and self.URM_test    \n",
    "        playlistList = self.train_final['playlist_id'].values\n",
    "        itemList = self.train_final['track_id'].values\n",
    "\n",
    "        #Translate ids\n",
    "        playlistList_translated = np.zeros(playlistList.shape)\n",
    "        itemList_translated = np.zeros(itemList.shape)\n",
    "        ratingList = np.ones((playlistList.shape), int)\n",
    "        filter_train = np.ones((playlistList.shape), bool)\n",
    "        filter_test = np.zeros((playlistList.shape), bool)\n",
    "        filter_test[0] = True # little workaround\n",
    "        playlist_counter = {}\n",
    "        \n",
    "        \n",
    "        for i, p_id in enumerate(playlistList):\n",
    "            p_idx = T.get_playlist_idx(p_id)\n",
    "            playlistList_translated[i] = p_idx \n",
    "            \n",
    "            i_idx = T.get_track_idx(itemList[i])\n",
    "            itemList_translated[i] = i_idx\n",
    "            \n",
    "            if p_idx not in playlist_counter:\n",
    "                playlist_counter[p_idx] = 0\n",
    "                \n",
    "            if playlist_counter[p_idx] < k:\n",
    "                filter_train[i] = False # Removes the rating for this particular rating.\n",
    "                filter_test[i] = True\n",
    "                playlist_counter[p_idx] += 1 # When k is reached we will remove no more from this pl.                     \n",
    "\n",
    "        \n",
    "        ## Build URM_train. \n",
    "        URM_train = sps.coo_matrix((ratingList[filter_train], (playlistList_translated[filter_train], itemList_translated[filter_train])))\n",
    "        URM_train = URM_train.tocsr()\n",
    "\n",
    "        ## Build URM_train & URM_test\n",
    "        URM_test = sps.coo_matrix((ratingList[filter_test], (playlistList_translated[filter_test], itemList_translated[filter_test])))\n",
    "        URM_test= URM_test.tocsr()\n",
    "         \n",
    "        self.URM_train = URM_train\n",
    "        self.URM_test = URM_test\n",
    "        \n",
    "        print(URM_test.nnz)\n",
    "        print(URM_train.nnz)\n",
    "        print(\"%s, %s\" %(URM_test.nnz + URM_train.nnz, self.train_final.shape[0]))\n",
    "        print(\"Removed %s from %s playlists. %s \" %(len(filter_test.nonzero()[0]), len(playlist_counter),len(filter_test.nonzero()[0])/ len(playlist_counter) ))\n",
    "        print(playlist_counter[45648])\n",
    "        \n",
    "    def build_ICM(self):\n",
    "        i = 0\n",
    "        track_count = 0\n",
    "        track_index_list = np.zeros([1000000,])\n",
    "        content_index_list = np.zeros([1000000,])\n",
    "        for track_id, artist_id, duration, playcount, album_id, tags in self.tracks_final.values:\n",
    "            track_index_list[i] = T.get_track_idx(track_id)\n",
    "            content_index_list[i] = T.get_content_idx('ar'+str(artist_id))\n",
    "            i += 1\n",
    "            \n",
    "            track_index_list[i] = T.get_track_idx(track_id)\n",
    "            content_index_list[i] = T.get_content_idx('al'+str(album_id))\n",
    "            i += 1\n",
    "            \n",
    "            tags = tags.strip('[ ]').split(', ')\n",
    "            for tag in tags:\n",
    "                if (len(tag) > 0 and tag is not None and tag != 'None'): \n",
    "                    track_index_list[i] = T.get_track_idx(track_id)\n",
    "                    content_index_list[i] = T.get_content_idx('ta'+str(tag))\n",
    "                i += 1\n",
    "                    \n",
    "                \n",
    "            #if track_count % 10000 == 0: \n",
    "            #    print(\"Track %s out of 100k\" %track_count)\n",
    "            #    print(i)\n",
    "            track_count += 1\n",
    "        \n",
    "        self.ICM = sps.coo_matrix((np.ones(track_index_list.shape, int), (track_index_list, content_index_list)))\n",
    "        self.ICM = self.ICM.tocsr()\n",
    "\n",
    "        \n",
    "        print(\"Built ICM with dimensions: Item (%s) x Content (%s) \" %self.ICM.shape)\n",
    "#d = Data()\n",
    "#ttf = d.build_target_filter()\n",
    "#print(ttf.shape)\n",
    "#d.build_ICM()\n",
    "#sps.save_npz(\"Saved Matrixes/ICM_perfect_7\", d.ICM)\n",
    "#print(\"Saved ICM!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_matrices():\n",
    "    d = Data()\n",
    "    d.build_URMs(k = 5)\n",
    "    d.build_ICM()\n",
    "    print(d.URM_train.nnz)\n",
    "\n",
    "\n",
    "    ax = plot_coo_matrix(d.ICM)\n",
    "    ax.figure.show()\n",
    "\n",
    "    ax = plot_coo_matrix(d.URM_train)\n",
    "    ax.figure.show()\n",
    "\n",
    "    ax = plot_coo_matrix(d.URM_test)\n",
    "    ax.figure.show()\n",
    "#plot_matrices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Recommender(object):\n",
    "    def __init__(self, ICM, URM_train, URM_test, target_tracks_filter, shrinkage = 0, export = False):\n",
    "        self.URM_train = URM_train\n",
    "        self.ICM = ICM\n",
    "        self.ttf = target_tracks_filter\n",
    "        self.shrinkage = shrinkage\n",
    "        self.URM_test = URM_test\n",
    "        self.export = export\n",
    "\n",
    "        \n",
    "    def fit(self): \n",
    "        print(\"Fitting..\")\n",
    "        starttime = time.time()\n",
    "        # Compute ISM (I x I)\n",
    "        cp = time.time()\n",
    "        self.ISM = self.ICM * self.ICM.T\n",
    "        print(\"Computed ISM %s sec\"%(time.time()-cp))\n",
    "        cp = time.time()\n",
    "        \n",
    "        #sps.save_npz(\"Saved Matrixes/ISM_perfect\", self.ISM)\n",
    "        #print(\"Saved ICM!\")\n",
    "        \n",
    "        \n",
    "        # and apply the shrinkage\n",
    "        if self.shrinkage > 0:\n",
    "            dist = self.apply_shrinkage(self.ICM, self.ISM)\n",
    "            print(\"Applied shrinkage %s sec. \"%(time.time()-cp))\n",
    "            cp = time.time()\n",
    "        \n",
    "        #Has to be csc. \n",
    "        #self.ISM = check_matrix(self.ISM, 'csc')\n",
    "        \n",
    "        # Filter: only targeted tracks ISM_target (I x tI)\n",
    "        self.ISM_target = self.ISM\n",
    "        #self.ISM_target = self.ISM[:,self.ttf]\n",
    "        #print(\"Filtered untargeted tracks. %s sec\" %(time.time()-cp))\n",
    "        #print(\"ISM_target: I x tI %s %s. \" %ISM_target.shape)\n",
    "        #cp = time.time()\n",
    "        \n",
    "        # Compute URM (U x I) x ISM_target (I x tI) = pred (U x tI)\n",
    "        \n",
    "        self.URM_pred = self.URM_train * self.ISM_target\n",
    "        print(\"Computed predictions. %s sec\" %(time.time()-cp))\n",
    "        print(\"URM_pred: U x tI %s %s. \" %self.ISM_target.shape)\n",
    "        \n",
    "        \n",
    "        # Model is now fitted\n",
    "    \n",
    "        print(\"Model fitted in %s sec.\"%(time.time-starttime))\n",
    "    \n",
    "    \n",
    "    def apply_shrinkage(self, X, dist):\n",
    "        # create an \"indicator\" version of X (i.e. replace values in X with ones)\n",
    "        X_ind = X.copy()\n",
    "        X_ind.data = np.ones_like(X_ind.data)\n",
    "        # compute the co-rated counts\n",
    "        co_counts = X_ind * X_ind.T\n",
    "        # remove the diagonal\n",
    "        co_counts = co_counts - sps.dia_matrix((co_counts.diagonal()[scipy.newaxis, :], [0]), shape=co_counts.shape)\n",
    "        # compute the shrinkage factor as co_counts_ij / (co_counts_ij + shrinkage)\n",
    "        # then multiply dist with it\n",
    "        co_counts_shrink = co_counts.copy()\n",
    "        co_counts_shrink.data += self.shrinkage\n",
    "        co_counts.data /= co_counts_shrink.data\n",
    "        dist.data *= co_counts.data\n",
    "        return dist\n",
    "    \n",
    "    def recommend(self, playlist_idx, k):        \n",
    "\n",
    "        # Filter: no already seen tracks\n",
    "        seen = URM_train[playlist_idx,:]\n",
    "        weights = self.W[playlist_idx,:][seen == False]\n",
    "        \n",
    "        # get indices of k largest values\n",
    "        top_weight_idx = np.argsort(self.weights)[-k:]\n",
    "        topk = self.weights[top_weight_idx]\n",
    "        \n",
    "        # translate indices to ids and sort in descending (largest first) order. \n",
    "        recommendations = np.array([0]*k)\n",
    "        for i, index in enumerate(topk): \n",
    "            track_id = T.get_track_id(index)\n",
    "            recommendations[k-i-1] = track_id\n",
    "        return recommendations\n",
    "    \n",
    "    def get_recommendations(self): \n",
    "        zeros = np.zeros((target_playlists.size, 6), dtype = int)\n",
    "        recommendations = pd.DataFrame(zeros)\n",
    "        recommendations.columns = ['playlist_id', 1, 2, 3, 4, 5]\n",
    "        counter = 0\n",
    "        starttime = time.time()\n",
    "        for playlist_id in target_playlists['playlist_id']:\n",
    "\n",
    "            if counter % 1000 == 0: \n",
    "                print (\"%s out of 10000 playlists, %s sec.\" %(counter, time.time()-starttime))\n",
    "\n",
    "            playlist_idx = T.get_playlist_idx[int(playlist_id)]\n",
    "            recommendations.iloc[counter, 1:6] = rec.recommend_new(playlist_idx, 5)\n",
    "            recommendations.iloc[counter, 0] = playlist_id\n",
    "            counter += 1\n",
    "            \n",
    "    def evaluate(self): \n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 100000 indexes for 100000 tracks.\n",
      "Created 77042 indexes for 686290 contents.\n",
      "Total content size: 77042\n",
      "Created 57561 indexes for 57561 playlists.\n",
      "162965\n",
      "877557\n",
      "1040522, 1040522\n",
      "Removed 162965 from 45649 playlists. 3.5699577208701174 \n",
      "4\n",
      "Built ICM with dimensions: Item (100000) x Content (77042) \n",
      "Built target filter with shape 100000 \n"
     ]
    }
   ],
   "source": [
    "d = Data()\n",
    "d.build_URMs()\n",
    "d.build_ICM()\n",
    "d.build_target_filter()\n",
    "\n",
    "r = Recommender(d.ICM, d.URM_train, d.URM_test, d.ttf, shrinkage = 0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000,)\n"
     ]
    }
   ],
   "source": [
    "print(d.ttf.shape)\n",
    "#print(r.ISM.shape)\n",
    "#print(r.ISM[:,d.ttf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting..\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-c7f562bd9bbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-4a75e3c76a4d>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# Compute ISM (I x I)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mcp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mISM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mICM\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mICM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Computed ISM %s sec\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mcp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mcp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dimension mismatch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul_sparse_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0;31m# If it's a list or whatever, treat it like a matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m_mul_sparse_matrix\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    531\u001b[0m            \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m            \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m            indptr)\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0mnnz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindptr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "r.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"hej\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Evaluation functions\n",
    "\n",
    "def precision(recommended_items, relevant_items):\n",
    "    \n",
    "    is_relevant = np.in1d(recommended_items, relevant_items, assume_unique=True)\n",
    "    \n",
    "    precision_score = np.sum(is_relevant, dtype=np.float32) / len(is_relevant)\n",
    "    \n",
    "    return precision_score\n",
    "\n",
    "def recall(recommended_items, relevant_items):\n",
    "    \n",
    "    is_relevant = np.in1d(recommended_items, relevant_items, assume_unique=True)\n",
    "    \n",
    "    recall_score = np.sum(is_relevant, dtype=np.float32) / relevant_items.shape[0]\n",
    "    \n",
    "    return recall_score\n",
    "\n",
    "def MAP(recommended_items, relevant_items):\n",
    "   \n",
    "    is_relevant = np.in1d(recommended_items, relevant_items, assume_unique=True)\n",
    "    \n",
    "    # Cumulative sum: precision at 1, at 2, at 3 ...\n",
    "    p_at_k = is_relevant * np.cumsum(is_relevant, dtype=np.float32) / (1 + np.arange(is_relevant.shape[0]))\n",
    "    \n",
    "    map_score = np.sum(p_at_k) / np.min([relevant_items.shape[0], is_relevant.shape[0]])\n",
    "\n",
    "    return map_score\n",
    "\n",
    "def evaluate_algorithm(URM_test, recommendations, at=5):\n",
    "    \n",
    "    starttime = time.time()\n",
    "    cumulative_precision = 0.0\n",
    "    cumulative_recall = 0.0\n",
    "    cumulative_MAP = 0.0\n",
    "    \n",
    "    num_eval = 0\n",
    "    \n",
    "    playlists = target_playlists['playlist_id']\n",
    "    \n",
    "    for i, playlist_id in enumerate(playlists):\n",
    "        relevant_items = URM_test[playlist_to_index[playlist_id]].indices\n",
    "        \n",
    "        for j, item_id in enumerate(relevant_items):\n",
    "            relevant_items[j] = track_to_id[item_id]\n",
    "            \n",
    "        if i % 500 == 0:\n",
    "            print(\"User %d of %d, %d sec.\" % (i, len(playlists), round(time.time()-starttime)))\n",
    "            print(relevant_items)\n",
    "            print(recommendations.iloc[i,1:6])\n",
    "        \n",
    "        if len(relevant_items)>0:\n",
    "            \n",
    "            recommended_items = recommendations.iloc[i,1:6]\n",
    "            num_eval+=1\n",
    "\n",
    "            cumulative_precision += precision(recommended_items, relevant_items)\n",
    "            cumulative_recall += recall(recommended_items, relevant_items)\n",
    "            cumulative_MAP += MAP(recommended_items, relevant_items)\n",
    "\n",
    "\n",
    "    cumulative_precision /= num_eval\n",
    "    cumulative_recall /= num_eval\n",
    "    cumulative_MAP /= num_eval\n",
    "    \n",
    "    print(\"Recommender performance is: Precision = {:.4f}, Recall = {:.4f}, MAP = {:.4f}\".format(\n",
    "        cumulative_precision, cumulative_recall, cumulative_MAP))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
