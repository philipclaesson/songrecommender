{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse as sps\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n",
    "#train_final.csv - the training set of interactions\n",
    "train_final = pd.read_csv('input/train_final.csv', delimiter = \"\\t\");\n",
    "\n",
    "#tracks_final.csv - supplementary information about the items\n",
    "tracks_final = pd.read_csv('input/tracks_final.csv', delimiter = \"\\t\");\n",
    "\n",
    "#playlists_final.csv - supplementary information about the users\n",
    "playlists_final = pd.read_csv('input/playlists_final.csv', delimiter = \"\\t\");\n",
    "\n",
    "#target_playlists.csv - the set of target playlists that will receive recommendations\n",
    "target_playlists = pd.read_csv('input/target_playlists.csv');\n",
    "\n",
    "#target_tracks.csv - the set of target items (tracks) to be recommended\n",
    "target_tracks = pd.read_csv('input/target_tracks.csv');\n",
    "print(\"Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27604\n"
     ]
    }
   ],
   "source": [
    "albums = {}\n",
    "for album in tracks_final['album']:\n",
    "    album = album.strip('[ ]')\n",
    "    if album != None and album != \"None\" and len(album) > 0: #None should not be considered content\n",
    "        albums[album] = 1\n",
    "\n",
    "print(len(albums))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77040\n",
      "27604 albums. 27604 expected.\n",
      "17536 artists. 17537 expected.\n"
     ]
    }
   ],
   "source": [
    "tracks_final['tags'].head()\n",
    "\n",
    "content_to_index = {}\n",
    "content_to_id = {}\n",
    "content_counter = 0\n",
    "\n",
    "#Lets translate the tags to indexes.\n",
    "for row in tracks_final['tags']:\n",
    "    tags = row.strip('[ ]').split(', ')\n",
    "    for tag in tags:\n",
    "        if len(tag) > 0: \n",
    "            tag = \"ta\"+tag\n",
    "            if not(tag in content_to_index):\n",
    "                content_to_index[tag] = content_counter\n",
    "                content_to_id[content_counter] = tag\n",
    "                content_counter += 1;\n",
    "\n",
    "#Lets translate album into indexes\n",
    "albumcount = 0 # 27604\n",
    "for album in tracks_final['album']:\n",
    "    album = album.strip('[ ]')\n",
    "    if album != None and album != \"None\" and len(album) > 0: #None should not be considered content\n",
    "        album = \"al\"+album\n",
    "        if album == \"alNone\":\n",
    "            print(album)\n",
    "        if not(album in content_to_index):\n",
    "            content_to_index[album] = content_counter\n",
    "            content_to_id[content_counter] = album\n",
    "            content_counter += 1\n",
    "            albumcount += 1\n",
    "#Lets translate artist_id into indexes \n",
    "artistcount = 0 #17537\n",
    "for artist in tracks_final['artist_id']:\n",
    "    artist = str(artist)\n",
    "    if artist != None and artist != \"None\" and len(artist) > 0: #None should not be considered content\n",
    "        artist = \"ar\"+artist\n",
    "        if not(artist in content_to_index):\n",
    "            content_to_index[artist] = content_counter\n",
    "            content_to_id[content_counter] = artist\n",
    "            content_counter += 1\n",
    "            artistcount += 1\n",
    "            \n",
    "print(len(content_to_index))\n",
    "print(\"%s albums. 27604 expected.\" %albumcount)\n",
    "print(\"%s artists. 17537 expected.\" %artistcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 57561 playlists with 100000 unique tracks with 77040 unique content types. \n"
     ]
    }
   ],
   "source": [
    "#If we translate each track_id to a track_index which will serve as matrix index, we can save a lot of time. \n",
    "\n",
    "\n",
    "#We need a way to get from track_id to index in O(1).\n",
    "#Let's create a dictionary\n",
    "\n",
    "track_to_id = {}\n",
    "track_to_index = {}\n",
    "track_ids = tracks_final['track_id']\n",
    "\n",
    "counter = 0;\n",
    "for track_id in tracks_final['track_id']:\n",
    "    track_id = int(track_id)\n",
    "    track_to_index[track_id] = counter\n",
    "    track_to_id[counter] = track_id\n",
    "    counter += 1;\n",
    "    \n",
    "#and a way to get from playlist_id to index in O(1)\n",
    "\n",
    "\n",
    "playlist_to_index = {}\n",
    "playlist_to_id = {}\n",
    "counter = 0; \n",
    "for playlist_id in playlists_final['playlist_id']:\n",
    "    playlist_id = int(playlist_id)\n",
    "    playlist_to_index[playlist_id] = counter\n",
    "    playlist_to_id[counter] = playlist_id\n",
    "    counter += 1;\n",
    "    \n",
    "print(\"We have {} playlists with {} unique tracks with {} unique content types. \".format(len(playlist_to_index), len(track_to_index), len(content_to_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track 0 of 100000. 0.0 s sec.\n",
      "Track 5000 of 100000. 0.12 s sec.\n",
      "Track 10000 of 100000. 0.24 s sec.\n",
      "Track 15000 of 100000. 0.36 s sec.\n",
      "Track 20000 of 100000. 0.49 s sec.\n",
      "Track 25000 of 100000. 0.6 s sec.\n",
      "Track 30000 of 100000. 0.72 s sec.\n",
      "Track 35000 of 100000. 0.83 s sec.\n",
      "Track 40000 of 100000. 0.94 s sec.\n",
      "Track 45000 of 100000. 1.05 s sec.\n",
      "Track 50000 of 100000. 1.16 s sec.\n",
      "Track 55000 of 100000. 1.28 s sec.\n",
      "Track 60000 of 100000. 1.4 s sec.\n",
      "Track 65000 of 100000. 1.52 s sec.\n",
      "Track 70000 of 100000. 1.63 s sec.\n",
      "Track 75000 of 100000. 1.74 s sec.\n",
      "Track 80000 of 100000. 1.86 s sec.\n",
      "Track 85000 of 100000. 1.97 s sec.\n",
      "Track 90000 of 100000. 2.09 s sec.\n",
      "Track 95000 of 100000. 2.2 s sec.\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "Built ICM matrix with 656745 content values.\n",
      "27604 albums. 27604 expected.\n",
      "17536 artists. 17537 expected.\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#So let's fill the ICM with our data.\n",
    "import math\n",
    "\n",
    "def build_ICM():\n",
    "    \n",
    "    no_interactions = train_final.shape[0]\n",
    "    \n",
    "    tracks_matrix = tracks_final.as_matrix()\n",
    "    rows = np.zeros((no_interactions,), dtype = int)\n",
    "    cols = np.zeros((no_interactions,), dtype = int)\n",
    "    val = np.zeros((no_interactions,), dtype = int)\n",
    "    #val[i] = value of row[i] col[i]\n",
    "    #val = []\n",
    "    counter = 0\n",
    "    starttime = time.time()\n",
    "    lasttime = starttime\n",
    "    trackno = 0\n",
    "    addedalbums = {} #for testing\n",
    "    addedartists = {} # for testing\n",
    "    for track in tracks_matrix: \n",
    "        track_id, artist_id, duration, playcount, album, tags = np.split(track, 6)\n",
    "\n",
    "        #Get track index\n",
    "        track_index = track_to_index[int(track_id[0])]\n",
    "\n",
    "        \n",
    "        #add artist\n",
    "        \n",
    "        artist_index = content_to_index[\"ar\"+str(artist_id[0])]\n",
    "        addedartists[artist_index] = 1\n",
    "        \n",
    "        rows[counter] = track_index\n",
    "        cols[counter] = artist_index\n",
    "        val[counter] = 1\n",
    "        counter += 1\n",
    "\n",
    "        #add album\n",
    "        album = album[0].strip(\"[ ]\")\n",
    "\n",
    "        if album != None and len(album) > 0 and not album == \"None\":\n",
    "            album_index = content_to_index[\"al\"+album]\n",
    "            addedalbums[album_index] = 1 #testing\n",
    "            \n",
    "            rows[counter] = track_index\n",
    "            cols[counter] = album_index\n",
    "            val[counter] = 1\n",
    "            counter += 1\n",
    "\n",
    "        #add tags\n",
    "        tags = tags[0].strip('[ ]').split(', ')\n",
    "\n",
    "        for tag in tags: \n",
    "            if len(tag) > 0:\n",
    "                tag = \"ta\"+tag\n",
    "                tag_index = content_to_index[tag]\n",
    "\n",
    "                rows[counter] = track_index\n",
    "                cols[counter] = tag_index\n",
    "                val[counter] = 1\n",
    "                \n",
    "                counter+=1\n",
    "                \n",
    "        if trackno%5000 == 0:\n",
    "            print(\"Track %s of %s. %s s sec.\" %(trackno, tracks_matrix.shape[0], round(time.time()-starttime, 2)))  \n",
    "        trackno += 1\n",
    "    \n",
    "    rows = rows[:counter]\n",
    "    cols = cols[:counter]\n",
    "    val = val[:counter]\n",
    "    \n",
    "    print(rows[counter:])\n",
    "    \n",
    "    print(cols[counter:])\n",
    "    \n",
    "    print(val[counter:])\n",
    "    #val = np.ones(rows.shape, dtype = int)\n",
    "\n",
    "    #Build ICM matrix. \n",
    "    ICM_all = sps.coo_matrix((val, (rows, cols)), dtype = int)\n",
    "    \n",
    "    print(\"Built ICM matrix with %s content values.\" %(val.shape[0]))\n",
    "    \n",
    "    print(\"%s albums. 27604 expected.\" %len(addedalbums))\n",
    "    print(\"%s artists. 17537 expected.\" %len(addedartists))\n",
    "    \n",
    "    return ICM_all\n",
    "\n",
    "\n",
    "#Build new ICM\n",
    "ICM_all = build_ICM()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_target_item_filter(indices):\n",
    "    target_filter = np.zeros((indices), dtype = bool)\n",
    "    for track in target_tracks.values:\n",
    "        track_id = track[0]\n",
    "        track_index = track_to_index[track_id]\n",
    "        target_filter[track_index] = True\n",
    "    print(\"Created filter preserving %s out of %s \" %(np.count_nonzero(target_filter),target_filter.shape[0]))\n",
    "    return target_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: 832101. False: 208421. Tot: 1040522\n",
      "Built URM_test\n",
      "Total datapoints: 1040522. Expected: 1040522\n",
      "(57560, 100000)\n",
      "(57560, 99999)\n"
     ]
    }
   ],
   "source": [
    "def build_URM(train_test_split = 0.80):\n",
    "    #Builds urm \n",
    "    \n",
    "    #train_test_split = 1\n",
    "    \n",
    "    numInteractions = train_final.shape[0]\n",
    "\n",
    "    train_mask = np.random.choice(a = [True,False], size = numInteractions, p = [train_test_split, 1-train_test_split])\n",
    "    \n",
    "    playlistList = train_final['playlist_id'].values\n",
    "    itemList = train_final['track_id'].values\n",
    "\n",
    "    #Translate ids\n",
    "    playlistList_translated = np.zeros(playlistList.shape)\n",
    "    itemList_translated = np.zeros(itemList.shape)\n",
    "    ratingList = np.ones((playlistList.shape), int)\n",
    "    \n",
    "    tru = train_mask[train_mask == True].shape[0]\n",
    "    fal = (train_mask[train_mask == False].shape[0])\n",
    "    \n",
    "    print(\"True: %s. False: %s. Tot: %s\" %(tru, fal, (tru+fal)))\n",
    "\n",
    "    \n",
    "    for i in range(train_final.shape[0]):\n",
    "        playlistList_translated[i] = playlist_to_index[playlistList[i]]\n",
    "        itemList_translated[i] = track_to_index[itemList[i]]\n",
    "    #print(\"Translated ids to indexes.\")\n",
    "    \n",
    "    #Build URM matrix. \n",
    "    URM_train = sps.coo_matrix((ratingList[train_mask], (playlistList_translated[train_mask], itemList_translated[train_mask])))\n",
    "    URM_train = URM_train.tocsr()\n",
    "    #print(\"Built URM_train with shape %s,%s\" %(URM_train.shape[0],URM_train.shape[1]))\n",
    "    \n",
    "    if train_test_split < 1: \n",
    "        #Build URM_test\n",
    "        test_mask = np.logical_not(train_mask)\n",
    "        URM_test = sps.coo_matrix((ratingList[test_mask], (playlistList_translated[test_mask], itemList_translated[test_mask])))\n",
    "        URM_test = URM_test.tocsr()\n",
    "        print(\"Built URM_test\")\n",
    "        testsize = (test_mask[test_mask == True].shape[0])\n",
    "\n",
    "    else: \n",
    "        URM_test = sps.csc_matrix((10, 10), dtype=np.int8)\n",
    "        testsize = 0\n",
    "    \n",
    "    \n",
    "    trainsize = train_mask[train_mask == True].shape[0]\n",
    "    totsize = trainsize + testsize\n",
    "    print(\"Total datapoints: %s. Expected: %s\" %(totsize,numInteractions))\n",
    "\n",
    "    \n",
    "    print(URM_train.shape)\n",
    "    print(URM_test.shape)\n",
    "    \n",
    "    return URM_train, URM_test\n",
    "\n",
    "URM_train, URM_test = build_URM(0.8)\n",
    "\n",
    "#Problem: The number of true/false values is not consistent.. Gives problems when testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: 832263. False: 208259. Tot: 1040522\n",
      "Built URM_test\n",
      "Total datapoints: 1040522. Expected: 1040522\n",
      "(57560, 100000)\n",
      "(57560, 100000)\n",
      "832263\n"
     ]
    }
   ],
   "source": [
    "URM_train, URM_test = build_URM(0.8)\n",
    "print(URM_train.nnz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "class Recommender(object):\n",
    "    def __init__(self, URM, target_items, item_ids, k=50, shrinkage=100, similarity='cosine', filter_method = 'content', topK = 100):\n",
    "        self.dataset = URM\n",
    "        self.target_items = target_items\n",
    "        self.target_item_filter = get_target_item_filter(tracks_final.shape[0])\n",
    "        self.item_ids = item_ids\n",
    "        self.k = k\n",
    "        self.shrinkage = shrinkage\n",
    "        self.similarity_name = similarity\n",
    "        self.filter_method = filter_method\n",
    "        self.topK = topK\n",
    "        \n",
    "        self.UIM = None\n",
    "        \n",
    "        if similarity == 'cosine':\n",
    "            self.distance = Cosine(shrinkage=self.shrinkage)\n",
    "        elif similarity == 'pearson':\n",
    "            self.distance = Pearson(shrinkage=self.shrinkage)\n",
    "        elif similarity == 'adj-cosine':\n",
    "            self.distance = AdjustedCosine(shrinkage=self.shrinkage)\n",
    "        else:\n",
    "            raise NotImplementedError('Distance {} not implemented'.format(similarity))\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"Recommender(similarity={},k={},shrinkage={})\".format(self.similarity_name, self.k, self.shrinkage)\n",
    "\n",
    "    \n",
    "    def fit_new(self, X, noise = 0.1, CF_ratio = 0.5):\n",
    "        ## GET ISM MATRIX (I X I)\n",
    "        cp = time.time()\n",
    "        #Calculate cosine similarity\n",
    "        print(\"Using %s filtering with TopK = %s to compute distance.\" %(self.filter_method, self.topK))\n",
    "        \n",
    "        cosine_cython = Cosine_Similarity(URM_train, TopK=self.topK)\n",
    "        ISM_cf = cosine_cython.compute_similarity()\n",
    "        \n",
    "        print(\"Computed collaborative similarity matrix. %s \" %(time.time()-cp))\n",
    "        cp = time.time()\n",
    "        \n",
    "        ISM_cont = self.distance.compute(X)\n",
    "        print(\"Computed content based similarity matrix. %s \" %(time.time()-cp))\n",
    "        cp = time.time()\n",
    "        \n",
    "        w1 = CF_ratio\n",
    "        w2 = 1-CF_ratio\n",
    "        ISM = w1 * ISM_cf + w2 * ISM_cont\n",
    "        print(\"Combined similarity matrices with ratio %s. %s \" %(CF_ratio, time.time()-cp))\n",
    "        cp = time.time()\n",
    "        \n",
    "        ##GET URM (U X I)\n",
    "        \n",
    "        URM = self.dataset\n",
    "        \n",
    "        ## GET item_ids (1 x I)\n",
    "        \n",
    "        #self.item_ids\n",
    "        \n",
    "        ## FILTER item_ids INTO target_item_ids (1 x tI)\n",
    "        \n",
    "        self.target_item_ids = track_ids[self.target_item_filter]\n",
    "        print(URM.nnz)\n",
    "        print(ISM.nnz)\n",
    "        \n",
    "        ## FILTER TARGETED TRACKS\n",
    "        #Maybe this is not working as expected - are we filtering the right tracks? \n",
    "        \n",
    "        ISM = ISM[:,self.target_item_filter]\n",
    "        print(\"Filtered targeted tracks in ISM. %s \" %(time.time()-cp))\n",
    "        cp = time.time()\n",
    "        \n",
    "        #self.ISM = sps.csr_matrix(self.ISM)\n",
    "        \n",
    "        cp = time.time()  \n",
    "        print(URM.nnz)\n",
    "        #ISM = sps.csr_matrix(ISM)\n",
    "        print(ISM.nnz)\n",
    "        \n",
    "        ## CONVERT URM TO CSR\n",
    "        URM = check_matrix(URM, 'csr')\n",
    "        print(\"Checked URM csr %s \" %(time.time()-cp))\n",
    "        cp = time.time()\n",
    "        \n",
    "        ##Print dimension\n",
    "        print(URM.shape)\n",
    "        print(ISM.shape)\n",
    "        \n",
    "        ## MULTIPLY URM (U x I) * ISM (I x I)\n",
    "        UIM = URM.dot(ISM)\n",
    "        print(\"Computed URM * ISM %s \" %(time.time()-cp))\n",
    "        cp = time.time()\n",
    "        \n",
    "\n",
    "        \n",
    "        ## MAKE NOT SPARSE\n",
    "        #UIM_dense = UIM.todense()\n",
    "        \n",
    "        ## FILTER UIM into (U x tI) (not needed since I already filtered!)\n",
    "        #UIM_dense = UIM_dense[:,self.target_item_filter]\n",
    "        \n",
    "        ## THIS IS OUR FITTED MODEL\n",
    "        self.UIM = UIM\n",
    "        \n",
    "        return self.UIM\n",
    "\n",
    "        \n",
    "    def recommend_new(self, user_id, at = 5):\n",
    "        ## GET USER_INDEX\n",
    "        user_index = playlist_to_index[user_id]\n",
    "        \n",
    "        # Convert to np.array (why wasn't it before?!)\n",
    "        self.target_item_ids = np.array(self.target_item_ids)\n",
    "        \n",
    "        ## GET ROW CORRESPONDING TO USER (1 x tI)\n",
    "        user_weights = self.UIM[user_index,:].toarray()\n",
    "             \n",
    "        ## ARGSORT BASED ON AXIS = 0, GET [1,0:at]\n",
    "        top_indexes = np.argsort(user_weights)#[-at:]\n",
    "        top_k_indexes = top_indexes[0, -at:]\n",
    "\n",
    "        ## Translate to indexes\n",
    "        recommendations = self.target_item_ids[top_k_indexes]\n",
    "        \n",
    "        ## RETURN RECOMMENDATIONS\n",
    "        return(recommendations)\n",
    "    \n",
    "    def recommend_dev(self, user_id, at = 5):\n",
    "        print(\"Recommend %s items for user %s!\" %(at, user_id))\n",
    "        ## GET USER_INDEX\n",
    "        user_index = playlist_to_index[user_id]\n",
    "        \n",
    "        # Convert to np.array (why wasn't it before?!)\n",
    "        self.target_item_ids = np.array(self.target_item_ids)\n",
    "        \n",
    "        ## GET ROW CORRESPONDING TO USER (1 x tI)\n",
    "        user_weights = self.UIM[user_index,:].toarray()\n",
    "             \n",
    "        ## ARGSORT BASED ON AXIS = 0, GET [1,0:at]\n",
    "        top_indexes = np.argsort(user_weights)#[-at:]\n",
    "        print(top_indexes.shape)\n",
    "        top_k_indexes = top_indexes[0, -at:]\n",
    "        print(top_k_indexes.shape)\n",
    "\n",
    "        ## Translate to indexes\n",
    "        recommendations = self.target_item_ids[top_k_indexes]\n",
    "        \n",
    "        ## RETURN RECOMMENDATIONS\n",
    "        return(recommendations)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def recommend(self, user_id, at=None, exclude_seen=True):\n",
    "        # compute the scores using the dot product\n",
    "        user_profile = self.dataset[user_id]\n",
    "        print(\"User profile: %s\" %(user_profile))\n",
    "        scores = user_profile.dot(self.W_sparse).toarray().ravel()\n",
    "        print(\"Scores: %s\" %(scores))\n",
    "        # rank items\n",
    "        ranking = scores.argsort()[::-1]\n",
    "        if exclude_seen:\n",
    "            ranking = self._filter_seen(user_id, ranking)\n",
    "        \n",
    "        print(\"Ranking: %s\" %(ranking))\n",
    "        \n",
    "        export = [0,0,0,0,0]\n",
    "        for i in range(5):\n",
    "            t_id = track_to_id[ranking[i]]\n",
    "            export[i] = t_id\n",
    "            \n",
    "        return export\n",
    "    def _filter_seen(self, user_id, ranking):\n",
    "        user_profile = self.dataset[user_id]\n",
    "        seen = user_profile.indices\n",
    "        unseen_mask = np.in1d(ranking, seen, assume_unique=True, invert=True)\n",
    "        return ranking[unseen_mask]\n",
    "\n",
    "print(\"asd\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
