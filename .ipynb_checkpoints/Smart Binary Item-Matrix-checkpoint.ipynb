{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playlist_id</th>\n",
       "      <th>track_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3271849</td>\n",
       "      <td>2801526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5616275</td>\n",
       "      <td>727878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11267488</td>\n",
       "      <td>2805283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10103900</td>\n",
       "      <td>1515105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3836898</td>\n",
       "      <td>2945623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   playlist_id  track_id\n",
       "0      3271849   2801526\n",
       "1      5616275    727878\n",
       "2     11267488   2805283\n",
       "3     10103900   1515105\n",
       "4      3836898   2945623"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse as sps\n",
    "%matplotlib inline\n",
    "\n",
    "#train_final.csv - the training set of interactions\n",
    "train_final = pd.read_csv('input/train_final.csv', delimiter = \"\\t\");\n",
    "\n",
    "#tracks_final.csv - supplementary information about the items\n",
    "tracks_final = pd.read_csv('input/tracks_final.csv', delimiter = \"\\t\");\n",
    "\n",
    "#playlists_final.csv - supplementary information about the users\n",
    "playlists_final = pd.read_csv('input/playlists_final.csv', delimiter = \"\\t\");\n",
    "\n",
    "#target_playlists.csv - the set of target playlists that will receive recommendations\n",
    "target_playlists = pd.read_csv('input/target_playlists.csv');\n",
    "\n",
    "#target_tracks.csv - the set of target items (tracks) to be recommended\n",
    "target_tracks = pd.read_csv('input/target_tracks.csv');\n",
    "\n",
    "#Let's have a look at the train data. \n",
    "train_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41756, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we need to remove some redundant stuff. \n",
    "\n",
    "#We will remove all song which are not: 1. occurring more than 10 times in train_final and 2. not in the target_tracks. \n",
    "\n",
    "popularity = train_final.groupby(by=\"track_id\").playlist_id.nunique().to_frame()\n",
    "\n",
    "#remove index name\n",
    "popularity.reset_index(level = 0, inplace = True)\n",
    "\n",
    "#Rename the columns\n",
    "popularity.columns = ['track_id','occurrences']\n",
    "\n",
    "#Remove all targeted tracks - TESTED, working as expected\n",
    "tracks_relevant = popularity[~popularity['track_id'].isin(target_tracks['track_id'])]\n",
    "\n",
    "#Remove tracks occurring less than 10 times\n",
    "tracks_relevant = tracks_relevant[tracks_relevant['occurrences'] > 10]\n",
    "\n",
    "#Add the targeteted tracks back again\n",
    "tracks_relevant = pd.concat([tracks_relevant, target_tracks])\n",
    "\n",
    "tracks_relevant.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45649, 2)\n",
      "(23618, 2)\n"
     ]
    }
   ],
   "source": [
    "#We will remove all playlists which are not: 1. containing more than 5 tracks and 2. not in the target_playlists.\n",
    "\n",
    "playlists_sizes = train_final.groupby(by=\"playlist_id\").track_id.nunique().to_frame()\n",
    "\n",
    "#remove index name\n",
    "playlists_sizes.reset_index(level = 0, inplace = True)\n",
    "\n",
    "#Rename the columns\n",
    "playlists_sizes.columns = ['playlist_id','size']\n",
    "\n",
    "print(playlists_sizes.shape)\n",
    "\n",
    "#Remove all targeted playlists TESTED works\n",
    "playlists_relevant = playlists_sizes[~playlists_sizes['playlist_id'].isin(target_playlists['playlist_id'])]\n",
    "\n",
    "#Remove playlists of size less than 10\n",
    "playlists_relevant = playlists_relevant[playlists_relevant['size'] > 10]\n",
    "\n",
    "#Add the targeteted playlists back again\n",
    "playlists_relevant = pd.concat([playlists_relevant, target_playlists])\n",
    "\n",
    "print(playlists_relevant.shape)\n",
    "\n",
    "\n",
    "#WORKING! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1040522, 2)\n",
      "(731373, 2)\n",
      "(667033, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/philipclaesson/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "#Now we have to create a set of the relevant train data. \n",
    "\n",
    "\n",
    "print(train_final.shape)\n",
    "\n",
    "train_relevant = train_final[train_final['track_id'].isin(tracks_relevant['track_id'])]\n",
    "\n",
    "print(train_relevant.shape)\n",
    "\n",
    "train_relevant = train_relevant[train_final['playlist_id'].isin(playlists_relevant['playlist_id'])]\n",
    "\n",
    "print(train_relevant.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item_playlist_matrix = np.zeros([playlists_relevant.shape[0], tracks_relevant.shape[0]],int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "986258583"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Very large matrix filled with zeros.\n",
    "#Old size before removing used to be 5.756.100.000\n",
    "#New size: 986.193.208\n",
    "item_playlist_matrix.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hej1\n"
     ]
    }
   ],
   "source": [
    "#If we translate each track_id to a track_index which will serve as matrix index, we can save a lot of time. \n",
    "#Same goes for playlist_id --> playlist_index. \n",
    "\n",
    "\n",
    "#We need a way to get from track_id to index in O(1).\n",
    "#Let's create a dictionary\n",
    "\n",
    "track_indexes = {}\n",
    "index_to_item = {}\n",
    "counter = 0; \n",
    "for track_id in tracks_relevant['track_id']:\n",
    "    item_playlist_matrix[0][counter] = track_id\n",
    "    track_indexes[track_id] = counter\n",
    "    counter += 1;\n",
    "    \n",
    "#and a way to get from playlist_id to index in O(1)\n",
    "\n",
    "\n",
    "playlist_indexes = {}\n",
    "index_to_playlist = {}\n",
    "counter = 0; \n",
    "for playlist_id in playlists_relevant['playlist_id']:\n",
    "    item_playlist_matrix[counter][0] = playlist_id\n",
    "    playlist_indexes[playlist_id] = counter\n",
    "    counter += 1;\n",
    "\n",
    "#felsÃ¶kning\n",
    "#print(playlists_relevant[playlists_relevant['playlist_id']==1515105])\n",
    "print(\"hej1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   7912    1376    2623 ..., 2228646 2265463       0]\n",
      " [   8268       0       0 ...,       0       0       0]\n",
      " [   8900       0       0 ...,       0       0       0]\n",
      " ..., \n",
      " [7939535       0       0 ...,       0       0       0]\n",
      " [ 297021       0       0 ...,       0       0       0]\n",
      " [1502409       0       0 ...,       0       0       0]]\n",
      "hej2\n"
     ]
    }
   ],
   "source": [
    "#Lets build that matrix. \n",
    "\n",
    "interactions = train_relevant.as_matrix()\n",
    "for row in interactions:\n",
    "    #Lets get the info\n",
    "    playlist_id = row[0]\n",
    "    track_id = row[1]\n",
    "    \n",
    "    #Now lets get the proper indexes. \n",
    "    playlist_index = playlist_indexes[playlist_id]\n",
    "    track_index = track_indexes[track_id]\n",
    "    \n",
    "    #And now lets add it to the matrix\n",
    "    item_playlist_matrix[playlist_index][track_index] = 1\n",
    "    \n",
    "\n",
    "print(item_playlist_matrix)\n",
    "print(\"hej2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#Lets just extract the subset of the matrix that does not contain ids. \n",
    "print(item_playlist_matrix[1:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23618, 41756)\n",
      "tje2\n"
     ]
    }
   ],
   "source": [
    "#Now we have a item_playlist_matrix! Nice. lets save. \n",
    "\n",
    "sparse_matrix = sps.csr_matrix(item_playlist_matrix[1:,1:])\n",
    "\n",
    "#sps.save_npz(\"sparse_item_playlist\", sparse_matrix)\n",
    "\n",
    "print(sparse_matrix.shape)\n",
    "print(\"tje2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 22915)\t1\n",
      "  (0, 22534)\t1\n",
      "  (0, 22415)\t1\n",
      "  (0, 22188)\t1\n",
      "  (0, 21644)\t1\n",
      "  (0, 21128)\t1\n",
      "  (0, 21109)\t1\n",
      "  (0, 20702)\t1\n",
      "  (0, 20290)\t1\n",
      "  (0, 20219)\t1\n",
      "  (0, 20162)\t1\n",
      "  (0, 20117)\t1\n",
      "  (0, 19755)\t1\n",
      "  (0, 19461)\t1\n",
      "  (0, 19185)\t1\n",
      "  (0, 18725)\t1\n",
      "  (0, 18162)\t1\n",
      "  (0, 17924)\t1\n",
      "  (0, 16332)\t1\n",
      "  (0, 14892)\t1\n",
      "  (0, 14586)\t1\n",
      "  (0, 14258)\t1\n",
      "  (0, 14191)\t1\n",
      "  (0, 13811)\t1\n",
      "  (0, 12855)\t1\n",
      "  :\t:\n",
      "  (23616, 3063)\t1\n",
      "  (23616, 2413)\t1\n",
      "  (23616, 1728)\t5\n",
      "  (23616, 799)\t2\n",
      "  (23616, 23616)\t80\n",
      "  (23616, 23507)\t1\n",
      "  (23616, 22621)\t1\n",
      "  (23616, 20823)\t3\n",
      "  (23616, 19421)\t1\n",
      "  (23616, 18593)\t2\n",
      "  (23616, 14495)\t1\n",
      "  (23616, 13701)\t1\n",
      "  (23616, 13015)\t3\n",
      "  (23616, 12460)\t1\n",
      "  (23616, 12003)\t1\n",
      "  (23616, 11615)\t3\n",
      "  (23616, 11220)\t4\n",
      "  (23616, 6310)\t1\n",
      "  (23616, 5075)\t6\n",
      "  (23616, 4405)\t1\n",
      "  (23616, 4118)\t1\n",
      "  (23616, 3842)\t1\n",
      "  (23616, 2388)\t2\n",
      "  (23616, 1866)\t1\n",
      "  (23616, 708)\t1\n",
      "lgt2\n"
     ]
    }
   ],
   "source": [
    "#If we multiply the matrix with its transposition, we will get an item similarity matrix. \n",
    "\n",
    "\n",
    "playlist_similarities = sparse_matrix.dot(sparse_matrix.transpose())\n",
    "print(playlist_similarities)\n",
    "print(\"lgt2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23618, 23618)\n"
     ]
    }
   ],
   "source": [
    "#Let's normalize the matrix\n",
    "#playlist_similarities = playlist_similarities.multiply(1000/playlist_similarities.max())\n",
    "print(playlist_similarities.shape)\n",
    "\n",
    "#(23619, 23619)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#Here we can get the similarities between two playlists.   \n",
    "print(np.asarray(playlist_similarities.getrow(50).todense())[0][100])\n",
    "print(np.asarray(playlist_similarities.getrow(100).todense())[0][50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def playlist_similarity(playlist_id1, playlist_id2):    \n",
    "    similarity = np.asarray(playlist_similarities.getrow(playlist_indexes[playlist_id1]).todense())[0][playlist_indexes[playlist_id2]]\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#How many tracks do we want to work with? \n",
    "tracks = popularity.sort_values(by='occurrences', ascending=False)[:100]\n",
    "#remove index name\n",
    "tracks.reset_index(level = 0, inplace = True)\n",
    "#Rename the columns\n",
    "tracks.columns = ['relevance','track_id','occurrences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1193299 2158207 1209729  853629 2609171]]\n"
     ]
    }
   ],
   "source": [
    "def recommend(target_playlist_id, tracks = []):\n",
    "    playlist_index = playlist_indexes[target_playlist_id]\n",
    "    \n",
    "    #Output vector\n",
    "    recommendations = np.zeros([1,5], int)\n",
    "    #Datastructure for relevance. \n",
    "    relevance = np.zeros([tracks.shape[0],1], float)\n",
    "    \n",
    "\n",
    "    \n",
    "    track_counter = 0\n",
    "    #For each song not in the playlist (we will start with top 100 popular)\n",
    "    tracks = tracks.as_matrix()\n",
    "    for track in tracks:\n",
    "        sum = 0\n",
    "        track_id = track[1]\n",
    "        track_index = track_indexes[track_id]\n",
    "\n",
    "        #Get all playlists containing this track. \n",
    "        playlists_with_track = (item_playlist_matrix[item_playlist_matrix.T[track_index][:]==1])\n",
    "\n",
    "        playlists_with_track = playlists_with_track[:-1, :-1]\n",
    "        \n",
    "        #for each playlist containing the song\n",
    "        for playlist in playlists_with_track:\n",
    "            playlist_id = playlist[0]\n",
    "            if(playlist_id > 1): #weird workaround... \n",
    "                sum += playlist_similarity(target_playlist_id, playlist_id)\n",
    "        relevance[track_counter] = sum/track[2]  #Normalize. track[2] is the number of playlists containing the song. \n",
    "        track_counter += 1\n",
    "\n",
    "\n",
    "        #relevance = sum/num of playlists containing the song\n",
    "    found = 0\n",
    "    while found < 5: \n",
    "        maxindex = np.argmax(relevance, axis = 0)[0]\n",
    "        #print(tracks[maxindex][1])\n",
    "        recommendations[0, found] = tracks[maxindex, 1]\n",
    "        relevance[maxindex] *= -1\n",
    "        found += 1\n",
    "        \n",
    "    #print(tracks)\n",
    "    #print(relevance)\n",
    "\n",
    "    return recommendations\n",
    "print(recommend(10024884, tracks))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Get all playlists which contain a certain track:\n",
    "playlists = (item_playlist_matrix[item_playlist_matrix.T[1666][:]==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    10624787\n",
      "2     4891851\n",
      "3     4267369\n",
      "4       65078\n",
      "Name: playlist_id, dtype: int64\n",
      "Ten recommendations took  64.15566205978394  seconds. 10000 would take  17.821017238828873  hours... \n"
     ]
    }
   ],
   "source": [
    "#How many tracks do we want to work with? \n",
    "tracks = popularity.sort_values(by='occurrences', ascending=False)[:100]\n",
    "#remove index name\n",
    "tracks.reset_index(level = 0, inplace = True)\n",
    "#Rename the columns\n",
    "tracks.columns = ['relevance','track_id','occurrences']\n",
    "\n",
    "\n",
    "###Callin Recommend function, filling it into a DataFrame. ###\n",
    "###This part should not be changed ##\n",
    "\n",
    "zeros = np.zeros((target_playlists.size, 6), dtype = int)\n",
    "\n",
    "#Create empty dataframe\n",
    "recommendations = pd.DataFrame(zeros)\n",
    "\n",
    "#Rename the first col\n",
    "recommendations.columns = ['playlist_id', 1, 2, 3, 4, 5]\n",
    "\n",
    "#recommendations.iloc[:, 0] = target_playlists['playlist_id']\n",
    "\n",
    "\n",
    "print(target_playlists[1:5]['playlist_id'])\n",
    "\n",
    "import time\n",
    "starttime = time.time()\n",
    "\n",
    "#Fill the recommendations matrix through calling the recommend-function\n",
    "counter = 0; \n",
    "for playlist_id in target_playlists[1:10]['playlist_id']:\n",
    "    #Add the playlist ids as first col\n",
    "    recommendations.iloc[counter, 0] = playlist_id\n",
    "    #print(playlist_id)\n",
    "    #Fill the recommendations to col 1-5 for each playlist\n",
    "    recommendations.iloc[counter, 1:6] = recommend(playlist_id, tracks)\n",
    "    counter += 1\n",
    "\n",
    "#print(recommendations)\n",
    "runtime = time.time()-starttime\n",
    "\n",
    "hours = 1000*runtime/3600\n",
    "\n",
    "print(\"Ten recommendations took \",runtime,\" seconds. 10000 would take \", hours, \" hours... \")\n",
    "\n",
    "def save_to_file():\n",
    "    #Saves the recommendations dataframe to the .csv-file. \n",
    "    np.savetxt(\"recommendations.csv\",recommendations, fmt = '%s,%s %s %s %s %s', header = \"playlist_id,track_ids\", newline = \"\\n\")\n",
    "    \n",
    "save_to_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_to_file():\n",
    "    #Saves the recommendations dataframe to the .csv-file. \n",
    "    np.savetxt(\"recommendations.csv\",recommendations, fmt = '%s,%s %s %s %s %s', header = \"playlist_id,track_ids\", newline = \"\\n\")\n",
    "    \n",
    "    \n",
    "def test():\n",
    "    #Do something\n",
    "    print(\"Result: \")\n",
    "    pass\n",
    "\n",
    "\n",
    "save_to_file()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
