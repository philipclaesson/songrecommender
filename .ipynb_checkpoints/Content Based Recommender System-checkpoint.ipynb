{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse as sps\n",
    "%matplotlib inline\n",
    "\n",
    "#train_final.csv - the training set of interactions\n",
    "train_final = pd.read_csv('input/train_final.csv', delimiter = \"\\t\");\n",
    "\n",
    "#tracks_final.csv - supplementary information about the items\n",
    "tracks_final = pd.read_csv('input/tracks_final.csv', delimiter = \"\\t\");\n",
    "\n",
    "#playlists_final.csv - supplementary information about the users\n",
    "playlists_final = pd.read_csv('input/playlists_final.csv', delimiter = \"\\t\");\n",
    "\n",
    "#target_playlists.csv - the set of target playlists that will receive recommendations\n",
    "target_playlists = pd.read_csv('input/target_playlists.csv');\n",
    "\n",
    "#target_tracks.csv - the set of target items (tracks) to be recommended\n",
    "target_tracks = pd.read_csv('input/target_tracks.csv');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41756, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41756, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we want to remove some redundant stuff. \n",
    "\n",
    "#We will remove all songs which are not occurring more than 10 times in train_final\n",
    "#Nevertheless, we still want to keep all tracks which are in the target tracks.  \n",
    "\n",
    "popularity = train_final.groupby(by=\"track_id\").playlist_id.nunique().to_frame()\n",
    "\n",
    "#remove index name\n",
    "popularity.reset_index(level = 0, inplace = True)\n",
    "\n",
    "#Rename the columns\n",
    "popularity.columns = ['track_id','occurrences']\n",
    "\n",
    "#Remove all targeted tracks - TESTED, working as expected\n",
    "tracks_relevant = popularity[~popularity['track_id'].isin(target_tracks['track_id'])]\n",
    "\n",
    "#Remove tracks occurring less than 10 times\n",
    "tracks_relevant = tracks_relevant[tracks_relevant['occurrences'] > 10]\n",
    "\n",
    "#Add the targeteted tracks back again\n",
    "tracks_relevant = pd.concat([tracks_relevant, target_tracks])\n",
    "\n",
    "tracks_relevant.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>duration</th>\n",
       "      <th>playcount</th>\n",
       "      <th>album</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2972914</td>\n",
       "      <td>144</td>\n",
       "      <td>224000</td>\n",
       "      <td>49.0</td>\n",
       "      <td>[7]</td>\n",
       "      <td>[54087, 1757, 1718, 116712, 189631]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2750239</td>\n",
       "      <td>246</td>\n",
       "      <td>157000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[8]</td>\n",
       "      <td>[189631, 3424, 177424, 46208, 205245]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1550729</td>\n",
       "      <td>144</td>\n",
       "      <td>217000</td>\n",
       "      <td>554.0</td>\n",
       "      <td>[9]</td>\n",
       "      <td>[54087, 109806, 46869, 183258, 54337]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2169950</td>\n",
       "      <td>144</td>\n",
       "      <td>207000</td>\n",
       "      <td>200.0</td>\n",
       "      <td>[9]</td>\n",
       "      <td>[54087, 70618, 207003, 109806, 116712]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1903709</td>\n",
       "      <td>144</td>\n",
       "      <td>198000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[54087, 81223, 116712, 215342, 71028]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   track_id  artist_id  duration  playcount   album  \\\n",
       "0   2972914        144    224000       49.0     [7]   \n",
       "1   2750239        246    157000        1.0     [8]   \n",
       "2   1550729        144    217000      554.0     [9]   \n",
       "3   2169950        144    207000      200.0     [9]   \n",
       "4   1903709        144    198000        5.0  [None]   \n",
       "\n",
       "                                     tags  \n",
       "0     [54087, 1757, 1718, 116712, 189631]  \n",
       "1   [189631, 3424, 177424, 46208, 205245]  \n",
       "2   [54087, 109806, 46869, 183258, 54337]  \n",
       "3  [54087, 70618, 207003, 109806, 116712]  \n",
       "4   [54087, 81223, 116712, 215342, 71028]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now lets take a look at the tags.\n",
    "tracks_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31900\n"
     ]
    }
   ],
   "source": [
    "#Lets translate the tags to indexes. \n",
    "tracks_final['tags'].head()\n",
    "\n",
    "\n",
    "tags_indexes = {}\n",
    "counter = 1; #We will start at 1, reserving col 0 for indexes. \n",
    "for row in tracks_final['tags']:\n",
    "    tags = row.strip('[ ]').split(', ')\n",
    "    for tag in tags:\n",
    "        if len(tag) > 0: \n",
    "            tag = int(tag)\n",
    "            if not(tag in tags_indexes):\n",
    "                tags_indexes[tag] = counter #Lets make it int to make it easier\n",
    "                counter += 1;\n",
    "\n",
    "print(len(tags_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 41756 unique tracks with 31900 unique tags\n"
     ]
    }
   ],
   "source": [
    "#If we translate each track_id to a track_index which will serve as matrix index, we can save a lot of time. \n",
    "\n",
    "\n",
    "#We need a way to get from track_id to index in O(1).\n",
    "#Let's create a dictionary\n",
    "\n",
    "tracks_indexes = {}\n",
    "index_to_item = {}\n",
    "counter = 1; #We will start at 1, reserving col 0 for indexes.  \n",
    "for track_id in tracks_relevant['track_id']:\n",
    "    tracks_indexes[track_id] = counter\n",
    "    counter += 1;\n",
    "    \n",
    "    \n",
    "print(\"We have {} unique tracks with {} unique tags\".format(len(tracks_indexes), len(tags_indexes)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41757, 31901)\n"
     ]
    }
   ],
   "source": [
    "#Now we can create an Item Content Matrix. \n",
    "\n",
    "ICM_all = np.zeros((len(tracks_indexes)+1, len(tags_indexes)+1), int)\n",
    "print(ICM_all.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   occurrences  track_id  artist_id  duration  playcount     album  \\\n",
      "0         18.0       360     169649    194000      522.0   [77662]   \n",
      "1         11.0      1376     381303    270000      629.0  [180587]   \n",
      "2         12.0      2623      36019    329000     7081.0   [17295]   \n",
      "3         15.0      2891     310373    194000      196.0  [142650]   \n",
      "4         14.0      2901     163720    293000      322.0   [74384]   \n",
      "\n",
      "                                      tags  \n",
      "0      [70618, 70251, 70625, 25307, 11056]  \n",
      "1  [205245, 254105, 11056, 209598, 189631]  \n",
      "2    [122769, 23214, 48976, 117167, 90254]  \n",
      "3     [189631, 54087, 70618, 94794, 61837]  \n",
      "4     [193464, 205245, 46208, 92324, 3982]  \n"
     ]
    }
   ],
   "source": [
    "#tracks_relevant.reset_index(level = 0, inplace = True)\n",
    "\n",
    "tracks = pd.merge(tracks_relevant, tracks_final, how='inner', on='track_id')\n",
    "\n",
    "print(tracks.head())\n",
    "\n",
    "tracks = tracks.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[      0   54087    1757 ...,   87957  275594  276430]\n",
      " [    360       0       0 ...,       0       0       0]\n",
      " [   1376       0       0 ...,       0       0       0]\n",
      " ..., \n",
      " [2739213       0       0 ...,       0       0       0]\n",
      " [2228646       0       0 ...,       0       0       0]\n",
      " [2265463       0       0 ...,       0       0       0]]\n"
     ]
    }
   ],
   "source": [
    "counter = 1\n",
    "for tag in tags_indexes:\n",
    "    ICM_all[0,counter] = tag\n",
    "    counter += 1\n",
    "    \n",
    "counter = 1\n",
    "for track_id in tracks_indexes: \n",
    "    ICM_all[counter, 0] = track_id\n",
    "    counter += 1\n",
    "    \n",
    "print(ICM_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-0ce85b3cc2f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[ ]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m', '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mtag_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtags_indexes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mtrack_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtracks_indexes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrack_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mICM_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrack_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtag_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "#We will put the track_id/tag in the [0]-column.\n",
    "\n",
    "#So let's fill it with our data.\n",
    "\n",
    "\n",
    "for row in tracks: \n",
    "    track_id = row[1]\n",
    "    tags = row[6].strip('[ ]').split(', ')\n",
    "    for tag in tags:\n",
    "        if tag == '': \n",
    "            print(row)\n",
    "        tag_index = tags_indexes[int(tag)]\n",
    "        track_index = tracks_indexes[track_id]\n",
    "        ICM_all[track_index,tag_index] = 1\n",
    "        #print(\"Added tag {} to track {}\".format(tag, track_id))\n",
    "            \n",
    "\n",
    "print(ICM_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ICM_all_sparse = sps.csc_matrix(ICM_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<41757x31901 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 74121 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ICM_all_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41757, 1)\n",
      "(1, 31901)\n"
     ]
    }
   ],
   "source": [
    "#Lets take a look at the data. \n",
    "\n",
    "features_per_item = (ICM_all_sparse > 0).sum(axis=1)\n",
    "items_per_feature = (ICM_all_sparse > 0).sum(axis=0)\n",
    "\n",
    "features_per_item = np.sort(features_per_item)\n",
    "items_per_feature = np.sort(items_per_feature)\n",
    "\n",
    "print(features_per_item.shape)\n",
    "print(items_per_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Let's Split the Data and create evluation functions. \n",
    "\n",
    "train_test_split = 0.80\n",
    "\n",
    "numInteractions = URM_all.nnz\n",
    "\n",
    "\n",
    "train_mask = np.random.choice([True,False], numInteractions, [train_test_split, 1-train_test_split])\n",
    "\n",
    "userList = np.array(userList)\n",
    "itemList = np.array(itemList)\n",
    "ratingList = np.array(ratingList)\n",
    "\n",
    "\n",
    "URM_train = sps.coo_matrix((ratingList[train_mask], (userList[train_mask], itemList[train_mask])))\n",
    "URM_train = URM_train.tocsr()\n",
    "\n",
    "test_mask = np.logical_not(train_mask)\n",
    "\n",
    "URM_test = sps.coo_matrix((ratingList[test_mask], (userList[test_mask], itemList[test_mask])))\n",
    "URM_test = URM_test.tocsr()\n",
    "\n",
    "def precision(recommended_items, relevant_items):\n",
    "    \n",
    "    is_relevant = np.in1d(recommended_items, relevant_items, assume_unique=True)\n",
    "    \n",
    "    precision_score = np.sum(is_relevant, dtype=np.float32) / len(is_relevant)\n",
    "    \n",
    "    return precision_score\n",
    "\n",
    "def recall(recommended_items, relevant_items):\n",
    "    \n",
    "    is_relevant = np.in1d(recommended_items, relevant_items, assume_unique=True)\n",
    "    \n",
    "    recall_score = np.sum(is_relevant, dtype=np.float32) / relevant_items.shape[0]\n",
    "    \n",
    "    return recall_score\n",
    "\n",
    "def MAP(recommended_items, relevant_items):\n",
    "   \n",
    "    is_relevant = np.in1d(recommended_items, relevant_items, assume_unique=True)\n",
    "    \n",
    "    # Cumulative sum: precision at 1, at 2, at 3 ...\n",
    "    p_at_k = is_relevant * np.cumsum(is_relevant, dtype=np.float32) / (1 + np.arange(is_relevant.shape[0]))\n",
    "    \n",
    "    map_score = np.sum(p_at_k) / np.min([relevant_items.shape[0], is_relevant.shape[0]])\n",
    "\n",
    "    return map_score\n",
    "\n",
    "def evaluate_algorithm(URM_test, recommender_object, at=5):\n",
    "    \n",
    "    cumulative_precision = 0.0\n",
    "    cumulative_recall = 0.0\n",
    "    cumulative_MAP = 0.0\n",
    "    \n",
    "    num_eval = 0\n",
    "\n",
    "\n",
    "    for i,user_id in  enumerate(userList_unique):\n",
    "        \n",
    "        if i % 500 == 0:\n",
    "            print(\"User %d of %d\" % (i, len(userList_unique)))\n",
    "\n",
    "        relevant_items = URM_test[user_id].indices\n",
    "        \n",
    "        if len(relevant_items)>0:\n",
    "            \n",
    "            recommended_items = recommender_object.recommend(user_id, at=at)\n",
    "            num_eval+=1\n",
    "\n",
    "            cumulative_precision += precision(recommended_items, relevant_items)\n",
    "            cumulative_recall += recall(recommended_items, relevant_items)\n",
    "            cumulative_MAP += MAP(recommended_items, relevant_items)\n",
    "\n",
    "\n",
    "    cumulative_precision /= num_eval\n",
    "    cumulative_recall /= num_eval\n",
    "    cumulative_MAP /= num_eval\n",
    "    \n",
    "    print(\"Recommender performance is: Precision = {:.4f}, Recall = {:.4f}, MAP = {:.4f}\".format(\n",
    "        cumulative_precision, cumulative_recall, cumulative_MAP))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
