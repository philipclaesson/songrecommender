{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playlist_id</th>\n",
       "      <th>track_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3271849</td>\n",
       "      <td>2801526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5616275</td>\n",
       "      <td>727878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11267488</td>\n",
       "      <td>2805283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10103900</td>\n",
       "      <td>1515105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3836898</td>\n",
       "      <td>2945623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   playlist_id  track_id\n",
       "0      3271849   2801526\n",
       "1      5616275    727878\n",
       "2     11267488   2805283\n",
       "3     10103900   1515105\n",
       "4      3836898   2945623"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse as sps\n",
    "%matplotlib inline\n",
    "\n",
    "#train_final.csv - the training set of interactions\n",
    "train_final = pd.read_csv('input/train_final.csv', delimiter = \"\\t\");\n",
    "\n",
    "#tracks_final.csv - supplementary information about the items\n",
    "tracks_final = pd.read_csv('input/tracks_final.csv', delimiter = \"\\t\");\n",
    "\n",
    "#playlists_final.csv - supplementary information about the users\n",
    "playlists_final = pd.read_csv('input/playlists_final.csv', delimiter = \"\\t\");\n",
    "\n",
    "#target_playlists.csv - the set of target playlists that will receive recommendations\n",
    "target_playlists = pd.read_csv('input/target_playlists.csv');\n",
    "\n",
    "#target_tracks.csv - the set of target items (tracks) to be recommended\n",
    "target_tracks = pd.read_csv('input/target_tracks.csv');\n",
    "\n",
    "#Let's have a look at the train data. \n",
    "train_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41756, 2)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we need to remove some redundant stuff. \n",
    "\n",
    "#We will remove all song which are not: 1. occurring more than 10 times in train_final and 2. not in the target_tracks. \n",
    "\n",
    "popularity = train_final.groupby(by=\"track_id\").playlist_id.nunique().to_frame()\n",
    "\n",
    "#remove index name\n",
    "popularity.reset_index(level = 0, inplace = True)\n",
    "\n",
    "#Rename the columns\n",
    "popularity.columns = ['track_id','occurrences']\n",
    "\n",
    "#Remove all targeted tracks - TESTED, working as expected\n",
    "tracks_relevant = popularity[~popularity['track_id'].isin(target_tracks['track_id'])]\n",
    "\n",
    "#Remove tracks occurring less than 10 times\n",
    "tracks_relevant = tracks_relevant[tracks_relevant['occurrences'] > 10]\n",
    "\n",
    "#Add the targeteted tracks back again\n",
    "tracks_relevant = pd.concat([tracks_relevant, target_tracks])\n",
    "\n",
    "tracks_relevant.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45649, 2)\n",
      "(23618, 2)\n"
     ]
    }
   ],
   "source": [
    "#We will remove all playlists which are not: 1. containing more than 5 tracks and 2. not in the target_playlists.\n",
    "\n",
    "playlists_sizes = train_final.groupby(by=\"playlist_id\").track_id.nunique().to_frame()\n",
    "\n",
    "#remove index name\n",
    "playlists_sizes.reset_index(level = 0, inplace = True)\n",
    "\n",
    "#Rename the columns\n",
    "playlists_sizes.columns = ['playlist_id','size']\n",
    "\n",
    "print(playlists_sizes.shape)\n",
    "\n",
    "#Remove all targeted playlists TESTED works\n",
    "playlists_relevant = playlists_sizes[~playlists_sizes['playlist_id'].isin(target_playlists['playlist_id'])]\n",
    "\n",
    "#Remove playlists of size less than 10\n",
    "playlists_relevant = playlists_relevant[playlists_relevant['size'] > 10]\n",
    "\n",
    "#Add the targeteted playlists back again\n",
    "playlists_relevant = pd.concat([playlists_relevant, target_playlists])\n",
    "\n",
    "print(playlists_relevant.shape)\n",
    "\n",
    "\n",
    "#WORKING! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1040522, 2)\n",
      "(731373, 2)\n",
      "(667033, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/philipclaesson/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "#Now we have to create a set of the relevant train data. \n",
    "\n",
    "\n",
    "print(train_final.shape)\n",
    "\n",
    "train_relevant = train_final[train_final['track_id'].isin(tracks_relevant['track_id'])]\n",
    "\n",
    "print(train_relevant.shape)\n",
    "\n",
    "train_relevant = train_relevant[train_final['playlist_id'].isin(playlists_relevant['playlist_id'])]\n",
    "\n",
    "print(train_relevant.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item_playlist_matrix = np.zeros([playlists_relevant.shape[0], tracks_relevant.shape[0]],int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "986193208"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Very large matrix filled with zeros.\n",
    "#Old size before removing used to be 5.756.100.000\n",
    "#New size: 986.193.208\n",
    "item_playlist_matrix.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hej1\n"
     ]
    }
   ],
   "source": [
    "#If we translate each track_id to a track_index which will serve as matrix index, we can save a lot of time. \n",
    "#Same goes for playlist_id --> playlist_index. \n",
    "\n",
    "\n",
    "#We need a way to get from track_id to index in O(1).\n",
    "#Let's create a dictionary\n",
    "\n",
    "track_indexes = {}\n",
    "index_to_item = {}\n",
    "counter = 0; \n",
    "for track_id in tracks_relevant['track_id']:\n",
    "    item_playlist_matrix[0][counter] = track_id\n",
    "    track_indexes[track_id] = counter\n",
    "    counter += 1;\n",
    "    \n",
    "#and a way to get from playlist_id to index in O(1)\n",
    "\n",
    "\n",
    "playlist_indexes = {}\n",
    "index_to_playlist = {}\n",
    "counter = 0; \n",
    "for playlist_id in playlists_relevant['playlist_id']:\n",
    "    item_playlist_matrix[counter][0] = playlist_id\n",
    "    playlist_indexes[playlist_id] = counter\n",
    "    counter += 1;\n",
    "\n",
    "#felsÃ¶kning\n",
    "#print(playlists_relevant[playlists_relevant['playlist_id']==1515105])\n",
    "print(\"hej1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    7912     1376     2623 ...,  2739213  2228646  2265463]\n",
      " [    8268        0        0 ...,        0        0        0]\n",
      " [    8900        0        0 ...,        0        0        0]\n",
      " ..., \n",
      " [11369546        0        0 ...,        0        0        0]\n",
      " [ 7939535        0        0 ...,        0        0        0]\n",
      " [  297021        0        0 ...,        0        0        0]]\n",
      "hej1\n"
     ]
    }
   ],
   "source": [
    "#Lets build that matrix. \n",
    "\n",
    "interactions = train_relevant.as_matrix()\n",
    "for row in interactions:\n",
    "    #Lets get the info\n",
    "    playlist_id = row[0]\n",
    "    track_id = row[1]\n",
    "    \n",
    "    #Now lets get the proper indexes. \n",
    "    playlist_index = playlist_indexes[playlist_id]\n",
    "    track_index = track_indexes[track_id]\n",
    "    \n",
    "    #And now lets add it to the matrix\n",
    "    item_playlist_matrix[playlist_index][track_index] = 1\n",
    "    \n",
    "\n",
    "print(item_playlist_matrix)\n",
    "print(\"hej1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#Lets just extract the subset of the matrix that does not contain ids. \n",
    "print(item_playlist_matrix[1:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23617, 41755)\n",
      "tje2\n"
     ]
    }
   ],
   "source": [
    "#Now we have a item_playlist_matrix! Nice. lets save. \n",
    "\n",
    "sparse_matrix = sps.csr_matrix(item_playlist_matrix[1:,1:])\n",
    "\n",
    "#sps.save_npz(\"sparse_item_playlist\", sparse_matrix)\n",
    "\n",
    "print(sparse_matrix.shape)\n",
    "print(\"tje2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23617, 23617)\n",
      "lgt2\n"
     ]
    }
   ],
   "source": [
    "#If we multiply the matrix with its transposition, we will get an item similarity matrix. \n",
    "\n",
    "playlist_similarities = sparse_matrix.dot(sparse_matrix.transpose())\n",
    "print(playlist_similarities.shape)\n",
    "print(\"lgt2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23617, 23617)\n"
     ]
    }
   ],
   "source": [
    "print(playlist_similarities.shape)\n",
    "\n",
    "#(23619, 23619)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#This way we can get the similarities between two playlists.   \n",
    "print(np.asarray(playlist_similarities.getrow(50).todense())[0][100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def playlist_similarity(playlist_id1, playlist_id2):   \n",
    "    #Takes two playlist ids, returns their similarity as integer.\n",
    "    similarity = np.asarray(playlist_similarities.getrow(playlist_indexes[playlist_id1]).todense())[0][playlist_indexes[playlist_id2]]\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    relevance  track_id  occurrences\n",
      "0       38111   1563309          476\n",
      "1       33725   1363985          432\n",
      "2       94748   3705881          425\n",
      "3       38860   1595978          403\n",
      "4       82528   3166665          391\n",
      "5       96651   3779477          390\n",
      "6        5020    204966          387\n",
      "7       73719   2863395          370\n",
      "8       38517   1580480          349\n",
      "9       28189   1156143          346\n",
      "10      32541   1321053          339\n",
      "11       5167    209196          330\n",
      "12      17830    675104          324\n",
      "13      97203   3796108          317\n",
      "14       6847    276186          315\n",
      "15      25754   1074579          307\n",
      "16      31886   1286763          306\n",
      "17      92927   3628787          306\n",
      "18      58901   2339150          306\n",
      "19      36483   1495432          304\n",
      "20      98457   3862221          301\n",
      "21      68598   2730084          300\n",
      "22      63653   2547173          294\n",
      "23      73023   2840855          294\n",
      "24      65417   2609171          294\n",
      "25      99687   4733003          293\n",
      "26      77450   2981369          292\n",
      "27      89689   3498036          291\n",
      "28      22598    889547          281\n",
      "29      29880   1210884          281\n",
      "30      77065   2967714          280\n",
      "31      97135   3794036          276\n",
      "32      84199   3242142          275\n",
      "33      50893   2032052          275\n",
      "34       9364    363983          273\n",
      "35      53940   2158207          272\n",
      "36      19568    723392          272\n",
      "37      71118   2802723          270\n",
      "38      98541   3866410          267\n",
      "39      21091    840796          265\n",
      "40      73825   2866388          262\n",
      "41      83156   3197875          259\n",
      "42      60611   2419222          257\n",
      "43      22748    897771          254\n",
      "44      41639   1705891          254\n",
      "45      13339    497483          252\n",
      "46      13946    516664          250\n",
      "47       4217    183353          250\n",
      "48      47030   1896558          248\n",
      "49      22919    905773          248\n"
     ]
    }
   ],
   "source": [
    "#How many tracks do we want to work with? \n",
    "tracks = popularity.sort_values(by='occurrences', ascending=False)[:50]\n",
    "#remove index name\n",
    "tracks.reset_index(level = 0, inplace = True)\n",
    "#Rename the columns\n",
    "tracks.columns = ['relevance','track_id','occurrences']\n",
    "\n",
    "\n",
    "#print(tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1193299 2158207 1209729  853629 2609171]]\n"
     ]
    }
   ],
   "source": [
    "def recommend(target_playlist_id, tracks):\n",
    "    playlist_index = playlist_indexes[target_playlist_id]\n",
    "    \n",
    "    import time\n",
    "    \n",
    "    \n",
    "    #Output vector\n",
    "    recommendations = np.zeros([1,5], int)\n",
    "    #Datastructure for relevance. \n",
    "    relevance = np.zeros([tracks.shape[0],1], float)\n",
    "    \n",
    "    timea = time.time()\n",
    "    \n",
    "    track_counter = 0\n",
    "    #For each song not in the playlist (we will start with top 100 popular)\n",
    "    tracks = tracks.as_matrix()\n",
    "    for track in tracks:\n",
    "        sum = 0\n",
    "        track_id = track[1]\n",
    "        track_index = track_indexes[track_id]\n",
    "\n",
    "        #Get all playlists containing this track. \n",
    "        playlists_with_track = (item_playlist_matrix[item_playlist_matrix.T[track_index][:]==1])\n",
    "\n",
    "        #playlists_with_track = playlists_with_track[:-1, :-1]\n",
    "        \n",
    "        #for each playlist containing the song\n",
    "        for playlist in playlists_with_track:\n",
    "            playlist_id = playlist[0]\n",
    "            if(playlist_id > 1): #weird workaround... \n",
    "                sum += playlist_similarity(target_playlist_id, playlist_id)\n",
    "        \n",
    "        relevance[track_counter] = sum/track[2]  #Normalize. track[2] is the number of playlists containing the song. \n",
    "        track_counter += 1\n",
    "    \n",
    "        #relevance = sum/num of playlists containing the song\n",
    "    found = 0\n",
    "    while found < 5: \n",
    "        maxindex = np.argmax(relevance, axis = 0)[0]\n",
    "        #print(tracks[maxindex][1])\n",
    "        recommendations[0, found] = tracks[maxindex, 1]\n",
    "        relevance[maxindex] *= -1\n",
    "        found += 1\n",
    "    \n",
    "    #print(tracks)\n",
    "    #print(relevance)\n",
    "    \n",
    "    return recommendations\n",
    "print(recommend(10024884, tracks))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Get all playlists which contain a certain track:\n",
    "playlists = (item_playlist_matrix[item_playlist_matrix.T[1666][:]==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 min since start time.  9998  playlists to go. ETA:  666  minutes\n",
      "0 min since start time.  9996  playlists to go. ETA:  681  minutes\n",
      "0 min since start time.  9994  playlists to go. ETA:  674  minutes\n",
      "1 min since start time.  9992  playlists to go. ETA:  666  minutes\n",
      "Ten recommendations took  35.826850175857544  seconds. 10000 would take  9.951902826627096  hours... \n"
     ]
    }
   ],
   "source": [
    "###Callin Recommend function, filling it into a DataFrame. ###\n",
    "###This part should not be changed ##\n",
    "\n",
    "zeros = np.zeros((target_playlists.size, 6), dtype = int)\n",
    "\n",
    "#Create empty dataframe\n",
    "recommendations = pd.DataFrame(zeros)\n",
    "\n",
    "#Rename the first col\n",
    "recommendations.columns = ['playlist_id', 1, 2, 3, 4, 5]\n",
    "\n",
    "#recommendations.iloc[:, 0] = target_playlists['playlist_id']\n",
    "\n",
    "\n",
    "#print(target_playlists[1:5]['playlist_id'])\n",
    "\n",
    "import time\n",
    "starttime = time.time()\n",
    "#print(time.time()-starttime, \"since start\")\n",
    "#Fill the recommendations matrix through calling the recommend-function\n",
    "counter = 0; \n",
    "#print(time.time()-starttime, \"since start time. \",10000-counter,\" playlists to go. Progress: \", counter/10000)\n",
    "\n",
    "for playlist_id in target_playlists['playlist_id']:\n",
    "    #Add the playlist ids as first col\n",
    "    recommendations.iloc[counter, 0] = playlist_id\n",
    "    #print(playlist_id)\n",
    "    #Fill the recommendations to col 1-5 for each playlist\n",
    "    recommendations.iloc[counter, 1:6] = recommend(playlist_id, tracks)\n",
    "    counter += 1\n",
    "    if counter%250 == 0: \n",
    "        runtime = time.time()-starttime\n",
    "        print(round((time.time()-starttime)/60) , \"min since start time. \",10000-counter,\" playlists to go. ETA: \", round(runtime/(1-(10000-counter)/10000)/60),\" minutes\")\n",
    "\n",
    "#print(recommendations)\n",
    "runtime = time.time()-starttime\n",
    "\n",
    "hours = 1000*runtime/3600\n",
    "\n",
    "print(\"Ten recommendations took \",runtime,\" seconds. 10000 would take \", hours, \" hours... \")\n",
    "\n",
    "def save_to_file():\n",
    "    #Saves the recommendations dataframe to the .csv-file. \n",
    "    np.savetxt(\"recommendations.csv\",recommendations, fmt = '%s,%s %s %s %s %s', header = \"playlist_id,track_ids\", newline = \"\\n\")\n",
    "    \n",
    "save_to_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_to_file():\n",
    "    #Saves the recommendations dataframe to the .csv-file. \n",
    "    np.savetxt(\"recommendations.csv\",recommendations, fmt = '%s,%s %s %s %s %s', header = \"playlist_id,track_ids\", newline = \"\\n\")\n",
    "    \n",
    "    \n",
    "def test():\n",
    "    #Do something\n",
    "    print(\"Result: \")\n",
    "    pass\n",
    "\n",
    "\n",
    "save_to_file()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
