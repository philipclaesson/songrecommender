{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playlist_id</th>\n",
       "      <th>track_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3271849</td>\n",
       "      <td>2801526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5616275</td>\n",
       "      <td>727878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11267488</td>\n",
       "      <td>2805283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10103900</td>\n",
       "      <td>1515105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3836898</td>\n",
       "      <td>2945623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   playlist_id  track_id\n",
       "0      3271849   2801526\n",
       "1      5616275    727878\n",
       "2     11267488   2805283\n",
       "3     10103900   1515105\n",
       "4      3836898   2945623"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse as sps\n",
    "%matplotlib inline\n",
    "\n",
    "#train_final.csv - the training set of interactions\n",
    "train_final = pd.read_csv('input/train_final.csv', delimiter = \"\\t\");\n",
    "\n",
    "#tracks_final.csv - supplementary information about the items\n",
    "tracks_final = pd.read_csv('input/tracks_final.csv', delimiter = \"\\t\");\n",
    "\n",
    "#playlists_final.csv - supplementary information about the users\n",
    "playlists_final = pd.read_csv('input/playlists_final.csv', delimiter = \"\\t\");\n",
    "\n",
    "#target_playlists.csv - the set of target playlists that will receive recommendations\n",
    "target_playlists = pd.read_csv('input/target_playlists.csv');\n",
    "\n",
    "#target_tracks.csv - the set of target items (tracks) to be recommended\n",
    "target_tracks = pd.read_csv('input/target_tracks.csv');\n",
    "\n",
    "#Let's have a look at the train data. \n",
    "train_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41756, 2)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we need to remove some redundant stuff. \n",
    "\n",
    "#We will remove all song which are not: 1. occurring more than 10 times in train_final and 2. not in the target_tracks. \n",
    "\n",
    "popularity = train_final.groupby(by=\"track_id\").playlist_id.nunique().to_frame()\n",
    "\n",
    "#remove index name\n",
    "popularity.reset_index(level = 0, inplace = True)\n",
    "\n",
    "#Rename the columns\n",
    "popularity.columns = ['track_id','occurrences']\n",
    "\n",
    "#Remove all targeted tracks - TESTED, working as expected\n",
    "tracks_relevant = popularity[~popularity['track_id'].isin(target_tracks['track_id'])]\n",
    "\n",
    "#Remove tracks occurring less than 10 times\n",
    "tracks_relevant = tracks_relevant[tracks_relevant['occurrences'] > 10]\n",
    "\n",
    "#Add the targeteted tracks back again\n",
    "tracks_relevant = pd.concat([tracks_relevant, target_tracks])\n",
    "\n",
    "tracks_relevant.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45649, 2)\n",
      "(23618, 2)\n"
     ]
    }
   ],
   "source": [
    "#We will remove all playlists which are not: 1. containing more than 5 tracks and 2. not in the target_playlists.\n",
    "\n",
    "playlists_sizes = train_final.groupby(by=\"playlist_id\").track_id.nunique().to_frame()\n",
    "\n",
    "#remove index name\n",
    "playlists_sizes.reset_index(level = 0, inplace = True)\n",
    "\n",
    "#Rename the columns\n",
    "playlists_sizes.columns = ['playlist_id','size']\n",
    "\n",
    "print(playlists_sizes.shape)\n",
    "\n",
    "#Remove all targeted playlists TESTED works\n",
    "playlists_relevant = playlists_sizes[~playlists_sizes['playlist_id'].isin(target_playlists['playlist_id'])]\n",
    "\n",
    "#Remove playlists of size less than 10\n",
    "playlists_relevant = playlists_relevant[playlists_relevant['size'] > 10]\n",
    "\n",
    "#Add the targeteted playlists back again\n",
    "playlists_relevant = pd.concat([playlists_relevant, target_playlists])\n",
    "\n",
    "print(playlists_relevant.shape)\n",
    "\n",
    "\n",
    "#WORKING! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1040522, 2)\n",
      "(731373, 2)\n",
      "(667033, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/philipclaesson/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "#Now we have to create a set of the relevant train data. \n",
    "\n",
    "\n",
    "print(train_final.shape)\n",
    "\n",
    "train_relevant = train_final[train_final['track_id'].isin(tracks_relevant['track_id'])]\n",
    "\n",
    "print(train_relevant.shape)\n",
    "\n",
    "train_relevant = train_relevant[train_final['playlist_id'].isin(playlists_relevant['playlist_id'])]\n",
    "\n",
    "print(train_relevant.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item_playlist_matrix = np.zeros([playlists_relevant.shape[0], tracks_relevant.shape[0]],int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "986193208"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Very large matrix filled with zeros.\n",
    "#Old size before removing used to be 5.756.100.000\n",
    "#New size: 986.193.208\n",
    "item_playlist_matrix.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hej1\n"
     ]
    }
   ],
   "source": [
    "#If we translate each track_id to a track_index which will serve as matrix index, we can save a lot of time. \n",
    "#Same goes for playlist_id --> playlist_index. \n",
    "\n",
    "\n",
    "#We need a way to get from track_id to index in O(1).\n",
    "#Let's create a dictionary\n",
    "\n",
    "track_indexes = {}\n",
    "index_to_item = {}\n",
    "counter = 0; \n",
    "for track_id in tracks_relevant['track_id']:\n",
    "    item_playlist_matrix[0][counter] = track_id\n",
    "    track_indexes[track_id] = counter\n",
    "    counter += 1;\n",
    "    \n",
    "#and a way to get from playlist_id to index in O(1)\n",
    "\n",
    "\n",
    "playlist_indexes = {}\n",
    "index_to_playlist = {}\n",
    "counter = 0; \n",
    "for playlist_id in playlists_relevant['playlist_id']:\n",
    "    item_playlist_matrix[counter][0] = playlist_id\n",
    "    playlist_indexes[playlist_id] = counter\n",
    "    counter += 1;\n",
    "\n",
    "#fels√∂kning\n",
    "#print(playlists_relevant[playlists_relevant['playlist_id']==1515105])\n",
    "print(\"hej1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    7912     1376     2623 ...,  2739213  2228646  2265463]\n",
      " [    8268        0        0 ...,        0        0        0]\n",
      " [    8900        0        0 ...,        0        0        0]\n",
      " ..., \n",
      " [11369546        0        0 ...,        0        0        0]\n",
      " [ 7939535        0        0 ...,        0        0        0]\n",
      " [  297021        0        0 ...,        0        0        0]]\n",
      "hej1\n"
     ]
    }
   ],
   "source": [
    "#Lets build that matrix. \n",
    "\n",
    "interactions = train_relevant.as_matrix()\n",
    "for row in interactions:\n",
    "    #Lets get the info\n",
    "    playlist_id = row[0]\n",
    "    track_id = row[1]\n",
    "    \n",
    "    #Now lets get the proper indexes. \n",
    "    playlist_index = playlist_indexes[playlist_id]\n",
    "    track_index = track_indexes[track_id]\n",
    "    \n",
    "    #And now lets add it to the matrix\n",
    "    item_playlist_matrix[playlist_index][track_index] = 1\n",
    "    \n",
    "\n",
    "print(item_playlist_matrix)\n",
    "print(\"hej1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#Lets just extract the subset of the matrix that does not contain ids. \n",
    "print(item_playlist_matrix[1:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23617, 41755)\n",
      "tje2\n"
     ]
    }
   ],
   "source": [
    "#Now we have a item_playlist_matrix! Nice. lets save. \n",
    "\n",
    "sparse_matrix = sps.csr_matrix(item_playlist_matrix[1:,1:])\n",
    "\n",
    "#sps.save_npz(\"sparse_item_playlist\", sparse_matrix)\n",
    "\n",
    "print(sparse_matrix.shape)\n",
    "print(\"tje2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23617, 23617)\n",
      "lgt2\n"
     ]
    }
   ],
   "source": [
    "#If we multiply the matrix with its transposition, we will get an item similarity matrix. \n",
    "\n",
    "playlist_similarities = sparse_matrix.dot(sparse_matrix.transpose())\n",
    "print(playlist_similarities.shape)\n",
    "print(\"lgt2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23617, 23617)\n"
     ]
    }
   ],
   "source": [
    "print(playlist_similarities.shape)\n",
    "\n",
    "#(23619, 23619)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#This way we can get the similarities between two playlists.   \n",
    "print(np.asarray(playlist_similarities.getrow(50).todense())[0][100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def playlist_similarity(playlist_id1, playlist_id2):   \n",
    "    #Takes two playlist ids, returns their similarity as integer.\n",
    "    similarity = np.asarray(playlist_similarities.getrow(playlist_indexes[playlist_id1]).todense())[0][playlist_indexes[playlist_id2]]\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'popularity' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bc170bd25fb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#How many tracks do we want to work with?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtracks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpopularity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'occurrences'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#remove index name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtracks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#Rename the columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'popularity' is not defined"
     ]
    }
   ],
   "source": [
    "#How many tracks do we want to work with? \n",
    "tracks = popularity.sort_values(by='occurrences', ascending=False)\n",
    "#remove index name\n",
    "tracks.reset_index(level = 0, inplace = True)\n",
    "#Rename the columns\n",
    "tracks.columns = ['relevance','track_id','occurrences']\n",
    "\n",
    "print(tracks.shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1193299 2158207 1209729  853629 2609171]]\n"
     ]
    }
   ],
   "source": [
    "def recommend(target_playlist_id, tracks):\n",
    "    playlist_index = playlist_indexes[target_playlist_id]\n",
    "    \n",
    "    import time\n",
    "    \n",
    "    \n",
    "    #Output vector\n",
    "    recommendations = np.zeros([1,5], int)\n",
    "    \n",
    "    #Datastructure for relevance. \n",
    "    relevance = np.zeros([tracks.shape[0],1], float)\n",
    "    \n",
    "    #timing\n",
    "    timea = time.time()\n",
    "    \n",
    "    track_counter = 0\n",
    "    \n",
    "    #\n",
    "    \n",
    "    for track in tracks:\n",
    "        sum = 0\n",
    "        track_id = track[1]\n",
    "        track_index = track_indexes[track_id]\n",
    "\n",
    "        #Get all playlists containing this track. \n",
    "        playlists_with_track = (item_playlist_matrix[item_playlist_matrix.T[track_index][:]==1])\n",
    "\n",
    "        #playlists_with_track = playlists_with_track[:-1, :-1]\n",
    "        \n",
    "        #for each playlist containing the song\n",
    "        for playlist in playlists_with_track:\n",
    "            playlist_id = playlist[0]\n",
    "            if(playlist_id > 1): #weird workaround... \n",
    "                sum += playlist_similarity(target_playlist_id, playlist_id)\n",
    "        \n",
    "        relevance[track_counter] = sum/track[2]  #Normalize. track[2] is the number of playlists containing the song. \n",
    "        track_counter += 1\n",
    "    \n",
    "        #relevance = sum/num of playlists containing the song\n",
    "    found = 0\n",
    "    while found < 5: \n",
    "        maxindex = np.argmax(relevance, axis = 0)[0]\n",
    "        #print(tracks[maxindex][1])\n",
    "        recommendations[0, found] = tracks[maxindex, 1]\n",
    "        relevance[maxindex] *= -1\n",
    "        found += 1\n",
    "    \n",
    "    #print(tracks)\n",
    "    #print(relevance)\n",
    "    \n",
    "    return recommendations\n",
    "print(recommend(10024884, tracks))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Get all playlists which contain a certain track:\n",
    "playlists = (item_playlist_matrix[item_playlist_matrix.T[1666][:]==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 min since start time.  9750  playlists to go. ETA:  753  minutes\n",
      "36 min since start time.  9500  playlists to go. ETA:  720  minutes\n",
      "53 min since start time.  9250  playlists to go. ETA:  711  minutes\n",
      "71 min since start time.  9000  playlists to go. ETA:  710  minutes\n",
      "87 min since start time.  8750  playlists to go. ETA:  699  minutes\n",
      "104 min since start time.  8500  playlists to go. ETA:  691  minutes\n",
      "120 min since start time.  8250  playlists to go. ETA:  686  minutes\n",
      "138 min since start time.  8000  playlists to go. ETA:  692  minutes\n",
      "156 min since start time.  7750  playlists to go. ETA:  693  minutes\n",
      "173 min since start time.  7500  playlists to go. ETA:  691  minutes\n",
      "189 min since start time.  7250  playlists to go. ETA:  689  minutes\n",
      "206 min since start time.  7000  playlists to go. ETA:  686  minutes\n",
      "222 min since start time.  6750  playlists to go. ETA:  683  minutes\n",
      "240 min since start time.  6500  playlists to go. ETA:  686  minutes\n",
      "259 min since start time.  6250  playlists to go. ETA:  691  minutes\n",
      "277 min since start time.  6000  playlists to go. ETA:  694  minutes\n",
      "296 min since start time.  5750  playlists to go. ETA:  696  minutes\n",
      "313 min since start time.  5500  playlists to go. ETA:  696  minutes\n",
      "330 min since start time.  5250  playlists to go. ETA:  695  minutes\n",
      "347 min since start time.  5000  playlists to go. ETA:  693  minutes\n",
      "363 min since start time.  4750  playlists to go. ETA:  691  minutes\n",
      "379 min since start time.  4500  playlists to go. ETA:  689  minutes\n",
      "395 min since start time.  4250  playlists to go. ETA:  687  minutes\n",
      "412 min since start time.  4000  playlists to go. ETA:  686  minutes\n",
      "428 min since start time.  3750  playlists to go. ETA:  685  minutes\n",
      "444 min since start time.  3500  playlists to go. ETA:  683  minutes\n",
      "460 min since start time.  3250  playlists to go. ETA:  682  minutes\n",
      "477 min since start time.  3000  playlists to go. ETA:  681  minutes\n",
      "493 min since start time.  2750  playlists to go. ETA:  680  minutes\n",
      "509 min since start time.  2500  playlists to go. ETA:  679  minutes\n",
      "525 min since start time.  2250  playlists to go. ETA:  678  minutes\n",
      "542 min since start time.  2000  playlists to go. ETA:  677  minutes\n",
      "558 min since start time.  1750  playlists to go. ETA:  676  minutes\n",
      "574 min since start time.  1500  playlists to go. ETA:  675  minutes\n",
      "590 min since start time.  1250  playlists to go. ETA:  675  minutes\n",
      "607 min since start time.  1000  playlists to go. ETA:  674  minutes\n",
      "625 min since start time.  750  playlists to go. ETA:  675  minutes\n",
      "643 min since start time.  500  playlists to go. ETA:  677  minutes\n",
      "661 min since start time.  250  playlists to go. ETA:  678  minutes\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of bounds: 0 <= 23617 <= 23617, 0 <= 23618 <= 23617, 23617 <= 23618",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-149-6e404bc7447f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m#print(playlist_id)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m#Fill the recommendations to col 1-5 for each playlist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mrecommendations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecommend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplaylist_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m250\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-139-5c8ec9da8916>\u001b[0m in \u001b[0;36mrecommend\u001b[0;34m(target_playlist_id, tracks)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mplaylist_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplaylist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplaylist_id\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#weird workaround...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                 \u001b[0msum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mplaylist_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_playlist_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplaylist_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mrelevance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrack_counter\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m#Normalize. track[2] is the number of playlists containing the song.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-133-1ce41af51f4c>\u001b[0m in \u001b[0;36mplaylist_similarity\u001b[0;34m(playlist_id1, playlist_id2)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplaylist_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplaylist_id1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplaylist_id2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m#Takes two playlist ids, returns their similarity as integer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0msimilarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplaylist_similarities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplaylist_indexes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mplaylist_id1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mplaylist_indexes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mplaylist_id2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/sparse/csr.py\u001b[0m in \u001b[0;36mgetrow\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0mCSR\u001b[0m \u001b[0mmatrix\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m \u001b[0mvector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \"\"\"\n\u001b[0;32m--> 360\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_submatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/sparse/csr.py\u001b[0m in \u001b[0;36m_get_submatrix\u001b[0;34m(self, row_slice, col_slice)\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0mi0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_slice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0mj0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_slice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0mcheck_bounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m         \u001b[0mcheck_bounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/sparse/csr.py\u001b[0m in \u001b[0;36mcheck_bounds\u001b[0;34m(i0, i1, num)\u001b[0m\n\u001b[1;32m    441\u001b[0m                 raise IndexError(\n\u001b[1;32m    442\u001b[0m                       \u001b[0;34m\"index out of bounds: 0 <= %d <= %d, 0 <= %d <= %d,\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m                       \" %d <= %d\" % (i0, num, i1, num, i0, i1))\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0mi0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_slice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of bounds: 0 <= 23617 <= 23617, 0 <= 23618 <= 23617, 23617 <= 23618"
     ]
    }
   ],
   "source": [
    "###Callin Recommend function, filling it into a DataFrame. ###\n",
    "###This part should not be changed ##\n",
    "\n",
    "zeros = np.zeros((target_playlists.size, 6), dtype = int)\n",
    "\n",
    "#Create empty dataframe\n",
    "recommendations = pd.DataFrame(zeros)\n",
    "\n",
    "#Rename the first col\n",
    "recommendations.columns = ['playlist_id', 1, 2, 3, 4, 5]\n",
    "\n",
    "#recommendations.iloc[:, 0] = target_playlists['playlist_id']\n",
    "\n",
    "\n",
    "#print(target_playlists[1:5]['playlist_id'])\n",
    "\n",
    "import time\n",
    "starttime = time.time()\n",
    "#print(time.time()-starttime, \"since start\")\n",
    "#Fill the recommendations matrix through calling the recommend-function\n",
    "counter = 0; \n",
    "#print(time.time()-starttime, \"since start time. \",10000-counter,\" playlists to go. Progress: \", counter/10000)\n",
    "\n",
    "for playlist_id in target_playlists['playlist_id']:\n",
    "    #Add the playlist ids as first col\n",
    "    recommendations.iloc[counter, 0] = playlist_id\n",
    "    #print(playlist_id)\n",
    "    #Fill the recommendations to col 1-5 for each playlist\n",
    "    recommendations.iloc[counter, 1:6] = recommend(playlist_id, tracks)\n",
    "    counter += 1\n",
    "    if counter%250 == 0: \n",
    "        runtime = time.time()-starttime\n",
    "        print(round((time.time()-starttime)/60) , \"min since start time. \",10000-counter,\" playlists to go. ETA: \", round(runtime/(1-(10000-counter)/10000)/60),\" minutes\")\n",
    "\n",
    "#print(recommendations)\n",
    "runtime = time.time()-starttime\n",
    "\n",
    "hours = 1000*runtime/3600\n",
    "\n",
    "#print(\"Ten recommendations took \",runtime,\" seconds. 10000 would take \", hours, \" hours... \")\n",
    "\n",
    "\n",
    "\n",
    "def save_to_file():\n",
    "    #Saves the recommendations dataframe to the .csv-file. \n",
    "    np.savetxt(\"recommendations.csv\",recommendations, fmt = '%s,%s %s %s %s %s', header = \"playlist_id,track_ids\", newline = \"\\n\")\n",
    "    \n",
    "save_to_file()\n",
    "\n",
    "print(\"The recommendations took \",(runtime/3600))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_to_file():\n",
    "    #Saves the recommendations dataframe to the .csv-file. \n",
    "    np.savetxt(\"recommendations_backup.csv\",recommendations, fmt = '%s,%s %s %s %s %s', header = \"playlist_id,track_ids\", newline = \"\\n\")\n",
    "    \n",
    "    \n",
    "def test():\n",
    "    #Do something\n",
    "    print(\"Result: \")\n",
    "    pass\n",
    "\n",
    "\n",
    "save_to_file()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
