{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse as sps\n",
    "%matplotlib inline\n",
    "\n",
    "#train_final.csv - the training set of interactions\n",
    "train_final = pd.read_csv('input/train_final.csv', delimiter = \"\\t\");\n",
    "\n",
    "#tracks_final.csv - supplementary information about the items\n",
    "tracks_final = pd.read_csv('input/tracks_final.csv', delimiter = \"\\t\");\n",
    "\n",
    "#playlists_final.csv - supplementary information about the users\n",
    "playlists_final = pd.read_csv('input/playlists_final.csv', delimiter = \"\\t\");\n",
    "\n",
    "#target_playlists.csv - the set of target playlists that will receive recommendations\n",
    "target_playlists = pd.read_csv('input/target_playlists.csv');\n",
    "\n",
    "#target_tracks.csv - the set of target items (tracks) to be recommended\n",
    "target_tracks = pd.read_csv('input/target_tracks.csv');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<57561x6 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 0 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41756, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we want to remove some redundant stuff. \n",
    "\n",
    "#We will remove all songs which are not occurring more than 10 times in train_final\n",
    "#Nevertheless, we still want to keep all tracks which are in the target tracks.  \n",
    "\n",
    "popularity = train_final.groupby(by=\"track_id\").playlist_id.nunique().to_frame()\n",
    "\n",
    "#remove index name\n",
    "popularity.reset_index(level = 0, inplace = True)\n",
    "\n",
    "#Rename the columns\n",
    "popularity.columns = ['track_id','occurrences']\n",
    "\n",
    "#Remove all targeted tracks - TESTED, working as expected\n",
    "tracks_relevant = popularity[~popularity['track_id'].isin(target_tracks['track_id'])]\n",
    "\n",
    "#Remove tracks occurring less than 10 times\n",
    "tracks_relevant = tracks_relevant[tracks_relevant['occurrences'] > 10]\n",
    "\n",
    "#Add the targeteted tracks back again\n",
    "tracks_relevant = pd.concat([tracks_relevant, target_tracks])\n",
    "\n",
    "tracks_relevant.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create train_relevant\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<57561x41756 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 0 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a User Rating Matrix. In our case, User is represented by playlist\n",
    "#And the ratings are implicit binary, 1/0 depending on wether a song is in the playlist. \n",
    "\n",
    "URM_all = sps.csr_matrix(np.zeros((playlists_final.shape[0], tracks_relevant.shape[0])))\n",
    "\n",
    "URM_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>duration</th>\n",
       "      <th>playcount</th>\n",
       "      <th>album</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2972914</td>\n",
       "      <td>144</td>\n",
       "      <td>224000</td>\n",
       "      <td>49.0</td>\n",
       "      <td>[7]</td>\n",
       "      <td>[54087, 1757, 1718, 116712, 189631]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2750239</td>\n",
       "      <td>246</td>\n",
       "      <td>157000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[8]</td>\n",
       "      <td>[189631, 3424, 177424, 46208, 205245]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1550729</td>\n",
       "      <td>144</td>\n",
       "      <td>217000</td>\n",
       "      <td>554.0</td>\n",
       "      <td>[9]</td>\n",
       "      <td>[54087, 109806, 46869, 183258, 54337]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2169950</td>\n",
       "      <td>144</td>\n",
       "      <td>207000</td>\n",
       "      <td>200.0</td>\n",
       "      <td>[9]</td>\n",
       "      <td>[54087, 70618, 207003, 109806, 116712]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1903709</td>\n",
       "      <td>144</td>\n",
       "      <td>198000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[54087, 81223, 116712, 215342, 71028]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   track_id  artist_id  duration  playcount   album  \\\n",
       "0   2972914        144    224000       49.0     [7]   \n",
       "1   2750239        246    157000        1.0     [8]   \n",
       "2   1550729        144    217000      554.0     [9]   \n",
       "3   2169950        144    207000      200.0     [9]   \n",
       "4   1903709        144    198000        5.0  [None]   \n",
       "\n",
       "                                     tags  \n",
       "0     [54087, 1757, 1718, 116712, 189631]  \n",
       "1   [189631, 3424, 177424, 46208, 205245]  \n",
       "2   [54087, 109806, 46869, 183258, 54337]  \n",
       "3  [54087, 70618, 207003, 109806, 116712]  \n",
       "4   [54087, 81223, 116712, 215342, 71028]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now lets take a look at the tags.\n",
    "tracks_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31900\n"
     ]
    }
   ],
   "source": [
    "#Lets translate the tags to indexes. \n",
    "tracks_final['tags'].head()\n",
    "\n",
    "\n",
    "tags_indexes = {}\n",
    "counter = 0; #We will start at 1, reserving col 0 for indexes. \n",
    "for row in tracks_final['tags']:\n",
    "    tags = row.strip('[ ]').split(', ')\n",
    "    for tag in tags:\n",
    "        if len(tag) > 0: \n",
    "            tag = int(tag)\n",
    "            if not(tag in tags_indexes):\n",
    "                tags_indexes[tag] = counter #Lets make it int to make it easier\n",
    "                counter += 1;\n",
    "\n",
    "print(len(tags_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 100000 unique tracks with 31900 unique tags\n"
     ]
    }
   ],
   "source": [
    "#If we translate each track_id to a track_index which will serve as matrix index, we can save a lot of time. \n",
    "\n",
    "\n",
    "#We need a way to get from track_id to index in O(1).\n",
    "#Let's create a dictionary\n",
    "\n",
    "tracks_indexes = {}\n",
    "index_to_item = {}\n",
    "counter = 0; #We will start at 1, reserving col 0 for indexes.  \n",
    "for track_id in tracks_final['track_id']:\n",
    "    tracks_indexes[track_id] = counter\n",
    "    counter += 1;\n",
    "    \n",
    "    \n",
    "print(\"We have {} unique tracks with {} unique tags\".format(len(tracks_indexes), len(tags_indexes)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#and a way to get from playlist_id to index in O(1)\n",
    "\n",
    "\n",
    "playlist_indexes = {}\n",
    "index_to_playlist = {}\n",
    "counter = 0; \n",
    "for playlist_id in playlists_final['playlist_id']:\n",
    "    playlist_indexes[playlist_id] = counter\n",
    "    counter += 1;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 31900)\n"
     ]
    }
   ],
   "source": [
    "#Now we can create an Item Content Matrix. \n",
    "\n",
    "ICM_all = np.zeros((len(tracks_indexes), len(tags_indexes)), int)\n",
    "print(ICM_all.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   occurrences  track_id  artist_id  duration  playcount     album  \\\n",
      "0         18.0       360     169649    194000      522.0   [77662]   \n",
      "1         11.0      1376     381303    270000      629.0  [180587]   \n",
      "2         12.0      2623      36019    329000     7081.0   [17295]   \n",
      "3         15.0      2891     310373    194000      196.0  [142650]   \n",
      "4         14.0      2901     163720    293000      322.0   [74384]   \n",
      "\n",
      "                                      tags  \n",
      "0      [70618, 70251, 70625, 25307, 11056]  \n",
      "1  [205245, 254105, 11056, 209598, 189631]  \n",
      "2    [122769, 23214, 48976, 117167, 90254]  \n",
      "3     [189631, 54087, 70618, 94794, 61837]  \n",
      "4     [193464, 205245, 46208, 92324, 3982]  \n"
     ]
    }
   ],
   "source": [
    "#tracks_relevant.reset_index(level = 0, inplace = True)\n",
    "\n",
    "tracks = pd.merge(tracks_relevant, tracks_final, how='inner', on='track_id')\n",
    "\n",
    "print(tracks.head())\n",
    "\n",
    "tracks = tracks.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counter = 1\n",
    "#for tag in tags_indexes:\n",
    "#    ICM_all[0,counter] = tag\n",
    "#    counter += 1\n",
    "#    \n",
    "#counter = 1\n",
    "#for track_id in tracks_indexes: \n",
    "#    ICM_all[counter, 0] = track_id\n",
    "#    counter += 1\n",
    "#    \n",
    "#print(ICM_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [1 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#We will put the track_id/tag in the [0]-column.\n",
    "\n",
    "#So let's fill it with our data.\n",
    "\n",
    "\n",
    "for row in tracks: \n",
    "    track_id = row[1]\n",
    "    tags = row[6].strip('[ ]').split(', ')\n",
    "    for tag in tags:\n",
    "        if len(tag) > 0:\n",
    "            tag_index = tags_indexes[int(tag)]\n",
    "            track_index = tracks_indexes[track_id]\n",
    "            ICM_all[track_index,tag_index] = 1\n",
    "            #print(\"Added tag {} to track {}\".format(tag, track_id))\n",
    "            \n",
    "\n",
    "print(ICM_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ICM_all_sparse = sps.csr_matrix(ICM_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<100000x31900 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 203506 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ICM_all_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 1)\n",
      "(1, 31900)\n"
     ]
    }
   ],
   "source": [
    "#Lets take a look at the data. \n",
    "\n",
    "features_per_item = (ICM_all_sparse > 0).sum(axis=1)\n",
    "items_per_feature = (ICM_all_sparse > 0).sum(axis=0)\n",
    "\n",
    "features_per_item = np.sort(features_per_item)\n",
    "items_per_feature = np.sort(items_per_feature)\n",
    "\n",
    "print(features_per_item.shape)\n",
    "print(items_per_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1040522, 2)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_relevant' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-7fdfdf7ca822>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mitem_playlist_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mplaylists_final\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracks_final\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0minteractions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_relevant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minteractions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#Lets get the info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_relevant' is not defined"
     ]
    }
   ],
   "source": [
    "#Lets build that URM matrix. Should be nofplaylists x nofitems\n",
    "\n",
    "item_playlist_matrix = np.zeros([playlists_final.shape[0], tracks_final.shape[0]],int) \n",
    "\n",
    "interactions = train_final.as_matrix()\n",
    "for row in interactions:\n",
    "    #Lets get the info\n",
    "    playlist_id = row[0]\n",
    "    track_id = row[1]\n",
    "    \n",
    "    #Now lets get the proper indexes. \n",
    "    playlist_index = playlist_indexes[playlist_id]\n",
    "    track_index = tracks_indexes[track_id]\n",
    "    \n",
    "    #And now lets add it to the matrix\n",
    "    item_playlist_matrix[playlist_index][track_index] = 1\n",
    "    \n",
    "\n",
    "print(item_playlist_matrix.shape)\n",
    "print(\"hej1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-30c603884e4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mURM_alternate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_playlist_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"done\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sps' is not defined"
     ]
    }
   ],
   "source": [
    "URM_alternate = sps.csr_matrix(item_playlist_matrix)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57560, 100000)\n",
      "(1040522,)\n",
      "(1040522,)\n"
     ]
    }
   ],
   "source": [
    "#Let's Split the Data and create evluation functions. \n",
    "\n",
    "train_test_split = 0.80\n",
    "\n",
    "numInteractions = train_final.shape[0]\n",
    "\n",
    "\n",
    "train_mask = np.random.choice([True,False], numInteractions, [train_test_split, 1-train_test_split])\n",
    "\n",
    "playlistList = np.zeros((train_final['playlist_id'].shape[0], 1), int)\n",
    "playlistList[:, 0] = train_final['playlist_id']\n",
    "\n",
    "#itemList = np.zeros((train_final['track_id'].shape[0], 1), int)\n",
    "#itemList[:, 0] = train_final['track_id']\n",
    "playlistList = train_final['playlist_id'].values\n",
    "itemList = train_final['track_id'].values\n",
    "\n",
    "#Translate ids\n",
    "playlistList_translated = np.zeros(playlistList.shape)\n",
    "itemList_translated = np.zeros(itemList.shape)\n",
    "for i in range(train_final.shape[0]):\n",
    "    playlistList_translated[i] = playlist_indexes[playlistList[i]]\n",
    "    itemList_translated[i] = tracks_indexes[itemList[i]]\n",
    "\n",
    "\n",
    "\n",
    "ratingList = np.ones((playlistList.shape), int)\n",
    "\n",
    "\n",
    "URM_train = sps.coo_matrix((ratingList[train_mask], (playlistList_translated[train_mask], itemList_translated[train_mask])))\n",
    "URM_train = URM_train.tocsr()\n",
    "\n",
    "print(URM_train.shape)\n",
    "print(playlistList.shape)\n",
    "print(itemList.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_mask = np.logical_not(train_mask)\n",
    "\n",
    "URM_test = sps.coo_matrix((ratingList[test_mask], (playlistList[test_mask], itemList[test_mask])))\n",
    "URM_test = URM_test.tocsr()\n",
    "\n",
    "def precision(recommended_items, relevant_items):\n",
    "    \n",
    "    is_relevant = np.in1d(recommended_items, relevant_items, assume_unique=True)\n",
    "    \n",
    "    precision_score = np.sum(is_relevant, dtype=np.float32) / len(is_relevant)\n",
    "    \n",
    "    return precision_score\n",
    "\n",
    "def recall(recommended_items, relevant_items):\n",
    "    \n",
    "    is_relevant = np.in1d(recommended_items, relevant_items, assume_unique=True)\n",
    "    \n",
    "    recall_score = np.sum(is_relevant, dtype=np.float32) / relevant_items.shape[0]\n",
    "    \n",
    "    return recall_score\n",
    "\n",
    "def MAP(recommended_items, relevant_items):\n",
    "   \n",
    "    is_relevant = np.in1d(recommended_items, relevant_items, assume_unique=True)\n",
    "    \n",
    "    # Cumulative sum: precision at 1, at 2, at 3 ...\n",
    "    p_at_k = is_relevant * np.cumsum(is_relevant, dtype=np.float32) / (1 + np.arange(is_relevant.shape[0]))\n",
    "    \n",
    "    map_score = np.sum(p_at_k) / np.min([relevant_items.shape[0], is_relevant.shape[0]])\n",
    "\n",
    "    return map_score\n",
    "\n",
    "def evaluate_algorithm(URM_test, recommender_object, at=5):\n",
    "    \n",
    "    cumulative_precision = 0.0\n",
    "    cumulative_recall = 0.0\n",
    "    cumulative_MAP = 0.0\n",
    "    \n",
    "    num_eval = 0\n",
    "\n",
    "\n",
    "    for i,user_id in  enumerate(userList_unique):\n",
    "        \n",
    "        if i % 500 == 0:\n",
    "            print(\"User %d of %d\" % (i, len(userList_unique)))\n",
    "\n",
    "        relevant_items = URM_test[user_id].indices\n",
    "        \n",
    "        if len(relevant_items)>0:\n",
    "            \n",
    "            recommended_items = recommender_object.recommend(user_id, at=at)\n",
    "            num_eval+=1\n",
    "\n",
    "            cumulative_precision += precision(recommended_items, relevant_items)\n",
    "            cumulative_recall += recall(recommended_items, relevant_items)\n",
    "            cumulative_MAP += MAP(recommended_items, relevant_items)\n",
    "\n",
    "\n",
    "    cumulative_precision /= num_eval\n",
    "    cumulative_recall /= num_eval\n",
    "    cumulative_MAP /= num_eval\n",
    "    \n",
    "    print(\"Recommender performance is: Precision = {:.4f}, Recall = {:.4f}, MAP = {:.4f}\".format(\n",
    "        cumulative_precision, cumulative_recall, cumulative_MAP))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BasicItemKNNRecommender(object):\n",
    "    \"\"\" ItemKNN recommender with cosine similarity and no shrinkage\"\"\"\n",
    "\n",
    "    def __init__(self, URM, k=50, shrinkage=100, similarity='cosine'):\n",
    "        self.dataset = URM\n",
    "        self.k = k\n",
    "        self.shrinkage = shrinkage\n",
    "        self.similarity_name = similarity\n",
    "        if similarity == 'cosine':\n",
    "            self.distance = Cosine(shrinkage=self.shrinkage)\n",
    "        elif similarity == 'pearson':\n",
    "            self.distance = Pearson(shrinkage=self.shrinkage)\n",
    "        elif similarity == 'adj-cosine':\n",
    "            self.distance = AdjustedCosine(shrinkage=self.shrinkage)\n",
    "        else:\n",
    "            raise NotImplementedError('Distance {} not implemented'.format(similarity))\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"ItemKNN(similarity={},k={},shrinkage={})\".format(\n",
    "            self.similarity_name, self.k, self.shrinkage)\n",
    "\n",
    "    def fit(self, X):\n",
    "        item_weights = self.distance.compute(X)\n",
    "        \n",
    "        item_weights = check_matrix(item_weights, 'csr') # nearly 10 times faster\n",
    "        print(\"Converted to csr\")\n",
    "        \n",
    "        # for each column, keep only the top-k scored items\n",
    "        # THIS IS THE SLOW PART, FIND A BETTER SOLUTION        \n",
    "        values, rows, cols = [], [], []\n",
    "        nitems = self.dataset.shape[1]\n",
    "        for i in range(nitems):\n",
    "            if (i % 10000 == 0):\n",
    "                print(\"Item %d of %d\" % (i, nitems))\n",
    "                \n",
    "            this_item_weights = item_weights[i,:].toarray()[0]\n",
    "            top_k_idx = np.argsort(this_item_weights) [-self.k:]\n",
    "                        \n",
    "            values.extend(this_item_weights[top_k_idx])\n",
    "            rows.extend(np.arange(nitems)[top_k_idx])\n",
    "            cols.extend(np.ones(self.k) * i)\n",
    "        self.W_sparse = sps.csc_matrix((values, (rows, cols)), shape=(nitems, nitems), dtype=np.float32)\n",
    "\n",
    "    def recommend(self, user_id, at=None, exclude_seen=True):\n",
    "        # compute the scores using the dot product\n",
    "        user_profile = self.dataset[user_id]\n",
    "        scores = user_profile.dot(self.W_sparse).toarray().ravel()\n",
    "\n",
    "        # rank items\n",
    "        ranking = scores.argsort()[::-1]\n",
    "        if exclude_seen:\n",
    "            ranking = self._filter_seen(user_id, ranking)\n",
    "            \n",
    "        return ranking[:at]\n",
    "    \n",
    "    def _filter_seen(self, user_id, ranking):\n",
    "        user_profile = self.dataset[user_id]\n",
    "        seen = user_profile.indices\n",
    "        unseen_mask = np.in1d(ranking, seen, assume_unique=True, invert=True)\n",
    "        return ranking[unseen_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_matrix(X, format='csc', dtype=np.float32):\n",
    "    if format == 'csc' and not isinstance(X, sps.csc_matrix):\n",
    "        return X.tocsc().astype(dtype)\n",
    "    elif format == 'csr' and not isinstance(X, sps.csr_matrix):\n",
    "        return X.tocsr().astype(dtype)\n",
    "    elif format == 'coo' and not isinstance(X, sps.coo_matrix):\n",
    "        return X.tocoo().astype(dtype)\n",
    "    elif format == 'dok' and not isinstance(X, sps.dok_matrix):\n",
    "        return X.todok().astype(dtype)\n",
    "    elif format == 'bsr' and not isinstance(X, sps.bsr_matrix):\n",
    "        return X.tobsr().astype(dtype)\n",
    "    elif format == 'dia' and not isinstance(X, sps.dia_matrix):\n",
    "        return X.todia().astype(dtype)\n",
    "    elif format == 'lil' and not isinstance(X, sps.lil_matrix):\n",
    "        return X.tolil().astype(dtype)\n",
    "    else:\n",
    "        return X.astype(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "class ISimilarity(object):\n",
    "    \"\"\"Abstract interface for the similarity metrics\"\"\"\n",
    "\n",
    "    def __init__(self, shrinkage=10):\n",
    "        self.shrinkage = shrinkage\n",
    "\n",
    "    def compute(self, X):\n",
    "        pass\n",
    "\n",
    "\n",
    "class Cosine(ISimilarity):\n",
    "    def compute(self, X):\n",
    "        # convert to csc matrix for faster column-wise operations\n",
    "        X = check_matrix(X, 'csc', dtype=np.float32)\n",
    "\n",
    "        # 1) normalize the columns in X\n",
    "        # compute the column-wise norm\n",
    "        # NOTE: this is slightly inefficient. We must copy X to compute the column norms.\n",
    "        # A faster solution is to  normalize the matrix inplace with a Cython function.\n",
    "        Xsq = X.copy()\n",
    "        Xsq.data **= 2\n",
    "        norm = np.sqrt(Xsq.sum(axis=0))\n",
    "        norm = np.asarray(norm).ravel()\n",
    "        norm += 1e-6\n",
    "        # compute the number of non-zeros in each column\n",
    "        # NOTE: this works only if X is instance of sparse.csc_matrix\n",
    "        col_nnz = np.diff(X.indptr)\n",
    "        # then normalize the values in each column\n",
    "        X.data /= np.repeat(norm, col_nnz)\n",
    "        print(\"Normalized\")\n",
    "\n",
    "        # 2) compute the cosine similarity using the dot-product\n",
    "        dist = X * X.T\n",
    "        print(\"Computed\")\n",
    "        \n",
    "        # zero out diagonal values\n",
    "        dist = dist - sps.dia_matrix((dist.diagonal()[scipy.newaxis, :], [0]), shape=dist.shape)\n",
    "        print(\"Removed diagonal\")\n",
    "        \n",
    "        # and apply the shrinkage\n",
    "        if self.shrinkage > 0:\n",
    "            dist = self.apply_shrinkage(X, dist)\n",
    "            print(\"Applied shrinkage\")    \n",
    "        \n",
    "        return dist\n",
    "\n",
    "    def apply_shrinkage(self, X, dist):\n",
    "        # create an \"indicator\" version of X (i.e. replace values in X with ones)\n",
    "        X_ind = X.copy()\n",
    "        X_ind.data = np.ones_like(X_ind.data)\n",
    "        # compute the co-rated counts\n",
    "        co_counts = X_ind * X_ind.T\n",
    "        # remove the diagonal\n",
    "        co_counts = co_counts - sps.dia_matrix((co_counts.diagonal()[scipy.newaxis, :], [0]), shape=co_counts.shape)\n",
    "        # compute the shrinkage factor as co_counts_ij / (co_counts_ij + shrinkage)\n",
    "        # then multiply dist with it\n",
    "        co_counts_shrink = co_counts.copy()\n",
    "        co_counts_shrink.data += self.shrinkage\n",
    "        co_counts.data /= co_counts_shrink.data\n",
    "        dist.data *= co_counts.data\n",
    "        return dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57560, 100000)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URM_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized\n",
      "Computed\n",
      "Removed diagonal\n",
      "Converted to csr\n",
      "Item 0 of 100000\n",
      "Item 10000 of 100000\n",
      "Item 20000 of 100000\n",
      "Item 30000 of 100000\n",
      "Item 40000 of 100000\n",
      "Item 50000 of 100000\n",
      "Item 60000 of 100000\n",
      "Item 70000 of 100000\n",
      "Item 80000 of 100000\n",
      "Item 90000 of 100000\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "rec = BasicItemKNNRecommender(URM=URM_train, shrinkage=0.0, k=50)\n",
    "rec.fit(ICM_all_sparse)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "zeros = np.zeros((target_playlists.size, 6), dtype = int)\n",
    "recommendations = pd.DataFrame(zeros)\n",
    "recommendations.columns = ['playlist_id', 1, 2, 3, 4, 5]\n",
    "\n",
    "counter = 0\n",
    "for playlist_id in target_playlists['playlist_id']:\n",
    "    \n",
    "    if counter % 1000 == 0: \n",
    "        print (\"% out of 10000 playlisys\" %(counter))\n",
    "    \n",
    "    \n",
    "    playlist_id_translated = playlist_indexes[int(playlist_id)]\n",
    "    #print(rec.recommend(playlist_id_translated, at=5))\n",
    "    recommendations.iloc[counter, 1:6] = rec.recommend(playlist_id_translated, at=5)\n",
    "    recommendations.iloc[counter, 0] = playlist_id\n",
    "    counter += 1\n",
    "    \n",
    "#print(recommendations)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  out of 10000 playlists\n",
      "1000  out of 10000 playlists\n",
      "2000  out of 10000 playlists\n",
      "3000  out of 10000 playlists\n",
      "4000  out of 10000 playlists\n",
      "5000  out of 10000 playlists\n",
      "6000  out of 10000 playlists\n",
      "7000  out of 10000 playlists\n",
      "8000  out of 10000 playlists\n",
      "9000  out of 10000 playlists\n",
      "done2\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "\n",
    "for playlist_id in target_playlists['playlist_id']:\n",
    "    if counter % 1000 == 0: \n",
    "        print (\"%s out of 10000 playlists\" %(counter))\n",
    "    recommendations.iloc[counter, 0] = playlist_id\n",
    "    counter += 1\n",
    "print(\"done2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of       playlist_id      1      2      3      4      5\n",
      "0               0  98934  87509  80967   8725  88009\n",
      "1               0  61545  52696  30316  43951  28369\n",
      "2               0  21510  21500  21521  48827   7670\n",
      "3               0  87099  39561  39566  69158  69154\n",
      "4               0  59826  59820  59813  44567  44566\n",
      "5               0  94896  94835  94843  94832  94847\n",
      "6               0  94712  14299  77288  77442  77450\n",
      "7               0  93366  93369  93368  78361  15279\n",
      "8               0  39298  46258  46264  46255  39291\n",
      "9               0  30434  30441  30457  30461  30428\n",
      "10              0  12758  79387  12762  12767  70712\n",
      "11              0  26876  71531  29784  49226  88093\n",
      "12              0  85548  10458  10457  43152  27412\n",
      "13              0  83334  15361  56626  60641  60644\n",
      "14              0  57512  57502  57576  57491  57513\n",
      "15              0  59351  30369   2144   2143   2137\n",
      "16              0  97979  40440  40441  52067  96161\n",
      "17              0   5282   5286   5289   5284   5291\n",
      "18              0  59918  35850   1258  30550  30558\n",
      "19              0  99999  33349  33327  33328  33329\n",
      "20              0  13585    202   7533  24571  44191\n",
      "21              0   3704   3729   3692   3693   3699\n",
      "22              0  26900  26902  26916  26907  26911\n",
      "23              0  64815  77211  65441  29861  29851\n",
      "24              0  11146  11151  11166  11170  11132\n",
      "25              0  12882  31132  31130  31118  31125\n",
      "26              0  94064  94082  94066  94083   9505\n",
      "27              0  15792  52610  92639  52216  52609\n",
      "28              0  74599  74608  74592  74602  74590\n",
      "29              0  54480  33869  93681  11900  54478\n",
      "...           ...    ...    ...    ...    ...    ...\n",
      "9970            0  78427  78448  49346  26554  56220\n",
      "9971            0  94669  94697  94682  94684  94690\n",
      "9972            0  63044  54027  95932  95943  95947\n",
      "9973            0   6715   6711  48803  48811  48687\n",
      "9974            0  68660  68691  68645  68629  68677\n",
      "9975            0  24048  29386  29380  23054  23049\n",
      "9976            0  91892  91879  91908  91916  91878\n",
      "9977            0  60727  60712  60685  60686  60689\n",
      "9978            0  60043  61545   3832  42815  42820\n",
      "9979            0  52317  66779  66780  66782  36115\n",
      "9980            0  31916  30401  19818  30398  30460\n",
      "9981            0  21249  70801  80705  18940  73490\n",
      "9982            0   6849   6859  77404  19322  74253\n",
      "9983            0  82321  82318  82325  82317  82293\n",
      "9984            0  92318  92291  92310  92298  92315\n",
      "9985            0  99999  33349  33327  33328  33329\n",
      "9986            0  55038  54872  70143  55538  55040\n",
      "9987            0  31511  31507    764  23043  23030\n",
      "9988            0  99999  33349  33327  33328  33329\n",
      "9989            0  46926  46934  46939  46927  46941\n",
      "9990            0  35326  20512  13104  43120  25803\n",
      "9991            0   8397  40594   8372  30749   8381\n",
      "9992            0   1829   1828  77880   7035   2506\n",
      "9993            0  25731  88162  88154  88157  63857\n",
      "9994            0  27322  45869  45883  45973  45897\n",
      "9995            0  46360  46399  46345  46385  46387\n",
      "9996            0  31795  31787  31797  31775  31785\n",
      "9997            0  80170  24693  24697  18188  18191\n",
      "9998            0  46478  88676  78856  50497  50491\n",
      "9999            0  20692  62481  62949  62947  62955\n",
      "\n",
      "[10000 rows x 6 columns]>\n"
     ]
    }
   ],
   "source": [
    "def save_to_file():\n",
    "    #Saves the recommendations dataframe to the .csv-file. \n",
    "    np.savetxt(\"recommendations_backup.csv\",recommendations, fmt = '%s,%s %s %s %s %s', header = \"playlist_id,track_ids\", newline = \"\\n\")\n",
    "    \n",
    "    \n",
    "def test():\n",
    "    #Do something\n",
    "    print(\"Result: \")\n",
    "    pass\n",
    "\n",
    "\n",
    "save_to_file()\n",
    "print(recommendations.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
