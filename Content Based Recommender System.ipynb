{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse as sps\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n",
    "#train_final.csv - the training set of interactions\n",
    "train_final = pd.read_csv('input/train_final.csv', delimiter = \"\\t\");\n",
    "\n",
    "#tracks_final.csv - supplementary information about the items\n",
    "tracks_final = pd.read_csv('input/tracks_final.csv', delimiter = \"\\t\");\n",
    "\n",
    "#playlists_final.csv - supplementary information about the users\n",
    "playlists_final = pd.read_csv('input/playlists_final.csv', delimiter = \"\\t\");\n",
    "\n",
    "#target_playlists.csv - the set of target playlists that will receive recommendations\n",
    "target_playlists = pd.read_csv('input/target_playlists.csv');\n",
    "\n",
    "#target_tracks.csv - the set of target items (tracks) to be recommended\n",
    "target_tracks = pd.read_csv('input/target_tracks.csv');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_final now contains 945579 interactions. \n",
      "Tracks_final now contains 74542 tracks. \n"
     ]
    }
   ],
   "source": [
    "#This step is not needed yet, will make ratings worse! \n",
    "\n",
    "def get_relevant_tracks():\n",
    "    #Now we want to remove some redundant stuff. \n",
    "\n",
    "    #We will remove all songs which are not occurring more than 10 times in train_final\n",
    "    #Nevertheless, we still want to keep all tracks which are in the target tracks.  \n",
    "\n",
    "    popularity = train_final.groupby(by=\"track_id\").playlist_id.nunique().to_frame()\n",
    "\n",
    "    #remove index name\n",
    "    popularity.reset_index(level = 0, inplace = True)\n",
    "\n",
    "    #Rename the columns\n",
    "    popularity.columns = ['track_id','occurrences']\n",
    "\n",
    "    #Remove all targeted tracks - TESTED, working as expected\n",
    "    tracks_relevant = popularity[~popularity['track_id'].isin(target_tracks['track_id'])]\n",
    "\n",
    "    #Remove tracks occurring less than 10 times\n",
    "    tracks_relevant = tracks_relevant[tracks_relevant['occurrences'] > 4]\n",
    "\n",
    "    #Add the targeteted tracks back again\n",
    "    tracks_relevant = pd.concat([tracks_relevant, target_tracks])\n",
    "\n",
    "    return(tracks_relevant)\n",
    "\n",
    "    print(\"Removed %s redundant tracks which occured less than 10 times.\" %(tracks_final-tracks_relevant))\n",
    "\n",
    "tracks_relevant = get_relevant_tracks()\n",
    "\n",
    "#Remove irrelevant tracks from train_final and tracks_final\n",
    "train_final = train_final[train_final['track_id'].isin(tracks_relevant['track_id'])]\n",
    "\n",
    "print(\"Train_final now contains %s interactions. \" %(train_final.shape[0]))\n",
    "\n",
    "tracks_final = tracks_final[tracks_final['track_id'].isin(tracks_relevant['track_id'])]\n",
    "\n",
    "print(\"Tracks_final now contains %s tracks. \"%(tracks_final.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>duration</th>\n",
       "      <th>playcount</th>\n",
       "      <th>album</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2972914</td>\n",
       "      <td>144</td>\n",
       "      <td>224000</td>\n",
       "      <td>49.0</td>\n",
       "      <td>[7]</td>\n",
       "      <td>[54087, 1757, 1718, 116712, 189631]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2750239</td>\n",
       "      <td>246</td>\n",
       "      <td>157000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[8]</td>\n",
       "      <td>[189631, 3424, 177424, 46208, 205245]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1550729</td>\n",
       "      <td>144</td>\n",
       "      <td>217000</td>\n",
       "      <td>554.0</td>\n",
       "      <td>[9]</td>\n",
       "      <td>[54087, 109806, 46869, 183258, 54337]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2169950</td>\n",
       "      <td>144</td>\n",
       "      <td>207000</td>\n",
       "      <td>200.0</td>\n",
       "      <td>[9]</td>\n",
       "      <td>[54087, 70618, 207003, 109806, 116712]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1903709</td>\n",
       "      <td>144</td>\n",
       "      <td>198000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[54087, 81223, 116712, 215342, 71028]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   track_id  artist_id  duration  playcount   album  \\\n",
       "0   2972914        144    224000       49.0     [7]   \n",
       "1   2750239        246    157000        1.0     [8]   \n",
       "2   1550729        144    217000      554.0     [9]   \n",
       "3   2169950        144    207000      200.0     [9]   \n",
       "4   1903709        144    198000        5.0  [None]   \n",
       "\n",
       "                                     tags  \n",
       "0     [54087, 1757, 1718, 116712, 189631]  \n",
       "1   [189631, 3424, 177424, 46208, 205245]  \n",
       "2   [54087, 109806, 46869, 183258, 54337]  \n",
       "3  [54087, 70618, 207003, 109806, 116712]  \n",
       "4   [54087, 81223, 116712, 215342, 71028]  "
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now lets take a look at the tags.\n",
    "tracks_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Translating all content ids into indexes.\n",
    "\n",
    "#We need to create buckets for the playcount and duration. \n",
    "#Lets create buckets and a help function for the duration. \n",
    "\n",
    "n_duration_buckets = 3\n",
    "def duration_to_bucket(duration, alternative = 2):\n",
    "    if (alternative == 1):\n",
    "        n_duration_buckets = 8\n",
    "        if duration <= 0:\n",
    "            print(\"Null duration reached bucket function. \")\n",
    "            return None\n",
    "        elif duration < 90000: #not a song\n",
    "            return 1\n",
    "        elif duration < 140000: #short song\n",
    "            return 2\n",
    "        elif duration < 220000: #radio song\n",
    "            return 3\n",
    "        elif duration < 340000: #normal song\n",
    "            return 4\n",
    "        elif duration < 480000: #long song\n",
    "            return 5\n",
    "        elif duration < 720000: #really long\n",
    "            return 6\n",
    "        elif duration < 1200000: #super long\n",
    "            return 7\n",
    "        elif duration >= 1200000: #mixtape/compilation\n",
    "            return 8\n",
    "    elif(alternative == 2):\n",
    "        n_duration_buckets = 3\n",
    "        if duration <= 0:\n",
    "            print(\"Null duration reached bucket function. \")\n",
    "            return None\n",
    "        elif duration <= 150000: #very short\n",
    "            return 1\n",
    "        elif duration > 150000 and duration < 720000: #very long\n",
    "            return 2\n",
    "        elif duration >= 720000: #mixtape/compilation\n",
    "            return 3\n",
    "        else: \n",
    "            return 0\n",
    "        \n",
    "\n",
    "n_playcount_buckets = 7\n",
    "def playcount_to_bucket(playcount):\n",
    "    if playcount <= 0 or playcount is None:\n",
    "        print(\"Null playcount reached bucket function. \")\n",
    "        return None\n",
    "    elif playcount < 254: #0,4 percentile not popular\n",
    "        return 1\n",
    "    elif playcount < 881: #0,6 perc: known\n",
    "        return 2\n",
    "    elif playcount < 1560: #0,7 popular\n",
    "        return 3\n",
    "    elif playcount < 2808: #0,8 very popular\n",
    "        return 4\n",
    "    elif playcount < 5900: #0,9 hits\n",
    "        return 5\n",
    "    elif playcount < 10494: #0,95 super hits\n",
    "        return 6\n",
    "    elif playcount >= 10494: # mega hits\n",
    "        return 7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77040\n",
      "27604 albums. 27607 expected.\n",
      "17536 artists. 17537 expected.\n"
     ]
    }
   ],
   "source": [
    "tracks_final['tags'].head()\n",
    "\n",
    "content_to_index = {}\n",
    "content_to_id = {}\n",
    "content_counter = 0\n",
    "\n",
    "#Lets translate the tags to indexes.\n",
    "for row in tracks_final['tags']:\n",
    "    tags = row.strip('[ ]').split(', ')\n",
    "    for tag in tags:\n",
    "        if len(tag) > 0: \n",
    "            tag = \"t\"+tag\n",
    "            if not(tag in content_to_index):\n",
    "                content_to_index[tag] = content_counter\n",
    "                content_to_id[content_counter] = tag\n",
    "                content_counter += 1;\n",
    "                \n",
    "#Lets translate album into indexes\n",
    "albumcount = 0 # 27607\n",
    "for album in tracks_final['album']:\n",
    "    album = album.strip('[ ]')\n",
    "    if album != None and album != \"None\" and len(album) > 0: #None should not be considered content\n",
    "        album = \"al\"+album\n",
    "        if album == \"alNone\":\n",
    "            print(album)\n",
    "        if not(album in content_to_index):\n",
    "            content_to_index[album] = content_counter\n",
    "            content_to_id[content_counter] = album\n",
    "            content_counter += 1\n",
    "            albumcount += 1\n",
    "\n",
    "#Lets translate artist_id into indexes \n",
    "artistcount = 0 #17537\n",
    "for artist in tracks_final['artist_id']:\n",
    "    artist = str(artist)\n",
    "    if artist != None and artist != \"None\" and len(artist) > 0: #None should not be considered content\n",
    "        artist = \"ar\"+artist\n",
    "        if not(artist in content_to_index):\n",
    "            content_to_index[artist] = content_counter\n",
    "            content_to_id[content_counter] = artist\n",
    "            content_counter += 1\n",
    "            artistcount += 1\n",
    "        \n",
    "\"\"\"\n",
    "#Lets translate the duration buckets into indexes. \n",
    "for bucket in range(n_duration_buckets): \n",
    "    bucket = \"d\"+str(bucket+1)\n",
    "    content_to_index[bucket] = content_counter\n",
    "    content_to_id[content_counter] = bucket\n",
    "    print(\"added %s\" %(bucket))\n",
    "    content_counter += 1\n",
    "\n",
    "#Lets translate the playcount buckets into indexes. \n",
    "for playcount in range(n_playcount_buckets): \n",
    "    playcount = \"p\"+str(playcount+1)\n",
    "    content_to_index[playcount] = content_counter\n",
    "    content_to_id[content_counter] = playcount\n",
    "    \n",
    "    content_counter += 1\n",
    "\n",
    "\n",
    "## Alternative 2: Just one content type per continous variable. \n",
    "#Fun thing to try: can I add all duration/playcounts in one col, normalizing from 0-1? \n",
    "\n",
    "\n",
    "content_to_index[\"duration\"] = content_counter\n",
    "content_to_id[content_counter] = \"duration\"\n",
    "content_counter += 1\n",
    "\n",
    "content_to_index[\"playcount\"] = content_counter\n",
    "content_to_id[content_counter] = \"playcount\"\n",
    "content_counter += 1\n",
    "\"\"\"\n",
    "\n",
    "print(len(content_to_index))\n",
    "print(\"%s albums. 27607 expected.\" %albumcount)\n",
    "print(\"%s artists. 17537 expected.\" %artistcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 57561 playlists with 100000 unique tracks with 77040 unique content types. \n"
     ]
    }
   ],
   "source": [
    "#If we translate each track_id to a track_index which will serve as matrix index, we can save a lot of time. \n",
    "\n",
    "\n",
    "#We need a way to get from track_id to index in O(1).\n",
    "#Let's create a dictionary\n",
    "\n",
    "track_to_id = {}\n",
    "track_to_index = {}\n",
    "track_ids = tracks_final['track_id']\n",
    "\n",
    "counter = 0;\n",
    "for track_id in tracks_final['track_id']:\n",
    "    track_id = int(track_id)\n",
    "    track_to_index[track_id] = counter\n",
    "    track_to_id[counter] = track_id\n",
    "    counter += 1;\n",
    "    \n",
    "#and a way to get from playlist_id to index in O(1)\n",
    "\n",
    "\n",
    "playlist_to_index = {}\n",
    "playlist_to_id = {}\n",
    "counter = 0; \n",
    "for playlist_id in playlists_final['playlist_id']:\n",
    "    playlist_id = int(playlist_id)\n",
    "    playlist_to_index[playlist_id] = counter\n",
    "    playlist_to_id[counter] = playlist_id\n",
    "    counter += 1;\n",
    "    \n",
    "print(\"We have {} playlists with {} unique tracks with {} unique content types. \".format(len(playlist_to_index), len(track_to_index), len(content_to_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now we can create an Item Content Matrix. \n",
    "\n",
    "#ICM_all = np.zeros((len(tracks_indexes), len(tags_indexes)), int)\n",
    "#ICM_all = sps.coo_matrix((len(track_to_index), len(content_to_index)), int)\n",
    "#print(ICM_all.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>duration</th>\n",
       "      <th>playcount</th>\n",
       "      <th>album</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2972914</td>\n",
       "      <td>144</td>\n",
       "      <td>224000</td>\n",
       "      <td>49.0</td>\n",
       "      <td>[7]</td>\n",
       "      <td>[54087, 1757, 1718, 116712, 189631]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2750239</td>\n",
       "      <td>246</td>\n",
       "      <td>157000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[8]</td>\n",
       "      <td>[189631, 3424, 177424, 46208, 205245]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1550729</td>\n",
       "      <td>144</td>\n",
       "      <td>217000</td>\n",
       "      <td>554.0</td>\n",
       "      <td>[9]</td>\n",
       "      <td>[54087, 109806, 46869, 183258, 54337]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2169950</td>\n",
       "      <td>144</td>\n",
       "      <td>207000</td>\n",
       "      <td>200.0</td>\n",
       "      <td>[9]</td>\n",
       "      <td>[54087, 70618, 207003, 109806, 116712]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1903709</td>\n",
       "      <td>144</td>\n",
       "      <td>198000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[54087, 81223, 116712, 215342, 71028]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2256817</td>\n",
       "      <td>144</td>\n",
       "      <td>218000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[9]</td>\n",
       "      <td>[54087, 109806, 189631, 49166, 116712]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2561768</td>\n",
       "      <td>928</td>\n",
       "      <td>223000</td>\n",
       "      <td>249.0</td>\n",
       "      <td>[26]</td>\n",
       "      <td>[50764, 4425, 11056, 205245, 81223]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>474864</td>\n",
       "      <td>928</td>\n",
       "      <td>193000</td>\n",
       "      <td>73.0</td>\n",
       "      <td>[22]</td>\n",
       "      <td>[205245, 81223, 11056, 267, 3982]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1378455</td>\n",
       "      <td>928</td>\n",
       "      <td>304000</td>\n",
       "      <td>73.0</td>\n",
       "      <td>[22]</td>\n",
       "      <td>[11056, 205245, 81223, 189631, 84597]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1523190</td>\n",
       "      <td>928</td>\n",
       "      <td>206000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[22]</td>\n",
       "      <td>[205245, 11056, 81223, 4425, 189631]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   track_id  artist_id  duration  playcount   album  \\\n",
       "0   2972914        144    224000       49.0     [7]   \n",
       "1   2750239        246    157000        1.0     [8]   \n",
       "2   1550729        144    217000      554.0     [9]   \n",
       "3   2169950        144    207000      200.0     [9]   \n",
       "4   1903709        144    198000        5.0  [None]   \n",
       "5   2256817        144    218000        2.0     [9]   \n",
       "6   2561768        928    223000      249.0    [26]   \n",
       "7    474864        928    193000       73.0    [22]   \n",
       "8   1378455        928    304000       73.0    [22]   \n",
       "9   1523190        928    206000       10.0    [22]   \n",
       "\n",
       "                                     tags  \n",
       "0     [54087, 1757, 1718, 116712, 189631]  \n",
       "1   [189631, 3424, 177424, 46208, 205245]  \n",
       "2   [54087, 109806, 46869, 183258, 54337]  \n",
       "3  [54087, 70618, 207003, 109806, 116712]  \n",
       "4   [54087, 81223, 116712, 215342, 71028]  \n",
       "5  [54087, 109806, 189631, 49166, 116712]  \n",
       "6     [50764, 4425, 11056, 205245, 81223]  \n",
       "7       [205245, 81223, 11056, 267, 3982]  \n",
       "8   [11056, 205245, 81223, 189631, 84597]  \n",
       "9    [205245, 11056, 81223, 4425, 189631]  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks_final[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track 0 of 100000. 0.0 s sec.\n",
      "Track 5000 of 100000. 0.1 s sec.\n",
      "Track 10000 of 100000. 0.22 s sec.\n",
      "Track 15000 of 100000. 0.34 s sec.\n",
      "Track 20000 of 100000. 0.46 s sec.\n",
      "Track 25000 of 100000. 0.58 s sec.\n",
      "Track 30000 of 100000. 0.69 s sec.\n",
      "Track 35000 of 100000. 0.8 s sec.\n",
      "Track 40000 of 100000. 0.92 s sec.\n",
      "Track 45000 of 100000. 1.03 s sec.\n",
      "Track 50000 of 100000. 1.15 s sec.\n",
      "Track 55000 of 100000. 1.27 s sec.\n",
      "Track 60000 of 100000. 1.39 s sec.\n",
      "Track 65000 of 100000. 1.5 s sec.\n",
      "Track 70000 of 100000. 1.61 s sec.\n",
      "Track 75000 of 100000. 1.73 s sec.\n",
      "Track 80000 of 100000. 1.84 s sec.\n",
      "Track 85000 of 100000. 1.95 s sec.\n",
      "Track 90000 of 100000. 2.08 s sec.\n",
      "Track 95000 of 100000. 2.2 s sec.\n",
      "Built ICM matrix with 656745 content values.\n",
      "27604 albums. 27607 expected.\n",
      "17536 artists. 17537 expected.\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#So let's fill the ICM with our data.\n",
    "import math\n",
    "\n",
    "def build_ICM():\n",
    "    \n",
    "    no_interactions = train_final.shape[0]\n",
    "    \n",
    "    tracks_matrix = tracks_final.as_matrix()\n",
    "    rows = np.zeros((no_interactions,), dtype = int)\n",
    "    cols = np.zeros((no_interactions,), dtype = int)\n",
    "    val = np.zeros((no_interactions,), dtype = int)\n",
    "    #val[i] = value of row[i] col[i]\n",
    "    #val = []\n",
    "    counter = 0\n",
    "    starttime = time.time()\n",
    "    lasttime = starttime\n",
    "    trackno = 0\n",
    "    addedalbums = {} #for testing\n",
    "    addedartists = {} # for testing\n",
    "    for track in tracks_matrix: \n",
    "        track_id, artist_id, duration, playcount, album, tags = np.split(track, 6)\n",
    "\n",
    "        #Get track index\n",
    "        track_index = track_to_index[int(track_id[0])]\n",
    "\n",
    "        \n",
    "        #add artist\n",
    "        \n",
    "        artist_index = content_to_index[\"ar\"+str(artist_id[0])]\n",
    "        addedartists[artist_index] = 1\n",
    "        \n",
    "        rows[counter] = track_index\n",
    "        cols[counter] = artist_index\n",
    "        val[counter] = 1\n",
    "        counter += 1\n",
    "\n",
    "        #add album\n",
    "        album = album[0].strip(\"[ ]\")\n",
    "\n",
    "        if album != None and len(album) > 0 and not album == \"None\":\n",
    "            album_index = content_to_index[\"al\"+album]\n",
    "            addedalbums[album_index] = 1 #testing\n",
    "            \n",
    "            rows[counter] = track_index\n",
    "            cols[counter] = album_index\n",
    "            val[counter] = 1\n",
    "            counter += 1\n",
    "\n",
    "        #add tags\n",
    "        tags = tags[0].strip('[ ]').split(', ')\n",
    "\n",
    "        for tag in tags: \n",
    "            if len(tag) > 0:\n",
    "                tag = \"t\"+tag\n",
    "                tag_index = content_to_index[tag]\n",
    "\n",
    "                rows[counter] = track_index\n",
    "                cols[counter] = tag_index\n",
    "                val[counter] = 1\n",
    "                \n",
    "                counter+=1\n",
    "        \"\"\"\n",
    "        ## ALT 1: Continuous variables in different content types. \n",
    "        \n",
    "        #add duration\n",
    "        duration = int(duration)\n",
    "        if duration > 0:\n",
    "            duration_bucket = duration_to_bucket(duration)\n",
    "            if duration_bucket > 0:   \n",
    "                duration_index = content_to_index[\"d\"+str(duration_bucket)]\n",
    "\n",
    "                rows[counter] = track_index\n",
    "                cols[counter] = duration_index\n",
    "\n",
    "                counter+=1\n",
    "        \n",
    "        #add playcount\n",
    "        if playcount is not None and playcount != \"None\" and not math.isnan(playcount):\n",
    "            playcount = int(playcount)\n",
    "            if playcount > 0: \n",
    "                playcount_bucket = playcount_to_bucket(playcount)\n",
    "                playcount_index = content_to_index[\"p\"+str(playcount_bucket)]\n",
    "\n",
    "                rows[counter] = track_index\n",
    "                cols[counter] = playcount_index\n",
    "                counter+=1\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        ## ALT 2: Continuous variables in one content type. \n",
    "        \n",
    "        #add duration\n",
    "        duration = int(duration)\n",
    "        if duration > 0:\n",
    "            duration_bucket = duration_to_bucket(duration)\n",
    "            duration_index = content_to_index[\"duration\"]\n",
    "\n",
    "            rows[counter] = track_index\n",
    "            cols[counter] = duration_index\n",
    "            val[counter] = duration_bucket/n_duration_buckets\n",
    "            \n",
    "            counter+=1\n",
    "\n",
    "        #add playcount\n",
    "        if playcount is not None and playcount != \"None\" and not math.isnan(playcount):\n",
    "            playcount = int(playcount)\n",
    "            if playcount > 0: \n",
    "                playcount_bucket = playcount_to_bucket(playcount)\n",
    "                playcount_index = content_to_index[\"playcount\"]\n",
    "\n",
    "                rows[counter] = track_index\n",
    "                cols[counter] = playcount_index\n",
    "                val[counter] = playcount_bucket/n_playcount_buckets\n",
    "\n",
    "                \n",
    "                counter+=1\n",
    "        \"\"\"\n",
    "        if trackno%5000 == 0:\n",
    "            print(\"Track %s of %s. %s s sec.\" %(trackno, tracks_matrix.shape[0], round(time.time()-starttime, 2)))  \n",
    "        trackno += 1\n",
    "\n",
    "    #Implicit ratings: all ratings are 1.             \n",
    "    \n",
    "    rows = rows[:counter]\n",
    "    cols = cols[:counter]\n",
    "    val = val[:counter]\n",
    "    #val = np.ones(rows.shape, dtype = int)\n",
    "\n",
    "    #Build ICM matrix. \n",
    "    ICM_all = sps.coo_matrix((val, (rows, cols)), dtype = int)\n",
    "    \n",
    "    print(\"Built ICM matrix with %s content values.\" %(val.shape[0]))\n",
    "    \n",
    "    print(\"%s albums. 27607 expected.\" %len(addedalbums))\n",
    "    print(\"%s artists. 17537 expected.\" %len(addedartists))\n",
    "    \n",
    "    return ICM_all\n",
    "\n",
    "\n",
    "#Build new ICM\n",
    "ICM_all = build_ICM()\n",
    "print(\"Done!\")\n",
    "\n",
    "\n",
    "\n",
    "#Get old ICM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'alNone'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-195-7d21ccf71c0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \"\"\"\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_to_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"alNone\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'alNone'"
     ]
    }
   ],
   "source": [
    "ICM_all.shape\n",
    "\"\"\"\n",
    "with open(\"output/content_tags.txt\",'w') as f:\n",
    "    for content in content_to_index: \n",
    "        f.write(content+\"\\n\")\n",
    "\"\"\"\n",
    "print(content_to_index[\"alNone\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ICM!\n"
     ]
    }
   ],
   "source": [
    "#Save the ICM\n",
    "\n",
    "sps.save_npz(\"Saved Matrixes/ICM_all_coo\", ICM_all)\n",
    "print(\"Saved ICM!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted\n"
     ]
    }
   ],
   "source": [
    "#Let's convert to csr. \n",
    "ICM_all = ICM_all.tocsr()\n",
    "print(\"Converted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1316175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3885714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3091270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>226759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   track_id\n",
       "0   1316175\n",
       "1   3885714\n",
       "2   3091270\n",
       "3    226759\n",
       "4    230596"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_tracks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_target_item_filter(indices):\n",
    "    target_filter = np.zeros((indices), dtype = bool)\n",
    "    for track in target_tracks.values:\n",
    "        track_id = track[0]\n",
    "        track_index = track_to_index[track_id]\n",
    "        target_filter[track_index] = True\n",
    "    print(\"Created filter preserving %s out of %s \" %(np.count_nonzero(target_filter),target_filter.shape[0]))\n",
    "    return target_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 4])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= np.array([1, 2, 3, 4])\n",
    "f = [True, False, True, True]\n",
    "a[f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t0.0\n",
      "  (0, 1)\t0.619816950386\n",
      "  (0, 2)\t0.858783595106\n",
      "  (1, 0)\t0.649576808799\n",
      "  (1, 1)\t0.0\n",
      "  (1, 2)\t0.0\n",
      "  (2, 0)\t0.0\n",
      "  (2, 1)\t0.735067713547\n",
      "  (2, 2)\t0.88801706132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/philipclaesson/anaconda3/lib/python3.6/site-packages/scipy/sparse/compressed.py:274: SparseEfficiencyWarning: Comparing a sparse matrix with a scalar greater than zero using <= is inefficient, try using > instead.\n",
      "  warn(bad_scalar_msg, SparseEfficiencyWarning)\n"
     ]
    }
   ],
   "source": [
    "a = sps.csr_matrix(np.random.rand(3,3))\n",
    "a[0.5 >= a] = 0\n",
    "\n",
    "#print(sps.csr_matrix(a.todense()))\n",
    "print(a)\n",
    "\n",
    "# Vi har en csr.\n",
    "\n",
    "# om vi loopar igenom den och plockar bort noise, sedan skapar ny matrix. \n",
    "\n",
    "\n",
    "#print(sps.csr_matrix(a.toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated ids to indexes.\n",
      "Built URM_train with shape 57560,100000\n",
      "Built URM_test\n",
      "Total datapoints: 1040522. Expected: 1040522\n",
      "(57560, 100000)\n",
      "(57560, 100000)\n"
     ]
    }
   ],
   "source": [
    "def build_URM(train_test_split = 0.80):\n",
    "    #Builds urm \n",
    "    \n",
    "    #train_test_split = 1\n",
    "    \n",
    "    numInteractions = train_final.shape[0]\n",
    "\n",
    "    train_mask = np.random.choice(a = [True,False], size = numInteractions, p = [train_test_split, 1-train_test_split])\n",
    "    \n",
    "    playlistList = train_final['playlist_id'].values\n",
    "    itemList = train_final['track_id'].values\n",
    "\n",
    "    #Translate ids\n",
    "    playlistList_translated = np.zeros(playlistList.shape)\n",
    "    itemList_translated = np.zeros(itemList.shape)\n",
    "    ratingList = np.ones((playlistList.shape), int)\n",
    "    \n",
    "    for i in range(train_final.shape[0]):\n",
    "        playlistList_translated[i] = playlist_to_index[playlistList[i]]\n",
    "        itemList_translated[i] = track_to_index[itemList[i]]\n",
    "    print(\"Translated ids to indexes.\")\n",
    "    \n",
    "    #Build URM matrix. \n",
    "    URM_train = sps.coo_matrix((ratingList[train_mask], (playlistList_translated[train_mask], itemList_translated[train_mask])))\n",
    "    URM_train = URM_train.tocsr()\n",
    "    print(\"Built URM_train with shape %s,%s\" %(URM_train.shape[0],URM_train.shape[1]))\n",
    "    \n",
    "    if train_test_split < 1: \n",
    "        #Build URM_test\n",
    "        test_mask = np.logical_not(train_mask)\n",
    "        URM_test = sps.coo_matrix((ratingList[test_mask], (playlistList_translated[test_mask], itemList_translated[test_mask])))\n",
    "        URM_test = URM_test.tocsr()\n",
    "        print(\"Built URM_test\")\n",
    "        testsize = (test_mask[test_mask == True].shape[0])\n",
    "\n",
    "    else: \n",
    "        URM_test = sps.csc_matrix((10, 10), dtype=np.int8)\n",
    "        testsize = 0\n",
    "    \n",
    "    \n",
    "    trainsize = train_mask[train_mask == True].shape[0]\n",
    "    totsize = trainsize + testsize\n",
    "    print(\"Total datapoints: %s. Expected: %s\" %(totsize,numInteractions))\n",
    "\n",
    "    \n",
    "    print(URM_train.shape)\n",
    "    print(URM_test.shape)\n",
    "    \n",
    "    return URM_train, URM_test\n",
    "\n",
    "URM_train, URM_test = build_URM(0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URM_train contains 832279 interactions. Expected 1040422\n",
      "Train: 0.7963. Test: 0.2037\n"
     ]
    }
   ],
   "source": [
    "#Testing the URM builder.\n",
    "print(\"URM_train contains %s interactions. Expected 1040422\" %URM_train.nnz)\n",
    "testcount = 0\n",
    "traincount = 0\n",
    "itr = 10000\n",
    "for playlist_id, track_id in train_final[0:itr].values: \n",
    "    if (URM_train[playlist_to_index[playlist_id],track_to_index[track_id]]) > 0: \n",
    "        #print(\"Playlist %s with index %s and track %s with index %s was not in URM_train.\" %(playlist_id, playlist_to_index[playlist_id],track_id, track_to_index[track_id]))\n",
    "        traincount += 1\n",
    "    elif (URM_test[playlist_to_index[playlist_id],track_to_index[track_id]]) > 0:\n",
    "        testcount += 1\n",
    "        \n",
    "print(\"Train: %s. Test: %s\"%(traincount/itr, testcount/itr))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Evaluation functions\n",
    "\n",
    "def precision(recommended_items, relevant_items):\n",
    "    \n",
    "    is_relevant = np.in1d(recommended_items, relevant_items, assume_unique=True)\n",
    "    \n",
    "    precision_score = np.sum(is_relevant, dtype=np.float32) / len(is_relevant)\n",
    "    \n",
    "    return precision_score\n",
    "\n",
    "def recall(recommended_items, relevant_items):\n",
    "    \n",
    "    is_relevant = np.in1d(recommended_items, relevant_items, assume_unique=True)\n",
    "    \n",
    "    recall_score = np.sum(is_relevant, dtype=np.float32) / relevant_items.shape[0]\n",
    "    \n",
    "    return recall_score\n",
    "\n",
    "def MAP(recommended_items, relevant_items):\n",
    "   \n",
    "    is_relevant = np.in1d(recommended_items, relevant_items, assume_unique=True)\n",
    "    \n",
    "    # Cumulative sum: precision at 1, at 2, at 3 ...\n",
    "    p_at_k = is_relevant * np.cumsum(is_relevant, dtype=np.float32) / (1 + np.arange(is_relevant.shape[0]))\n",
    "    \n",
    "    map_score = np.sum(p_at_k) / np.min([relevant_items.shape[0], is_relevant.shape[0]])\n",
    "\n",
    "    return map_score\n",
    "\n",
    "def evaluate_algorithm(URM_test, recommendations, at=5):\n",
    "    \n",
    "    starttime = time.time()\n",
    "    cumulative_precision = 0.0\n",
    "    cumulative_recall = 0.0\n",
    "    cumulative_MAP = 0.0\n",
    "    \n",
    "    num_eval = 0\n",
    "    \n",
    "    playlists = target_playlists['playlist_id']\n",
    "\n",
    "    for i, playlist_id in enumerate(playlists):\n",
    "        \n",
    "        if i % 500 == 0:\n",
    "            print(\"User %d of %d, %d sec.\" % (i, len(playlists), round(time.time()-starttime)))\n",
    "\n",
    "        relevant_items = URM_test[playlist_to_index[playlist_id]].indices\n",
    "        \n",
    "        if len(relevant_items)>0:\n",
    "            \n",
    "            recommended_items = recommendations.iloc[i,1:6]\n",
    "            num_eval+=1\n",
    "\n",
    "            cumulative_precision += precision(recommended_items, relevant_items)\n",
    "            cumulative_recall += recall(recommended_items, relevant_items)\n",
    "            cumulative_MAP += MAP(recommended_items, relevant_items)\n",
    "\n",
    "\n",
    "    cumulative_precision /= num_eval\n",
    "    cumulative_recall /= num_eval\n",
    "    cumulative_MAP /= num_eval\n",
    "    \n",
    "    print(\"Recommender performance is: Precision = {:.4f}, Recall = {:.4f}, MAP = {:.4f}\".format(\n",
    "        cumulative_precision, cumulative_recall, cumulative_MAP))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asd\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "class Recommender(object):\n",
    "    def __init__(self, URM, target_items, item_ids, k=50, shrinkage=100, similarity='cosine'):\n",
    "        self.dataset = URM\n",
    "        self.target_items = target_items\n",
    "        self.target_item_filter = get_target_item_filter(tracks_final.shape[0])\n",
    "        self.item_ids = item_ids\n",
    "        self.k = k\n",
    "        self.shrinkage = shrinkage\n",
    "        self.similarity_name = similarity\n",
    "        \n",
    "        self.UIM = None\n",
    "        \n",
    "        if similarity == 'cosine':\n",
    "            self.distance = Cosine(shrinkage=self.shrinkage)\n",
    "        elif similarity == 'pearson':\n",
    "            self.distance = Pearson(shrinkage=self.shrinkage)\n",
    "        elif similarity == 'adj-cosine':\n",
    "            self.distance = AdjustedCosine(shrinkage=self.shrinkage)\n",
    "        else:\n",
    "            raise NotImplementedError('Distance {} not implemented'.format(similarity))\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"Recommender(similarity={},k={},shrinkage={})\".format(self.similarity_name, self.k, self.shrinkage)\n",
    "\n",
    "    def fit(self, X):\n",
    "        cp = time.time()\n",
    "        #Calculate cosine similarity\n",
    "        ISM = self.distance.compute(X) \n",
    "        print(\"Computed Item-Item similarity matrix. %s \" %(time.time()-cp))\n",
    "        cp = time.time()\n",
    "        \n",
    "        \n",
    "        URM = check_matrix(self.dataset, 'csr')\n",
    "        \n",
    "        print(\"Converted URM to csc %s \" %(time.time()-cp))\n",
    "        cp = time.time()\n",
    "        \n",
    "        ISM = check_matrix(ISM, 'csr')\n",
    "        print(\"Converted ISM to csc %s \" %(time.time()-cp))\n",
    "        cp = time.time()\n",
    "        \n",
    "        #Filter not targeted tracks. (U x tI). self.target_item_filter has tracks_final.shape[0] as length. \n",
    "        print(\"Nnz: %s\" %(URM.nnz))\n",
    "        \n",
    "        print(URM.shape)\n",
    "        print(self.target_item_filter.shape)\n",
    "        #URM[:,self.target_item_filter.T] = 0\n",
    "        #ISM[self.target_item_filter,self.target_item_filter.T] = 0\n",
    "        \n",
    "        print(\"Filtered not target tracks. %\" %(time.time()-cp))\n",
    "        print(\"Nnz: %s\" %(URM.nnz))\n",
    "        \n",
    "        \n",
    "        \n",
    "        #Multiply URM * ISM (U x I * I x I = U x I)\n",
    "        print(URM.shape)\n",
    "        print(ISM.shape)\n",
    "        \n",
    "        #UIM = URM * ISM\n",
    "        #print(\"Computed UIM. %s\" %(time.time()-cp))\n",
    "        #cp = time.time()\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        cp = time.time()\n",
    "        \n",
    "        \n",
    "        \n",
    "        #This U x tI UIM can now be used by the recommender function. \n",
    "        \n",
    "        self.W_sparse = UIM\n",
    "\n",
    "    def fit_new(self, X, noise = 0.1):\n",
    "        \n",
    "        ## GET ISM MATRIX (I X I)\n",
    "        cp = time.time()\n",
    "        #Calculate cosine similarity\n",
    "        print(\"Lets compute distance.\")\n",
    "        ISM = self.distance.compute(X) \n",
    "        print(\"Computed Item-Item similarity matrix. %s \" %(time.time()-cp))\n",
    "        cp = time.time()\n",
    "        \n",
    "        ##GET URM (U X I)\n",
    "        \n",
    "        URM = self.dataset\n",
    "        \n",
    "        ## GET item_ids (1 x I)\n",
    "        \n",
    "        #self.item_ids\n",
    "        \n",
    "        ## FILTER item_ids INTO target_item_ids (1 x tI)\n",
    "        \n",
    "        self.target_item_ids = track_ids[self.target_item_filter]\n",
    "        print(URM.nnz)\n",
    "        print(ISM.nnz)\n",
    "        \n",
    "        ## FILTER TARGETED TRACKS\n",
    "        #Maybe this is not working as expected - are we filtering the right tracks? \n",
    "        \n",
    "        ISM = ISM[:,self.target_item_filter]\n",
    "        print(\"Filtered targeted tracks in ISM. %s \" %(time.time()-cp))\n",
    "        cp = time.time()\n",
    "        \n",
    "        #self.ISM = sps.csr_matrix(self.ISM)\n",
    "        \n",
    "        cp = time.time()  \n",
    "        print(URM.nnz)\n",
    "        #ISM = sps.csr_matrix(ISM)\n",
    "        print(ISM.nnz)\n",
    "        \n",
    "        ## CONVERT URM TO CSR\n",
    "        URM = check_matrix(URM, 'csr')\n",
    "        print(\"Checked URM csr %s \" %(time.time()-cp))\n",
    "        cp = time.time()\n",
    "        \n",
    "        ##Print dimension\n",
    "        print(URM.shape)\n",
    "        print(ISM.shape)\n",
    "        \n",
    "        ## MULTIPLY URM (U x I) * ISM (I x I)\n",
    "        UIM = URM.dot(ISM)\n",
    "        print(\"Computed URM * ISM %s \" %(time.time()-cp))\n",
    "        cp = time.time()\n",
    "        \n",
    "\n",
    "        \n",
    "        ## MAKE NOT SPARSE\n",
    "        #UIM_dense = UIM.todense()\n",
    "        \n",
    "        ## FILTER UIM into (U x tI) (not needed since I already filtered!)\n",
    "        #UIM_dense = UIM_dense[:,self.target_item_filter]\n",
    "        \n",
    "        ## THIS IS OUR FITTED MODEL\n",
    "        self.UIM = UIM\n",
    "        \n",
    "        return self.UIM\n",
    "\n",
    "        \n",
    "    def recommend_new(self, user_id, at = 5):\n",
    "        ## GET USER_INDEX\n",
    "        user_index = playlist_to_index[user_id]\n",
    "        \n",
    "        # Convert to np.array (why wasn't it before?!)\n",
    "        self.target_item_ids = np.array(self.target_item_ids)\n",
    "        \n",
    "        ## GET ROW CORRESPONDING TO USER (1 x tI)\n",
    "        user_weights = self.UIM[user_index,:].toarray()\n",
    "             \n",
    "        ## ARGSORT BASED ON AXIS = 0, GET [1,0:at]\n",
    "        top_indexes = np.argsort(user_weights)#[-at:]\n",
    "        top_k_indexes = top_indexes[0, -at:]\n",
    "\n",
    "        ## Translate to indexes\n",
    "        recommendations = self.target_item_ids[top_k_indexes]\n",
    "        \n",
    "        ## RETURN RECOMMENDATIONS\n",
    "        return(recommendations)\n",
    "    \n",
    "    def recommend_dev(self, user_id, at = 5):\n",
    "        print(\"Recommend %s items for user %s!\" %(at, user_id))\n",
    "        ## GET USER_INDEX\n",
    "        user_index = playlist_to_index[user_id]\n",
    "        \n",
    "        # Convert to np.array (why wasn't it before?!)\n",
    "        self.target_item_ids = np.array(self.target_item_ids)\n",
    "        \n",
    "        ## GET ROW CORRESPONDING TO USER (1 x tI)\n",
    "        user_weights = self.UIM[user_index,:].toarray()\n",
    "             \n",
    "        ## ARGSORT BASED ON AXIS = 0, GET [1,0:at]\n",
    "        top_indexes = np.argsort(user_weights)#[-at:]\n",
    "        print(top_indexes.shape)\n",
    "        top_k_indexes = top_indexes[0, -at:]\n",
    "        print(top_k_indexes.shape)\n",
    "\n",
    "        ## Translate to indexes\n",
    "        recommendations = self.target_item_ids[top_k_indexes]\n",
    "        \n",
    "        ## RETURN RECOMMENDATIONS\n",
    "        return(recommendations)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def recommend(self, user_id, at=None, exclude_seen=True):\n",
    "        # compute the scores using the dot product\n",
    "        user_profile = self.dataset[user_id]\n",
    "        print(\"User profile: %s\" %(user_profile))\n",
    "        scores = user_profile.dot(self.W_sparse).toarray().ravel()\n",
    "        print(\"Scores: %s\" %(scores))\n",
    "        # rank items\n",
    "        ranking = scores.argsort()[::-1]\n",
    "        if exclude_seen:\n",
    "            ranking = self._filter_seen(user_id, ranking)\n",
    "        \n",
    "        print(\"Ranking: %s\" %(ranking))\n",
    "        \n",
    "        export = [0,0,0,0,0]\n",
    "        for i in range(5):\n",
    "            t_id = track_to_id[ranking[i]]\n",
    "            export[i] = t_id\n",
    "            \n",
    "        return export\n",
    "    def _filter_seen(self, user_id, ranking):\n",
    "        user_profile = self.dataset[user_id]\n",
    "        seen = user_profile.indices\n",
    "        unseen_mask = np.in1d(ranking, seen, assume_unique=True, invert=True)\n",
    "        return ranking[unseen_mask]\n",
    "\n",
    "print(\"asd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 5 4]\n",
      "[4 6 7]\n"
     ]
    }
   ],
   "source": [
    "##TESTING\n",
    "\n",
    "\n",
    "user_weights = [1,2,4,3,7,6,1]\n",
    "target_item_ids = np.array([1,2,4,3,7,6,1])\n",
    "at = 3\n",
    "## ARGSORT BASED ON AXIS = 0, GET [1,0:at]\n",
    "top_indexes = np.argsort(user_weights)[-at:]\n",
    "print(top_indexes)\n",
    "## Translate to indexes\n",
    "recommendations = target_item_ids[top_indexes]\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created filter preserving 32195 out of 100000 \n",
      "(100000,)\n",
      "(100000,)\n"
     ]
    }
   ],
   "source": [
    "target_item_filter = get_target_item_filter(tracks_final.shape[0])\n",
    "print(target_item_filter.shape)\n",
    "print(track_ids.shape)\n",
    "target_item_ids = track_ids[target_item_filter]\n",
    "\n",
    "#print(target_item_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_matrix(X, format='csc', dtype=np.float32):\n",
    "    if format == 'csc' and not isinstance(X, sps.csc_matrix):\n",
    "        return X.tocsc().astype(dtype)\n",
    "    elif format == 'csr' and not isinstance(X, sps.csr_matrix):\n",
    "        return X.tocsr().astype(dtype)\n",
    "    elif format == 'coo' and not isinstance(X, sps.coo_matrix):\n",
    "        return X.tocoo().astype(dtype)\n",
    "    elif format == 'dok' and not isinstance(X, sps.dok_matrix):\n",
    "        return X.todok().astype(dtype)\n",
    "    elif format == 'bsr' and not isinstance(X, sps.bsr_matrix):\n",
    "        return X.tobsr().astype(dtype)\n",
    "    elif format == 'dia' and not isinstance(X, sps.dia_matrix):\n",
    "        return X.todia().astype(dtype)\n",
    "    elif format == 'lil' and not isinstance(X, sps.lil_matrix):\n",
    "        return X.tolil().astype(dtype)\n",
    "    else:\n",
    "        return X.astype(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class ISimilarity(object):\n",
    "    \"\"\"Abstract interface for the similarity metrics\"\"\"\n",
    "\n",
    "    def __init__(self, shrinkage=10):\n",
    "        self.shrinkage = shrinkage\n",
    "\n",
    "    def compute(self, X):\n",
    "        pass\n",
    "\n",
    "\n",
    "class Cosine(ISimilarity):\n",
    "    def compute(self, X):\n",
    "        # convert to csc matrix for faster column-wise operations\n",
    "        X = check_matrix(X, 'csc', dtype=np.float32)\n",
    "        print(\"Converted to csc.\")\n",
    "        # 1) normalize the columns in X\n",
    "        # compute the column-wise norm\n",
    "        # NOTE: this is slightly inefficient. We must copy X to compute the column norms.\n",
    "        # A faster solution is to  normalize the matrix inplace with a Cython function.\n",
    "        Xsq = X.copy()\n",
    "        Xsq.data **= 2\n",
    "        norm = np.sqrt(Xsq.sum(axis=0))\n",
    "        norm = np.asarray(norm).ravel()\n",
    "        norm += 1e-6\n",
    "        # compute the number of non-zeros in each column\n",
    "        # NOTE: this works only if X is instance of sparse.csc_matrix\n",
    "        col_nnz = np.diff(X.indptr)\n",
    "        # then normalize the values in each column\n",
    "        X.data /= np.repeat(norm, col_nnz)\n",
    "        print(\"Normalized\")\n",
    "\n",
    "        # 2) compute the cosine similarity using the dot-product\n",
    "        dist = X * X.T\n",
    "        print(\"Computed\")\n",
    "        \n",
    "        # zero out diagonal values\n",
    "        dist = dist - sps.dia_matrix((dist.diagonal()[scipy.newaxis, :], [0]), shape=dist.shape)\n",
    "        print(\"Removed diagonal\")\n",
    "        \n",
    "        # and apply the shrinkage\n",
    "        if self.shrinkage > 0:\n",
    "            dist = self.apply_shrinkage(X, dist)\n",
    "            print(\"Applied shrinkage\")    \n",
    "        \n",
    "        return dist\n",
    "\n",
    "    def apply_shrinkage(self, X, dist):\n",
    "        # create an \"indicator\" version of X (i.e. replace values in X with ones)\n",
    "        X_ind = X.copy()\n",
    "        X_ind.data = np.ones_like(X_ind.data)\n",
    "        # compute the co-rated counts\n",
    "        co_counts = X_ind * X_ind.T\n",
    "        # remove the diagonal\n",
    "        co_counts = co_counts - sps.dia_matrix((co_counts.diagonal()[scipy.newaxis, :], [0]), shape=co_counts.shape)\n",
    "        # compute the shrinkage factor as co_counts_ij / (co_counts_ij + shrinkage)\n",
    "        # then multiply dist with it\n",
    "        co_counts_shrink = co_counts.copy()\n",
    "        co_counts_shrink.data += self.shrinkage\n",
    "        co_counts.data /= co_counts_shrink.data\n",
    "        dist.data *= co_counts.data\n",
    "        return dist\n",
    "    \n",
    "    def remove_noise(self, X, noise):\n",
    "        X = check_matrix(X, 'csc', dtype=np.float32)\n",
    "        i = 0\n",
    "        for row in X:\n",
    "            r = row\n",
    "            row[row > noise] = 1\n",
    "            row[row <= noise] = 0\n",
    "\n",
    "            X[i,:] = r[row]\n",
    "            i += 1\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.64419709  0.48003901  0.67558476]]\n",
      "0.644197087836\n",
      "[[ 0.37399985  0.04801194  0.75656208]]\n",
      "0.373999853518\n",
      "[[ 0.57302005  0.36191736  0.4023458 ]]\n",
      "0.402345796465\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def kkeep_k_largest(X, k):\n",
    "    \n",
    "    M = X.todense()\n",
    "    for row in M: \n",
    "        top_k_idx = np.argsort(row)\n",
    "        print(row)\n",
    "        print(row[0,top_k_idx[0,-k]])\n",
    "        \n",
    "    \n",
    "    \n",
    "a = sps.csr_matrix(np.random.rand(3,3))\n",
    "print(kkeep_k_largest(a,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: Can we create a \"better\" URM by matrix factorization? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with train_rate 1\n",
      "Translated ids to indexes.\n",
      "Built URM_train with shape 57560,100000\n",
      "Total datapoints: 1040522. Expected: 1040522\n",
      "(57560, 100000)\n",
      "(10, 10)\n",
      "Created filter preserving 32195 out of 100000 \n",
      "Lets compute distance.\n",
      "Converted to csc.\n",
      "Normalized\n",
      "Computed\n",
      "Removed diagonal\n",
      "Applied shrinkage\n",
      "Computed Item-Item similarity matrix. 339.1293377876282 \n",
      "1040522\n",
      "1731644528\n",
      "Filtered targeted tracks in ISM. 56.400501012802124 \n",
      "1040522\n",
      "608798909\n",
      "Checked URM csr 0.09475302696228027 \n",
      "(57560, 100000)\n",
      "(100000, 32195)\n",
      "Computed URM * ISM 75.79554510116577 \n",
      "Fitted in 472.06158900260925 seconds\n"
     ]
    }
   ],
   "source": [
    "#This is the main script! \n",
    "\n",
    "\n",
    "#1. Fitting the model. \n",
    "\n",
    "#If export is true, the recommendations will be written to file. \n",
    "#If false, evaluation method can be used. \n",
    "export = True\n",
    "\n",
    "if export:\n",
    "    train_rate = 1\n",
    "else:\n",
    "    train_rate = 0.8\n",
    "print(\"Running with train_rate %s\" %(train_rate))\n",
    "\n",
    "URM_train, URM_test = build_URM(train_rate)\n",
    "\n",
    "import time\n",
    "starttime = time.time()\n",
    "rec = Recommender(URM=URM_train, target_items = target_tracks, item_ids = track_ids, shrinkage=30.0)\n",
    "#ICM_idf = ICM_add_IDF(ICM_all)\n",
    "ISM = rec.fit_new(ICM_all) ##Saving outside for quicker restarts. \n",
    "#rec.fit_bad(ICM_all, k = 2000)\n",
    "print(\"Fitted in %s seconds\" %(time.time()-starttime))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 10000 playlists, 0.002023935317993164 sec.\n",
      "1000 out of 10000 playlists, 2.344505786895752 sec.\n",
      "2000 out of 10000 playlists, 4.498498916625977 sec.\n",
      "3000 out of 10000 playlists, 6.7699198722839355 sec.\n",
      "4000 out of 10000 playlists, 9.017293930053711 sec.\n",
      "5000 out of 10000 playlists, 11.37050175666809 sec.\n",
      "6000 out of 10000 playlists, 13.708664894104004 sec.\n",
      "7000 out of 10000 playlists, 16.11584782600403 sec.\n",
      "8000 out of 10000 playlists, 18.46193289756775 sec.\n",
      "9000 out of 10000 playlists, 20.63483476638794 sec.\n",
      "Saved to file: \n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#2. Creating recommendations. \n",
    "zeros = np.zeros((target_playlists.size, 6), dtype = int)\n",
    "recommendations = pd.DataFrame(zeros)\n",
    "recommendations.columns = ['playlist_id', 1, 2, 3, 4, 5]\n",
    "\n",
    "counter = 0\n",
    "starttime = time.time()\n",
    "for playlist_id in target_playlists['playlist_id']:\n",
    "\n",
    "    if counter % 1000 == 0: \n",
    "        print (\"%s out of 10000 playlists, %s sec.\" %(counter, time.time()-starttime))\n",
    "\n",
    "    playlist_id_translated = playlist_to_index[int(playlist_id)]\n",
    "    recommendations.iloc[counter, 1:6] = rec.recommend_new(playlist_id, 5)\n",
    "    recommendations.iloc[counter, 0] = playlist_id\n",
    "    counter += 1\n",
    "\n",
    "if export:\n",
    "    filename = \"recommendations_6/11_\"\n",
    "    np.savetxt(\"output/recommendations_20nov_4.csv\",recommendations, fmt = '%s,%s %s %s %s %s', header = \"playlist_id,track_ids\", newline = \"\\n\")\n",
    "    print(\"Saved to file: \")\n",
    "\n",
    "#print(recommendations)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57556, 74541)\n",
      "(57560, 74542)\n",
      "User 0 of 10000, 0 sec.\n",
      "User 500 of 10000, 0 sec.\n",
      "User 1000 of 10000, 1 sec.\n",
      "User 1500 of 10000, 1 sec.\n",
      "User 2000 of 10000, 1 sec.\n",
      "User 2500 of 10000, 1 sec.\n",
      "User 3000 of 10000, 1 sec.\n",
      "User 3500 of 10000, 2 sec.\n",
      "User 4000 of 10000, 2 sec.\n",
      "User 4500 of 10000, 2 sec.\n",
      "User 5000 of 10000, 2 sec.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index (57559) out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-96c640e0a161>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mURM_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mevaluate_algorithm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mURM_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecommendations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-96-b66d963f2241>\u001b[0m in \u001b[0;36mevaluate_algorithm\u001b[0;34m(URM_test, recommendations, at)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"User %d of %d, %d sec.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplaylists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstarttime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mrelevant_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mURM_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mplaylist_to_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mplaylist_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelevant_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/sparse/csr.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0;31m# [i, 1:2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_row_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m             \u001b[0;31m# [i, [1, 2]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0missequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/sparse/csr.py\u001b[0m in \u001b[0;36m_get_row_slice\u001b[0;34m(self, i, cslice)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'index (%d) out of range'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcslice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index (57559) out of range"
     ]
    }
   ],
   "source": [
    "# 3. Want to evaluate? \n",
    "print(URM_test.shape)\n",
    "print(URM_train.shape)\n",
    "\n",
    "evaluate_algorithm(URM_test, recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 50000 were not in the target.\n"
     ]
    }
   ],
   "source": [
    "# Does the recommender rec just targeted tracks? \n",
    "def test_all_rec_in_target(recommendations):\n",
    "    tt = target_tracks.values\n",
    "    recommendations = recommendations.as_matrix()\n",
    "    notcount = 0\n",
    "    count = 0\n",
    "    for row in recommendations: \n",
    "        for item in row[1:6]: \n",
    "            count += 1\n",
    "            if item not in tt: \n",
    "                notcount += 1\n",
    "                #print(\"Rec not in target! %s\" %item)\n",
    "    print(\"%s out of %s were not in the target.\" %(notcount, count))\n",
    "    \n",
    "test_all_rec_in_target(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TESTING THE REC FUNCTION - SHOULD WORK\n",
    "#Fitted in 172.8 seconds\n",
    "\n",
    "rec_dev = Recommender(URM=URM_train, target_items = target_tracks, item_ids = track_ids, shrinkage=0.0)\n",
    "rec_dev.UIM = rec.UIM\n",
    "rec_dev.target_item_ids = rec.target_item_ids\n",
    "\n",
    "zeros = np.zeros((1, 6), dtype = int)\n",
    "recommendations = pd.DataFrame(zeros)\n",
    "recommendations.columns = ['playlist_id', 1, 2, 3, 4, 5]\n",
    "recommendations.iloc[counter, 1:6] = rec_dev.recommend_dev(playlist_to_id[30680], 5)\n",
    "recommendations.iloc[counter, 0] = playlist_to_id[30680]\n",
    "\n",
    "print(recommendations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "starttime = time.time()\n",
    "rec = Recommender(URM=URM_train, shrinkage=0.0)\n",
    "rec.fit(ICM_all)\n",
    "print(\"Done in %s seconds\" %(time.time()-starttime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ICM_add_IDF(ICM): \n",
    "    num_tot_items = ICM_all.shape[0]\n",
    "\n",
    "    # let's count how many items have a certain feature\n",
    "    items_per_feature = (ICM_all > 0).sum(axis=0)\n",
    "\n",
    "    IDF = np.array(np.log(num_tot_items / items_per_feature))[0]\n",
    "\n",
    "    print(ICM_all.shape)\n",
    "    print(IDF.shape)\n",
    "    ICM_idf = sps.csr_matrix(ICM_all, dtype=np.float64)\n",
    "    # compute the number of non-zeros in each col\n",
    "    # NOTE: this works only if X is instance of sparse.csc_matrix\n",
    "    col_nnz = np.diff(check_matrix(ICM_idf, 'csc').indptr)\n",
    "    print(col_nnz.shape)\n",
    "    print(ICM_idf.shape)\n",
    "    print(IDF.shape)\n",
    "    # then normalize the values in each col\n",
    "    ICM_idf.data *= np.repeat(IDF, col_nnz)\n",
    "    return ICM_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rec_idf = BasicItemKNNRecommender(URM=URM_train, shrinkage=0.0, k=50)\n",
    "rec_idf.fit(ICM_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluate_algorithm(URM_test, rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_to_file():\n",
    "    #Saves the recommendations dataframe to the .csv-file. \n",
    "    np.savetxt(\"output/recommendations_more_content.csv\",recommendations, fmt = '%s,%s %s %s %s %s', header = \"playlist_id,track_ids\", newline = \"\\n\")\n",
    "    \n",
    "    \n",
    "def test():\n",
    "    #Do something\n",
    "    print(\"Result: \")\n",
    "    pass\n",
    "\n",
    "\n",
    "save_to_file()\n",
    "print(recommendations.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
