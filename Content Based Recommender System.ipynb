{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse as sps\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n",
    "#train_final.csv - the training set of interactions\n",
    "train_final = pd.read_csv('input/train_final.csv', delimiter = \"\\t\");\n",
    "\n",
    "#tracks_final.csv - supplementary information about the items\n",
    "tracks_final = pd.read_csv('input/tracks_final.csv', delimiter = \"\\t\");\n",
    "\n",
    "#playlists_final.csv - supplementary information about the users\n",
    "playlists_final = pd.read_csv('input/playlists_final.csv', delimiter = \"\\t\");\n",
    "\n",
    "#target_playlists.csv - the set of target playlists that will receive recommendations\n",
    "target_playlists = pd.read_csv('input/target_playlists.csv');\n",
    "\n",
    "#target_tracks.csv - the set of target items (tracks) to be recommended\n",
    "target_tracks = pd.read_csv('input/target_tracks.csv');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_final now contains 731373 interactions. \n",
      "Tracks_final now contains 41756 tracks. \n"
     ]
    }
   ],
   "source": [
    "#This step is not needed yet, will make ratings worse! \n",
    "\n",
    "def get_relevant_tracks():\n",
    "    #Now we want to remove some redundant stuff. \n",
    "\n",
    "    #We will remove all songs which are not occurring more than 10 times in train_final\n",
    "    #Nevertheless, we still want to keep all tracks which are in the target tracks.  \n",
    "\n",
    "    popularity = train_final.groupby(by=\"track_id\").playlist_id.nunique().to_frame()\n",
    "\n",
    "    #remove index name\n",
    "    popularity.reset_index(level = 0, inplace = True)\n",
    "\n",
    "    #Rename the columns\n",
    "    popularity.columns = ['track_id','occurrences']\n",
    "\n",
    "    #Remove all targeted tracks - TESTED, working as expected\n",
    "    tracks_relevant = popularity[~popularity['track_id'].isin(target_tracks['track_id'])]\n",
    "\n",
    "    #Remove tracks occurring less than 10 times\n",
    "    tracks_relevant = tracks_relevant[tracks_relevant['occurrences'] > 10]\n",
    "\n",
    "    #Add the targeteted tracks back again\n",
    "    tracks_relevant = pd.concat([tracks_relevant, target_tracks])\n",
    "\n",
    "    return(tracks_relevant)\n",
    "\n",
    "    print(\"Removed %s redundant tracks which occured less than 10 times.\" %(tracks_final-tracks_relevant))\n",
    "\n",
    "tracks_relevant = get_relevant_tracks()\n",
    "\n",
    "#Remove irrelevant tracks from train_final and tracks_final\n",
    "train_final = train_final[train_final['track_id'].isin(tracks_relevant['track_id'])]\n",
    "\n",
    "print(\"Train_final now contains %s interactions. \" %(train_final.shape[0]))\n",
    "\n",
    "tracks_final = tracks_final[tracks_final['track_id'].isin(tracks_relevant['track_id'])]\n",
    "\n",
    "print(\"Tracks_final now contains %s tracks. \"%(tracks_final.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<57561x41756 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 0 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>duration</th>\n",
       "      <th>playcount</th>\n",
       "      <th>album</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2972914</td>\n",
       "      <td>144</td>\n",
       "      <td>224000</td>\n",
       "      <td>49.0</td>\n",
       "      <td>[7]</td>\n",
       "      <td>[54087, 1757, 1718, 116712, 189631]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2750239</td>\n",
       "      <td>246</td>\n",
       "      <td>157000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[8]</td>\n",
       "      <td>[189631, 3424, 177424, 46208, 205245]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1550729</td>\n",
       "      <td>144</td>\n",
       "      <td>217000</td>\n",
       "      <td>554.0</td>\n",
       "      <td>[9]</td>\n",
       "      <td>[54087, 109806, 46869, 183258, 54337]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2169950</td>\n",
       "      <td>144</td>\n",
       "      <td>207000</td>\n",
       "      <td>200.0</td>\n",
       "      <td>[9]</td>\n",
       "      <td>[54087, 70618, 207003, 109806, 116712]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3387498</td>\n",
       "      <td>928</td>\n",
       "      <td>245000</td>\n",
       "      <td>9622.0</td>\n",
       "      <td>[31]</td>\n",
       "      <td>[81223, 189631, 205245, 4425, 50764]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    track_id  artist_id  duration  playcount album  \\\n",
       "0    2972914        144    224000       49.0   [7]   \n",
       "1    2750239        246    157000        1.0   [8]   \n",
       "2    1550729        144    217000      554.0   [9]   \n",
       "3    2169950        144    207000      200.0   [9]   \n",
       "11   3387498        928    245000     9622.0  [31]   \n",
       "\n",
       "                                      tags  \n",
       "0      [54087, 1757, 1718, 116712, 189631]  \n",
       "1    [189631, 3424, 177424, 46208, 205245]  \n",
       "2    [54087, 109806, 46869, 183258, 54337]  \n",
       "3   [54087, 70618, 207003, 109806, 116712]  \n",
       "11    [81223, 189631, 205245, 4425, 50764]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now lets take a look at the tags.\n",
    "tracks_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Translating all content ids into indexes.\n",
    "\n",
    "#We need to create buckets for the playcount and duration. \n",
    "#Lets create buckets and a help function for the duration. \n",
    "\n",
    "n_duration_buckets = 8\n",
    "def duration_to_bucket(duration):\n",
    "    if duration <= 0:\n",
    "        print(\"Null duration reached bucket function. \")\n",
    "        return None\n",
    "    elif duration < 90000: #not a song\n",
    "        return 1\n",
    "    elif duration < 140000: #short song\n",
    "        return 2\n",
    "    elif duration < 220000: #radio song\n",
    "        return 3\n",
    "    elif duration < 340000: #normal song\n",
    "        return 4\n",
    "    elif duration < 480000: #long song\n",
    "        return 5\n",
    "    elif duration < 720000: #really long\n",
    "        return 6\n",
    "    elif duration < 1200000: #super long\n",
    "        return 7\n",
    "    elif duration >= 1200000: #mixtape/compilation\n",
    "        return 8\n",
    "\n",
    "n_playcount_buckets = 7\n",
    "def playcount_to_bucket(playcount):\n",
    "    if playcount <= 0 or playcount is None:\n",
    "        print(\"Null playcount reached bucket function. \")\n",
    "        return None\n",
    "    elif playcount < 254: #0,4 percentile not popular\n",
    "        return 1\n",
    "    elif playcount < 881: #0,6 perc: known\n",
    "        return 2\n",
    "    elif playcount < 1560: #0,7 popular\n",
    "        return 3\n",
    "    elif playcount < 2808: #0,8 very popular\n",
    "        return 4\n",
    "    elif playcount < 5900: #0,9 hits\n",
    "        return 5\n",
    "    elif playcount < 10494: #0,95 super hits\n",
    "        return 6\n",
    "    elif playcount >= 10494: # mega hits\n",
    "        return 7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38042\n"
     ]
    }
   ],
   "source": [
    "tracks_final['tags'].head()\n",
    "\n",
    "content_to_index = {}\n",
    "content_to_id = {}\n",
    "content_counter = 0\n",
    "\n",
    "#Lets translate the tags to indexes. \n",
    "for row in tracks_final['tags']:\n",
    "    tags = row.strip('[ ]').split(', ')\n",
    "    for tag in tags:\n",
    "        if len(tag) > 0: \n",
    "            tag = \"t\"+tag\n",
    "            if not(tag in content_to_index):\n",
    "                content_to_index[tag] = content_counter\n",
    "                content_to_id[content_counter] = tag\n",
    "                content_counter += 1;\n",
    "                \n",
    "#Lets translate album into indexes\n",
    "for album in tracks_final['album']:\n",
    "    album = album.strip('[ ]')\n",
    "    if album != None and len(album) > 0: #None should not be considered content\n",
    "        album = \"al\"+album\n",
    "        if not(album in content_to_index):\n",
    "            content_to_index[album] = content_counter\n",
    "            content_to_id[content_counter] = album\n",
    "            content_counter += 1;\n",
    "\n",
    "#Lets translate artist_id into indexes\n",
    "for artist in tracks_final['artist_id']:\n",
    "    artist = str(artist)\n",
    "    artist = \"ar\"+artist\n",
    "    if not(artist in content_to_index):\n",
    "        content_to_index[artist] = content_counter\n",
    "        content_to_id[content_counter] = artist\n",
    "        content_counter += 1;\n",
    "        \n",
    "\n",
    "#Lets translate the duration buckets into indexes. \n",
    "for bucket in range(n_duration_buckets): \n",
    "    bucket = \"d\"+str(bucket+1)\n",
    "    content_to_index[bucket] = content_counter\n",
    "    content_to_id[content_counter] = bucket\n",
    "    \n",
    "    content_counter += 1\n",
    "\n",
    "#Lets translate the playcount buckets into indexes. \n",
    "for playcount in range(n_playcount_buckets): \n",
    "    playcount = \"p\"+str(playcount+1)\n",
    "    content_to_index[playcount] = content_counter\n",
    "    content_to_id[content_counter] = playcount\n",
    "    \n",
    "    content_counter += 1\n",
    "\n",
    "#Fun thing to try: can I add all duration/playcounts in one col, normalizing from 0-1? \n",
    "\n",
    "print(len(content_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 57561 playlists with 41756 unique tracks with 38042 unique content types. \n"
     ]
    }
   ],
   "source": [
    "#If we translate each track_id to a track_index which will serve as matrix index, we can save a lot of time. \n",
    "\n",
    "\n",
    "#We need a way to get from track_id to index in O(1).\n",
    "#Let's create a dictionary\n",
    "\n",
    "track_to_id = {}\n",
    "track_to_index = {}\n",
    "counter = 0; #We will start at 1, reserving col 0 for indexes.  \n",
    "for track_id in tracks_final['track_id']:\n",
    "    track_id = int(track_id)\n",
    "    track_to_index[track_id] = counter\n",
    "    track_to_id[counter] = track_id\n",
    "    counter += 1;\n",
    "    \n",
    "#and a way to get from playlist_id to index in O(1)\n",
    "\n",
    "\n",
    "playlist_to_index = {}\n",
    "playlist_to_id = {}\n",
    "counter = 0; \n",
    "for playlist_id in playlists_final['playlist_id']:\n",
    "    playlist_id = int(playlist_id)\n",
    "    playlist_to_index[playlist_id] = counter\n",
    "    playlist_to_id[counter] = playlist_id\n",
    "    counter += 1;\n",
    "    \n",
    "print(\"We have {} playlists with {} unique tracks with {} unique content types. \".format(len(playlist_to_index), len(track_to_index), len(content_to_index)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we can create an Item Content Matrix. \n",
    "\n",
    "#ICM_all = np.zeros((len(tracks_indexes), len(tags_indexes)), int)\n",
    "#ICM_all = sps.coo_matrix((len(track_to_index), len(content_to_index)), int)\n",
    "#print(ICM_all.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_final[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track 0 of 41756. 0.0 s sec.\n",
      "Track 5000 of 41756. 0.14 s sec.\n",
      "Track 10000 of 41756. 0.29 s sec.\n",
      "Track 15000 of 41756. 0.45 s sec.\n",
      "Track 20000 of 41756. 0.61 s sec.\n",
      "Track 25000 of 41756. 0.75 s sec.\n",
      "Track 30000 of 41756. 0.91 s sec.\n",
      "Track 35000 of 41756. 1.07 s sec.\n",
      "Track 40000 of 41756. 1.22 s sec.\n",
      "Built ICM matrix with 358848 content values.\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#So let's fill the ICM with our data.\n",
    "import math\n",
    "\n",
    "def build_ICM():\n",
    "    \n",
    "    no_interactions = 1000000\n",
    "    \n",
    "    tracks_matrix = tracks_final.as_matrix()\n",
    "    rows = np.zeros((no_interactions,), dtype = int)\n",
    "    cols = np.zeros((no_interactions,), dtype = int)\n",
    "    #val[i] = value of row[i] col[i]\n",
    "    #val = []\n",
    "    counter = 0\n",
    "    starttime = time.time()\n",
    "    lasttime = starttime\n",
    "    trackno = 0\n",
    "    for track in tracks_matrix: \n",
    "        track_id, artist_id, duration, playcount, album, tags = np.split(track, 6)\n",
    "\n",
    "        #Get track index\n",
    "        track_index = track_to_index[int(track_id[0])]\n",
    "\n",
    "\n",
    "        #add artist\n",
    "        artist_index = content_to_index[\"ar\"+str(artist_id[0])]\n",
    "\n",
    "        rows[counter] = track_index\n",
    "        cols[counter] = artist_index\n",
    "        counter += 1\n",
    "\n",
    "        #add album\n",
    "        album = album[0].strip(\"[ ]\")\n",
    "        if album != None and len(album) > 0 and not album == (\"None\"):\n",
    "            album_index = content_to_index[\"al\"+album]\n",
    "\n",
    "            rows[counter] = track_index\n",
    "            cols[counter] = album_index\n",
    "            counter += 1\n",
    "\n",
    "        #add tags\n",
    "        tags = tags[0].strip('[ ]').split(', ')\n",
    "\n",
    "        for tag in tags: \n",
    "            if len(tag) > 0:\n",
    "                tag = \"t\"+tag\n",
    "                tag_index = content_to_index[tag]\n",
    "\n",
    "                rows[counter] = track_index\n",
    "                cols[counter] = tag_index\n",
    "                \n",
    "                counter+=1\n",
    "\n",
    "\n",
    "        #add duration\n",
    "        duration = int(duration)\n",
    "        if duration > 0:\n",
    "            duration_bucket = duration_to_bucket(duration)\n",
    "            duration_index = content_to_index[\"d\"+str(duration_bucket)]\n",
    "\n",
    "            rows[counter] = track_index\n",
    "            cols[counter] = duration_index\n",
    "            \n",
    "            counter+=1\n",
    "\n",
    "        #add playcount\n",
    "        if playcount is not None and playcount != \"None\" and not math.isnan(playcount):\n",
    "            playcount = int(playcount)\n",
    "            if playcount > 0: \n",
    "                playcount_bucket = playcount_to_bucket(playcount)\n",
    "                playcount_index = content_to_index[\"p\"+str(playcount_bucket)]\n",
    "\n",
    "                rows[counter] = track_index\n",
    "                cols[counter] = playcount_index\n",
    "                counter+=1\n",
    "            \n",
    "        if trackno%5000 == 0:\n",
    "            print(\"Track %s of %s. %s s sec.\" %(trackno, tracks_matrix.shape[0], round(time.time()-starttime, 2)))  \n",
    "        trackno += 1\n",
    "\n",
    "    #Implicit ratings: all ratings are 1.             \n",
    "    \n",
    "    rows = rows[:counter]\n",
    "    cols = cols[:counter]\n",
    "    val = np.ones(rows.shape, dtype = int)\n",
    "\n",
    "    #Build ICM matrix. \n",
    "    ICM_all = sps.coo_matrix((val, (rows, cols)), dtype = int)\n",
    "    \n",
    "    print(\"Built ICM matrix with %s content values.\" %(val.shape[0]))\n",
    "    return ICM_all\n",
    "\n",
    "\n",
    "#Build new ICM\n",
    "ICM_all = build_ICM()\n",
    "print(\"Done!\")\n",
    "\n",
    "#Fun idea! Could we normalize and put all bucket sizes of each continous variables in one variable?\n",
    "\n",
    "#Get old ICM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 77056)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ICM_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ICM!\n"
     ]
    }
   ],
   "source": [
    "#Save the ICM\n",
    "\n",
    "sps.save_npz(\"Saved Matrixes/ICM_all_coo\", ICM_all)\n",
    "print(\"Saved ICM!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted\n"
     ]
    }
   ],
   "source": [
    "#Let's convert to csr. \n",
    "ICM_all = ICM_all.tocsr()\n",
    "print(\"Converted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated ids to indexes.\n",
      "Built URM_train\n",
      "Built URM_test\n"
     ]
    }
   ],
   "source": [
    "def build_URM(train_test_split = 0.80):\n",
    "    #Builds urm \n",
    "    \n",
    "    numInteractions = train_final.shape[0]\n",
    "\n",
    "\n",
    "    train_mask = np.random.choice([True,False], numInteractions, [train_test_split, 1-train_test_split])\n",
    "\n",
    "    playlistList = train_final['playlist_id'].values\n",
    "    itemList = train_final['track_id'].values\n",
    "\n",
    "    #Translate ids\n",
    "    playlistList_translated = np.zeros(playlistList.shape)\n",
    "    itemList_translated = np.zeros(itemList.shape)\n",
    "    ratingList = np.ones((playlistList.shape), int)\n",
    "    \n",
    "    for i in range(train_final.shape[0]):\n",
    "        playlistList_translated[i] = playlist_to_index[playlistList[i]]\n",
    "        itemList_translated[i] = track_to_index[itemList[i]]\n",
    "    print(\"Translated ids to indexes.\")\n",
    "    \n",
    "    #Build URM matrix. \n",
    "    URM_train = sps.coo_matrix((ratingList[train_mask], (playlistList_translated[train_mask], itemList_translated[train_mask])))\n",
    "    URM_train = URM_train.tocsr()\n",
    "    print(\"Built URM_train\")\n",
    "    \n",
    "    \n",
    "    #Build URM_test\n",
    "    test_mask = np.logical_not(train_mask)\n",
    "    URM_test = sps.coo_matrix((ratingList[test_mask], (playlistList[test_mask], itemList[test_mask])))\n",
    "    URM_test = URM_test.tocsr()\n",
    "    print(\"Built URM_test\")\n",
    "    \n",
    "    return URM_train, URM_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Evaluation functions\n",
    "\n",
    "def precision(recommended_items, relevant_items):\n",
    "    \n",
    "    is_relevant = np.in1d(recommended_items, relevant_items, assume_unique=True)\n",
    "    \n",
    "    precision_score = np.sum(is_relevant, dtype=np.float32) / len(is_relevant)\n",
    "    \n",
    "    return precision_score\n",
    "\n",
    "def recall(recommended_items, relevant_items):\n",
    "    \n",
    "    is_relevant = np.in1d(recommended_items, relevant_items, assume_unique=True)\n",
    "    \n",
    "    recall_score = np.sum(is_relevant, dtype=np.float32) / relevant_items.shape[0]\n",
    "    \n",
    "    return recall_score\n",
    "\n",
    "def MAP(recommended_items, relevant_items):\n",
    "   \n",
    "    is_relevant = np.in1d(recommended_items, relevant_items, assume_unique=True)\n",
    "    \n",
    "    # Cumulative sum: precision at 1, at 2, at 3 ...\n",
    "    p_at_k = is_relevant * np.cumsum(is_relevant, dtype=np.float32) / (1 + np.arange(is_relevant.shape[0]))\n",
    "    \n",
    "    map_score = np.sum(p_at_k) / np.min([relevant_items.shape[0], is_relevant.shape[0]])\n",
    "\n",
    "    return map_score\n",
    "\n",
    "def evaluate_algorithm(URM_test, recommendations, at=5):\n",
    "    \n",
    "    starttime = time.time()\n",
    "    cumulative_precision = 0.0\n",
    "    cumulative_recall = 0.0\n",
    "    cumulative_MAP = 0.0\n",
    "    \n",
    "    num_eval = 0\n",
    "    \n",
    "    playlists = target_playlists['playlist_id']\n",
    "\n",
    "    for i, playlist_id in enumerate(playlists):\n",
    "        \n",
    "        if i % 500 == 0:\n",
    "            print(\"User %d of %d, %d sec.\" % (i, len(playlists), round(time.time()-starttime)))\n",
    "\n",
    "        relevant_items = URM_test[playlist_id].indices\n",
    "        \n",
    "        if len(relevant_items)>0:\n",
    "            \n",
    "            recommended_items = recommendations[i,1:6]\n",
    "            num_eval+=1\n",
    "\n",
    "            cumulative_precision += precision(recommended_items, relevant_items)\n",
    "            cumulative_recall += recall(recommended_items, relevant_items)\n",
    "            cumulative_MAP += MAP(recommended_items, relevant_items)\n",
    "\n",
    "\n",
    "    cumulative_precision /= num_eval\n",
    "    cumulative_recall /= num_eval\n",
    "    cumulative_MAP /= num_eval\n",
    "    \n",
    "    print(\"Recommender performance is: Precision = {:.4f}, Recall = {:.4f}, MAP = {:.4f}\".format(\n",
    "        cumulative_precision, cumulative_recall, cumulative_MAP))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recommender(object):\n",
    "    def __init__(self, URM, k=50, shrinkage=100, similarity='cosine'):\n",
    "        self.dataset = URM\n",
    "        self.k = k\n",
    "        self.shrinkage = shrinkage\n",
    "        self.similarity_name = similarity\n",
    "        if similarity == 'cosine':\n",
    "            self.distance = Cosine(shrinkage=self.shrinkage)\n",
    "        elif similarity == 'pearson':\n",
    "            self.distance = Pearson(shrinkage=self.shrinkage)\n",
    "        elif similarity == 'adj-cosine':\n",
    "            self.distance = AdjustedCosine(shrinkage=self.shrinkage)\n",
    "        else:\n",
    "            raise NotImplementedError('Distance {} not implemented'.format(similarity))\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"Recommender(similarity={},k={},shrinkage={})\".format(self.similarity_name, self.k, self.shrinkage)\n",
    "\n",
    "\n",
    "    def fit(self, X):\n",
    "        #Calculate cosine similarity\n",
    "        item_weights = self.distance.compute(X) \n",
    "        \n",
    "        self.W_sparse = check_matrix(item_weights, 'csc')\n",
    "        print(\"Converted to csc\")\n",
    "        \n",
    "    def fit_bad(self, X):\n",
    "        item_weights = self.distance.compute(X) #Calculate cosine similarity\n",
    "        \n",
    "        item_weights = check_matrix(item_weights, 'csr') # nearly 10 times faster\n",
    "        print(\"Converted to csr\")\n",
    "        \n",
    "        # for each column, keep only the top-k scored items\n",
    "        # THIS IS THE SLOW PART, FIND A BETTER SOLUTION        \n",
    "        values, rows, cols = [], [], []\n",
    "        nitems = self.dataset.shape[1]\n",
    "        for i in range(nitems):\n",
    "            if (i % 10000 == 0):\n",
    "                print(\"Item %d of %d\" % (i, nitems))\n",
    "            \n",
    "            #Get the row of weights belonging to the item\n",
    "            this_item_weights = item_weights[i,:].toarray()[0]\n",
    "            \n",
    "            #Get the top k similar items\n",
    "            top_k_idx = np.argsort(this_item_weights) [-self.k:]\n",
    "            \n",
    "            #\n",
    "            values.extend(this_item_weights[top_k_idx])\n",
    "            rows.extend(np.arange(nitems)[top_k_idx])\n",
    "            cols.extend(np.ones(self.k) * i)\n",
    "            \n",
    "        self.W_sparse = sps.csc_matrix((values, (rows, cols)), shape=(nitems, nitems), dtype=np.float32)\n",
    "\n",
    "\n",
    "\n",
    "    def recommend(self, user_id, at=None, exclude_seen=True):\n",
    "        # compute the scores using the dot product\n",
    "        user_profile = self.dataset[user_id]\n",
    "        scores = user_profile.dot(self.W_sparse).toarray().ravel()\n",
    "\n",
    "        # rank items\n",
    "        ranking = scores.argsort()[::-1]\n",
    "        if exclude_seen:\n",
    "            ranking = self._filter_seen(user_id, ranking)\n",
    "            \n",
    "        export = [0,0,0,0,0]\n",
    "        for i in range(5):\n",
    "            t_id = track_to_id[ranking[i]]\n",
    "            export[i] = t_id\n",
    "            \n",
    "        return export\n",
    "    def _filter_seen(self, user_id, ranking):\n",
    "        user_profile = self.dataset[user_id]\n",
    "        seen = user_profile.indices\n",
    "        unseen_mask = np.in1d(ranking, seen, assume_unique=True, invert=True)\n",
    "        return ranking[unseen_mask]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_matrix(X, format='csc', dtype=np.float32):\n",
    "    if format == 'csc' and not isinstance(X, sps.csc_matrix):\n",
    "        return X.tocsc().astype(dtype)\n",
    "    elif format == 'csr' and not isinstance(X, sps.csr_matrix):\n",
    "        return X.tocsr().astype(dtype)\n",
    "    elif format == 'coo' and not isinstance(X, sps.coo_matrix):\n",
    "        return X.tocoo().astype(dtype)\n",
    "    elif format == 'dok' and not isinstance(X, sps.dok_matrix):\n",
    "        return X.todok().astype(dtype)\n",
    "    elif format == 'bsr' and not isinstance(X, sps.bsr_matrix):\n",
    "        return X.tobsr().astype(dtype)\n",
    "    elif format == 'dia' and not isinstance(X, sps.dia_matrix):\n",
    "        return X.todia().astype(dtype)\n",
    "    elif format == 'lil' and not isinstance(X, sps.lil_matrix):\n",
    "        return X.tolil().astype(dtype)\n",
    "    else:\n",
    "        return X.astype(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class ISimilarity(object):\n",
    "    \"\"\"Abstract interface for the similarity metrics\"\"\"\n",
    "\n",
    "    def __init__(self, shrinkage=10):\n",
    "        self.shrinkage = shrinkage\n",
    "\n",
    "    def compute(self, X):\n",
    "        pass\n",
    "\n",
    "\n",
    "class Cosine(ISimilarity):\n",
    "    def compute(self, X):\n",
    "        # convert to csc matrix for faster column-wise operations\n",
    "        X = check_matrix(X, 'csc', dtype=np.float32)\n",
    "        print(\"Converted to csc.\")\n",
    "        # 1) normalize the columns in X\n",
    "        # compute the column-wise norm\n",
    "        # NOTE: this is slightly inefficient. We must copy X to compute the column norms.\n",
    "        # A faster solution is to  normalize the matrix inplace with a Cython function.\n",
    "        Xsq = X.copy()\n",
    "        Xsq.data **= 2\n",
    "        norm = np.sqrt(Xsq.sum(axis=0))\n",
    "        norm = np.asarray(norm).ravel()\n",
    "        norm += 1e-6\n",
    "        # compute the number of non-zeros in each column\n",
    "        # NOTE: this works only if X is instance of sparse.csc_matrix\n",
    "        col_nnz = np.diff(X.indptr)\n",
    "        # then normalize the values in each column\n",
    "        X.data /= np.repeat(norm, col_nnz)\n",
    "        print(\"Normalized\")\n",
    "\n",
    "        # 2) compute the cosine similarity using the dot-product\n",
    "        dist = X * X.T\n",
    "        print(\"Computed\")\n",
    "        \n",
    "        # zero out diagonal values\n",
    "        dist = dist - sps.dia_matrix((dist.diagonal()[scipy.newaxis, :], [0]), shape=dist.shape)\n",
    "        print(\"Removed diagonal\")\n",
    "        \n",
    "        # and apply the shrinkage\n",
    "        if self.shrinkage > 0:\n",
    "            dist = self.apply_shrinkage(X, dist)\n",
    "            print(\"Applied shrinkage\")    \n",
    "        \n",
    "        return dist\n",
    "\n",
    "    def apply_shrinkage(self, X, dist):\n",
    "        # create an \"indicator\" version of X (i.e. replace values in X with ones)\n",
    "        X_ind = X.copy()\n",
    "        X_ind.data = np.ones_like(X_ind.data)\n",
    "        # compute the co-rated counts\n",
    "        co_counts = X_ind * X_ind.T\n",
    "        # remove the diagonal\n",
    "        co_counts = co_counts - sps.dia_matrix((co_counts.diagonal()[scipy.newaxis, :], [0]), shape=co_counts.shape)\n",
    "        # compute the shrinkage factor as co_counts_ij / (co_counts_ij + shrinkage)\n",
    "        # then multiply dist with it\n",
    "        co_counts_shrink = co_counts.copy()\n",
    "        co_counts_shrink.data += self.shrinkage\n",
    "        co_counts.data /= co_counts_shrink.data\n",
    "        dist.data *= co_counts.data\n",
    "        return dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: Can we create a \"better\" URM by matrix factorization? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If export is true, the recommendations will be written to file. If false, evaluation method will be run. \n",
    "if export:\n",
    "    train_rate = 1\n",
    "else:\n",
    "    train_rate = 0.8\n",
    "print(\"Running with train_rate %s\" %(train_rate))\n",
    "\n",
    "URM_train, URM_test = build_URM(train_rate)\n",
    "\n",
    "import time\n",
    "starttime = time.time()\n",
    "rec = Recommender(URM=URM_train, shrinkage=0.0)\n",
    "rec.fit(ICM_all)\n",
    "print(\"Fitted in %s seconds\" %(time.time()-starttime))\n",
    "\n",
    "zeros = np.zeros((target_playlists.size, 6), dtype = int)\n",
    "recommendations = pd.DataFrame(zeros)\n",
    "recommendations.columns = ['playlist_id', 1, 2, 3, 4, 5]\n",
    "\n",
    "counter = 0\n",
    "starttime = time.time()\n",
    "for playlist_id in target_playlists['playlist_id']:\n",
    "\n",
    "    if counter % 1000 == 0: \n",
    "        print (\"%s out of 10000 playlists, %s sec.\" %(counter, time.time()-starttime))\n",
    "\n",
    "\n",
    "    playlist_id_translated = playlist_to_index[int(playlist_id)]\n",
    "    #print(rec.recommend(playlist_id_translated, at=5))\n",
    "    recommendations.iloc[counter, 1:6] = rec.recommend(playlist_id_translated, at=5)\n",
    "    recommendations.iloc[counter, 0] = playlist_id\n",
    "    counter += 1\n",
    "\n",
    "if export:\n",
    "    filename = \"recommendations_6/11_\"\n",
    "    np.savetxt(\"output/recommendations_more_content.csv\",recommendations, fmt = '%s,%s %s %s %s %s', header = \"playlist_id,track_ids\", newline = \"\\n\")\n",
    "    print(\"Saved to file: \")\n",
    "else:\n",
    "    pass\n",
    "    #evaluate_algorithm(URM_test, recommendations)\n",
    "#print(recommendations)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted to csc.\n",
      "Normalized\n",
      "Computed\n",
      "Removed diagonal\n",
      "Converted to csr\n",
      "Item 0 of 41756\n",
      "Item 10000 of 41756\n",
      "Item 20000 of 41756\n",
      "Item 30000 of 41756\n",
      "Item 40000 of 41756\n",
      "Done in 264.9076108932495 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "starttime = time.time()\n",
    "rec = Recommender(URM=URM_train, shrinkage=0.0)\n",
    "rec.fit(ICM_all)\n",
    "print(\"Done in %s seconds\" %(time.time()-starttime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated ids to indexes.\n",
      "Built URM_train\n",
      "Built URM_test\n",
      "Converted to csc.\n",
      "Normalized\n",
      "Computed\n",
      "Removed diagonal\n",
      "Converted to csr\n",
      "Item 0 of 41756\n",
      "Item 10000 of 41756\n",
      "Item 20000 of 41756\n",
      "Item 30000 of 41756\n",
      "Item 40000 of 41756\n",
      "Fitted in 255.72507190704346 seconds\n",
      "0 out of 10000 playlists, 0.0019888877868652344 sec.\n",
      "1000 out of 10000 playlists, 32.67095494270325 sec.\n",
      "2000 out of 10000 playlists, 65.14137315750122 sec.\n",
      "3000 out of 10000 playlists, 97.63627791404724 sec.\n",
      "4000 out of 10000 playlists, 130.3816659450531 sec.\n",
      "5000 out of 10000 playlists, 163.28235507011414 sec.\n",
      "6000 out of 10000 playlists, 200.2046160697937 sec.\n",
      "7000 out of 10000 playlists, 236.07709407806396 sec.\n",
      "8000 out of 10000 playlists, 270.5572769641876 sec.\n",
      "9000 out of 10000 playlists, 306.3936438560486 sec.\n",
      "Saved to file: \n",
      "done\n"
     ]
    }
   ],
   "source": [
    "run_recommender(rec, export = True)\n",
    "#evaluate_algorithm(rec, recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 31900)\n",
      "(31900,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/philipclaesson/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "num_tot_items = ICM_all.shape[0]\n",
    "\n",
    "# let's count how many items have a certain feature\n",
    "items_per_feature = (ICM_all > 0).sum(axis=0)\n",
    "\n",
    "IDF = np.array(np.log(num_tot_items / items_per_feature))[0]\n",
    "\n",
    "print(ICM_all.shape)\n",
    "print(IDF.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31900,)\n",
      "float64\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "ICM_idf = sps.csr_matrix(ICM_all, dtype=np.float64)\n",
    "# compute the number of non-zeros in each col\n",
    "# NOTE: this works only if X is instance of sparse.csc_matrix\n",
    "col_nnz = np.diff(check_matrix(ICM_idf, 'csc').indptr)\n",
    "print(col_nnz.shape)\n",
    "print(ICM_idf.shape)\n",
    "print(IDF.shape)\n",
    "# then normalize the values in each col\n",
    "ICM_idf.data *= np.repeat(IDF, col_nnz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized\n",
      "Computed\n",
      "Removed diagonal\n",
      "Converted to csr\n",
      "Item 0 of 100000\n",
      "Item 10000 of 100000\n",
      "Item 20000 of 100000\n",
      "Item 30000 of 100000\n",
      "Item 40000 of 100000\n",
      "Item 50000 of 100000\n",
      "Item 60000 of 100000\n",
      "Item 70000 of 100000\n",
      "Item 80000 of 100000\n",
      "Item 90000 of 100000\n"
     ]
    }
   ],
   "source": [
    "rec_idf = BasicItemKNNRecommender(URM=URM_train, shrinkage=0.0, k=50)\n",
    "rec_idf.fit(ICM_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 10000 playlists, 0.0018591880798339844 sec.\n",
      "1000 out of 10000 playlists, 103.81256532669067 sec.\n",
      "2000 out of 10000 playlists, 207.41671419143677 sec.\n",
      "3000 out of 10000 playlists, 309.9324781894684 sec.\n",
      "4000 out of 10000 playlists, 412.0452392101288 sec.\n",
      "5000 out of 10000 playlists, 515.3428280353546 sec.\n",
      "6000 out of 10000 playlists, 618.8582541942596 sec.\n",
      "7000 out of 10000 playlists, 721.2632591724396 sec.\n",
      "8000 out of 10000 playlists, 820.9152603149414 sec.\n",
      "9000 out of 10000 playlists, 923.4950971603394 sec.\n",
      "done\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 0 of 10000\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index (10024884) out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-150-b5367490e339>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate_algorithm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mURM_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-149-62b55034a358>\u001b[0m in \u001b[0;36mevaluate_algorithm\u001b[0;34m(URM_test, recommender_object, at)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelevant_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mrecommended_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecommender_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecommend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0mnum_eval\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-125-d8617ea2b388>\u001b[0m in \u001b[0;36mrecommend\u001b[0;34m(self, user_id, at, exclude_seen)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecommend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude_seen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# compute the scores using the dot product\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0muser_profile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser_profile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_sparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/sparse/csr.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0;31m# [i, 1:2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_row_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m             \u001b[0;31m# [i, [1, 2]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0missequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/sparse/csr.py\u001b[0m in \u001b[0;36m_get_row_slice\u001b[0;34m(self, i, cslice)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'index (%d) out of range'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcslice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index (10024884) out of range"
     ]
    }
   ],
   "source": [
    "evaluate_algorithm(URM_test, rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of       playlist_id        1        2        3        4        5\n",
      "0        10024884  1637241  1432851  3789197   820484   435345\n",
      "1        10624787  2969077  3719846  1629279  1980691   680692\n",
      "2         4891851  2089117   301240  2724257  1371741   193077\n",
      "3         4267369  2950102  1838583  1820820  1461310  3276967\n",
      "4           65078   949178  1492640  3276761   631238  2863566\n",
      "5        10637124  2340644  3846549  2582934   273502  3032626\n",
      "6         3223162  2967703  3610791  1254269   681739  1526301\n",
      "7         7541503   956454  1480755  4591425  1825510  1825990\n",
      "8         6189367  1675280     8795  1510163  1729189  3205586\n",
      "9         8459943  2222883   802763  2214075  2752335  1334909\n",
      "10       10138804  1155458  2935861  3866159  1887656  2137341\n",
      "11       10562075  4420433  3299694  1308886  1210562  3624009\n",
      "12       10184821  1056611  2127102   377629  3781394  1868817\n",
      "13        4189678  2664733   362133  1402667  2664942  2215412\n",
      "14        6299524   195778  1344229  3302962  3511462  1527961\n",
      "15        8515028  1440124  3375738  1767226   536085  3711077\n",
      "16       10631638  2899063  2842248   360800  3670757  1831605\n",
      "17       10947423  3191588  2330141  3349911   611428  2274205\n",
      "18       11295404   830634   219919  1605470  1797663  1669793\n",
      "19        3884714  3557796  3362015   369033  1201182  2491418\n",
      "20       10680851   826418  1563133  2785283  2676381  1030713\n",
      "21        3228268  2958044  1639903   425244  3554713  3085539\n",
      "22        7850055  2830527  3550406  2758872  3019845  3286648\n",
      "23       10864017  1804337  2983185  2522691  2575762   307738\n",
      "24        5660760  1325599  2856374  2918163  2937064   202544\n",
      "25        4157419  2807557  3079025  3796145  2293484  3534170\n",
      "26        3304833  1432964  1280489   673880  1130644  2929285\n",
      "27        1911645   644831  1498469  2798810  3075374   911131\n",
      "28        4902536  3581227  1216683   193133    80619  3794784\n",
      "29        1140304  2872197  3837471  2977159  3013763  2127241\n",
      "...           ...      ...      ...      ...      ...      ...\n",
      "9970     11381473   264241  2041519  2843676   679604   520226\n",
      "9971      3520121  2366797  2561312  1034094  2301705    42671\n",
      "9972      6612439  3392573  3505126  1709479    87352  1156134\n",
      "9973      6218231  3298612   503063   133036  2637827  2334485\n",
      "9974      8344678  1352567   683239  3779363  3030934  2339622\n",
      "9975      7470841  1595157  3792998    64209  1758146    77100\n",
      "9976      6423094  1439363  2331857  2435862  1909662  3203913\n",
      "9977      8139437  2622979  1341708  3501999  1672588   611370\n",
      "9978      8227203   798900  2955603   683975  2574235  1608143\n",
      "9979      5903507  3469795  1850609  2333066  3747916  2331038\n",
      "9980      3778920   573494   254401  3737793  2621488  1558791\n",
      "9981      1061175  1700970  1423194   319731   676985  2674387\n",
      "9982      8572406  3885598   351102  2550734  2498769  3532585\n",
      "9983     10413491  1531164  3890124  3087297  1915451  2052975\n",
      "9984      8868869  3440842   279683   704737  1096151  3199853\n",
      "9985      8202309   153171   166974   879552  2163301  1303340\n",
      "9986      7784396   621684  2160644  2542909  2828710  2727320\n",
      "9987      4622927  2841460  3305678  2279185  1686177  3438028\n",
      "9988     11542825   813943  2670309  1090144   251931  1935713\n",
      "9989      7138440  2822285  2248261   849916  2008442  2988391\n",
      "9990      5146771  1104131  1775890  1867423   568987   301360\n",
      "9991      4506918  2698883  3225767  3169143   104517   416162\n",
      "9992     10337087  3588711  1085651  1145938  1791685   860987\n",
      "9993      5608217  2146828  1340455  1823023  2805023   616811\n",
      "9994      7697108  3343909  3750086  1839142  3102375  1736577\n",
      "9995     11616286  4585032   809970   727234  1711595  4891510\n",
      "9996        53201  2895090  1475613  2940576  1278274  2208245\n",
      "9997     11369546  1134195   878297  2120528  1626372  2354563\n",
      "9998      7939535   143443  3749464  2933793   126113  1795800\n",
      "9999       297021  3841976  1735331  3611454  2280075  3703942\n",
      "\n",
      "[10000 rows x 6 columns]>\n"
     ]
    }
   ],
   "source": [
    "def save_to_file():\n",
    "    #Saves the recommendations dataframe to the .csv-file. \n",
    "    np.savetxt(\"output/recommendations_more_content.csv\",recommendations, fmt = '%s,%s %s %s %s %s', header = \"playlist_id,track_ids\", newline = \"\\n\")\n",
    "    \n",
    "    \n",
    "def test():\n",
    "    #Do something\n",
    "    print(\"Result: \")\n",
    "    pass\n",
    "\n",
    "\n",
    "save_to_file()\n",
    "print(recommendations.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
