{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse as sps\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n",
    "#train_final.csv - the training set of interactions\n",
    "train_final = pd.read_csv('input/train_final.csv', delimiter = \"\\t\");\n",
    "\n",
    "#tracks_final.csv - supplementary information about the items\n",
    "tracks_final = pd.read_csv('input/tracks_final.csv', delimiter = \"\\t\");\n",
    "\n",
    "#playlists_final.csv - supplementary information about the users\n",
    "playlists_final = pd.read_csv('input/playlists_final.csv', delimiter = \"\\t\");\n",
    "\n",
    "#target_playlists.csv - the set of target playlists that will receive recommendations\n",
    "target_playlists = pd.read_csv('input/target_playlists.csv');\n",
    "\n",
    "#target_tracks.csv - the set of target items (tracks) to be recommended\n",
    "target_tracks = pd.read_csv('input/target_tracks.csv');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41756, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This step is not needed yet, will make ratings worse! \n",
    "\n",
    "def get_relevant_tracks()\n",
    "    #Now we want to remove some redundant stuff. \n",
    "\n",
    "    #We will remove all songs which are not occurring more than 10 times in train_final\n",
    "    #Nevertheless, we still want to keep all tracks which are in the target tracks.  \n",
    "\n",
    "    popularity = train_final.groupby(by=\"track_id\").playlist_id.nunique().to_frame()\n",
    "\n",
    "    #remove index name\n",
    "    popularity.reset_index(level = 0, inplace = True)\n",
    "\n",
    "    #Rename the columns\n",
    "    popularity.columns = ['track_id','occurrences']\n",
    "\n",
    "    #Remove all targeted tracks - TESTED, working as expected\n",
    "    tracks_relevant = popularity[~popularity['track_id'].isin(target_tracks['track_id'])]\n",
    "\n",
    "    #Remove tracks occurring less than 10 times\n",
    "    tracks_relevant = tracks_relevant[tracks_relevant['occurrences'] > 10]\n",
    "\n",
    "    #Add the targeteted tracks back again\n",
    "    tracks_relevant = pd.concat([tracks_relevant, target_tracks])\n",
    "\n",
    "    return(tracks_relevant)\n",
    "\n",
    "    print(\"Removed %s redundant tracks which occured less than 10 times.\" %(tracks_final-tracks_relevant))\n",
    "\n",
    "tracks_relevant = get_relevant_tracks()\n",
    "\n",
    "#Remove irrelevant tracks from train_final and tracks_final\n",
    "train_final = train_final[train_final['track_id'].isin(tracks_relevant['track_id'])]\n",
    "\n",
    "print(\"Train_final now contains %s interactions. \" %(train_final.shape[0]))\n",
    "\n",
    "tracks_final = tracks_final[tracks_final['track_id'].isin(tracks_relevant['track_id'])]\n",
    "\n",
    "print(\"Tracks_final now contains %s tracks. \"%(tracks_final.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<57561x41756 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 0 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>duration</th>\n",
       "      <th>playcount</th>\n",
       "      <th>album</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2972914</td>\n",
       "      <td>144</td>\n",
       "      <td>224000</td>\n",
       "      <td>49.0</td>\n",
       "      <td>[7]</td>\n",
       "      <td>[54087, 1757, 1718, 116712, 189631]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2750239</td>\n",
       "      <td>246</td>\n",
       "      <td>157000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[8]</td>\n",
       "      <td>[189631, 3424, 177424, 46208, 205245]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1550729</td>\n",
       "      <td>144</td>\n",
       "      <td>217000</td>\n",
       "      <td>554.0</td>\n",
       "      <td>[9]</td>\n",
       "      <td>[54087, 109806, 46869, 183258, 54337]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2169950</td>\n",
       "      <td>144</td>\n",
       "      <td>207000</td>\n",
       "      <td>200.0</td>\n",
       "      <td>[9]</td>\n",
       "      <td>[54087, 70618, 207003, 109806, 116712]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1903709</td>\n",
       "      <td>144</td>\n",
       "      <td>198000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[54087, 81223, 116712, 215342, 71028]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   track_id  artist_id  duration  playcount   album  \\\n",
       "0   2972914        144    224000       49.0     [7]   \n",
       "1   2750239        246    157000        1.0     [8]   \n",
       "2   1550729        144    217000      554.0     [9]   \n",
       "3   2169950        144    207000      200.0     [9]   \n",
       "4   1903709        144    198000        5.0  [None]   \n",
       "\n",
       "                                     tags  \n",
       "0     [54087, 1757, 1718, 116712, 189631]  \n",
       "1   [189631, 3424, 177424, 46208, 205245]  \n",
       "2   [54087, 109806, 46869, 183258, 54337]  \n",
       "3  [54087, 70618, 207003, 109806, 116712]  \n",
       "4   [54087, 81223, 116712, 215342, 71028]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now lets take a look at the tags.\n",
    "tracks_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Translating all content ids into indexes.\n",
    "\n",
    "#We need to create buckets for the playcount and duration. \n",
    "#Lets create buckets and a help function for the duration. \n",
    "\n",
    "n_duration_buckets = 8\n",
    "def duration_to_bucket(duration):\n",
    "    if duration <= 0:\n",
    "        print(\"Null duration reached bucket function. \")\n",
    "        return None\n",
    "    elif duration < 90000: #not a song\n",
    "        return 1\n",
    "    elif duration < 140000: #short song\n",
    "        return 2\n",
    "    elif duration < 220000: #radio song\n",
    "        return 3\n",
    "    elif duration < 340000: #normal song\n",
    "        return 4\n",
    "    elif duration < 480000: #long song\n",
    "        return 5\n",
    "    elif duration < 720000: #really long\n",
    "        return 6\n",
    "    elif duration < 1200000: #super long\n",
    "        return 7\n",
    "    elif duration > 1200000: #mixtape/compilation\n",
    "        return 8\n",
    "\n",
    "n_playcount_buckets = 7\n",
    "def playcount_to_bucket(playcount):\n",
    "    if playcount <= 0 or playcount is None:\n",
    "        print(\"Null playcount reached bucket function. \")\n",
    "        return None\n",
    "    elif playcount < 254: #0,4 percentile not popular\n",
    "        return 1\n",
    "    elif playcount < 881: #0,6 perc: known\n",
    "        return 2\n",
    "    elif playcount < 1560: #0,7 popular\n",
    "        return 3\n",
    "    elif playcount < 2808: #0,8 very popular\n",
    "        return 4\n",
    "    elif playcount < 5900: #0,9 hits\n",
    "        return 5\n",
    "    elif playcount < 10494: #0,95 super hits\n",
    "        return 6\n",
    "    elif playcount > 10494: # mega hits\n",
    "        return 7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77056\n"
     ]
    }
   ],
   "source": [
    "tracks_final['tags'].head()\n",
    "\n",
    "content_to_index = {}\n",
    "content_to_id = {}\n",
    "content_counter = 0\n",
    "\n",
    "#Lets translate the tags to indexes. \n",
    "for row in tracks_final['tags']:\n",
    "    tags = row.strip('[ ]').split(', ')\n",
    "    for tag in tags:\n",
    "        if len(tag) > 0: \n",
    "            tag = \"t\"+tag\n",
    "            if not(tag in content_to_index):\n",
    "                content_to_index[tag] = content_counter\n",
    "                content_to_id[content_counter] = tag\n",
    "                content_counter += 1;\n",
    "                \n",
    "#Lets translate album into indexes\n",
    "for album in tracks_final['album']:\n",
    "    album = album.strip('[ ]')\n",
    "    if album != None and len(album) > 0: #None should not be considered content\n",
    "        album = \"al\"+album\n",
    "        if not(album in content_to_index):\n",
    "            content_to_index[album] = content_counter\n",
    "            content_to_id[content_counter] = album\n",
    "            content_counter += 1;\n",
    "\n",
    "#Lets translate artist_id into indexes\n",
    "for artist in tracks_final['artist_id']:\n",
    "    artist = str(artist)\n",
    "    artist = \"ar\"+artist\n",
    "    if not(artist in content_to_index):\n",
    "        content_to_index[artist] = content_counter\n",
    "        content_to_id[content_counter] = artist\n",
    "        content_counter += 1;\n",
    "        \n",
    "\n",
    "#Lets translate the duration buckets into indexes. \n",
    "for bucket in range(n_duration_buckets): \n",
    "    bucket = \"d\"+str(bucket)\n",
    "    content_to_index[bucket] = content_counter\n",
    "    content_to_id[content_counter] = bucket\n",
    "    \n",
    "    content_counter += 1\n",
    "\n",
    "#Lets translate the playcount buckets into indexes. \n",
    "for playcount in range(n_playcount_buckets): \n",
    "    playcount = \"p\"+str(playcount)\n",
    "    content_to_index[playcount] = content_counter\n",
    "    content_to_id[content_counter] = playcount\n",
    "    \n",
    "    content_counter += 1\n",
    "\n",
    "#Fun thing to try: can I add all duration/playcounts in one col, normalizing from 0-1? \n",
    "\n",
    "print(len(content_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 57561 playlists with 100000 unique tracks with 77041 unique content types. \n"
     ]
    }
   ],
   "source": [
    "#If we translate each track_id to a track_index which will serve as matrix index, we can save a lot of time. \n",
    "\n",
    "\n",
    "#We need a way to get from track_id to index in O(1).\n",
    "#Let's create a dictionary\n",
    "\n",
    "track_to_id = {}\n",
    "track_to_index = {}\n",
    "counter = 0; #We will start at 1, reserving col 0 for indexes.  \n",
    "for track_id in tracks_final['track_id']:\n",
    "    track_id = int(track_id)\n",
    "    track_to_index[track_id] = counter\n",
    "    track_to_id[counter] = track_id\n",
    "    counter += 1;\n",
    "    \n",
    "#and a way to get from playlist_id to index in O(1)\n",
    "\n",
    "\n",
    "playlist_to_index = {}\n",
    "playlist_to_id = {}\n",
    "counter = 0; \n",
    "for playlist_id in playlists_final['playlist_id']:\n",
    "    playlist_id = int(playlist_id)\n",
    "    playlist_to_index[playlist_id] = counter\n",
    "    playlist_to_id[counter] = playlist_id\n",
    "    counter += 1;\n",
    "    \n",
    "print(\"We have {} playlists with {} unique tracks with {} unique content types. \".format(len(playlist_to_index), len(track_to_index), len(content_to_index)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 77041)\n"
     ]
    }
   ],
   "source": [
    "#Now we can create an Item Content Matrix. \n",
    "\n",
    "#ICM_all = np.zeros((len(tracks_indexes), len(tags_indexes)), int)\n",
    "#ICM_all = sps.coo_matrix((len(track_to_index), len(content_to_index)), int)\n",
    "#print(ICM_all.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>duration</th>\n",
       "      <th>playcount</th>\n",
       "      <th>album</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2972914</td>\n",
       "      <td>144</td>\n",
       "      <td>224000</td>\n",
       "      <td>49.0</td>\n",
       "      <td>[7]</td>\n",
       "      <td>[54087, 1757, 1718, 116712, 189631]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2750239</td>\n",
       "      <td>246</td>\n",
       "      <td>157000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[8]</td>\n",
       "      <td>[189631, 3424, 177424, 46208, 205245]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1550729</td>\n",
       "      <td>144</td>\n",
       "      <td>217000</td>\n",
       "      <td>554.0</td>\n",
       "      <td>[9]</td>\n",
       "      <td>[54087, 109806, 46869, 183258, 54337]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2169950</td>\n",
       "      <td>144</td>\n",
       "      <td>207000</td>\n",
       "      <td>200.0</td>\n",
       "      <td>[9]</td>\n",
       "      <td>[54087, 70618, 207003, 109806, 116712]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1903709</td>\n",
       "      <td>144</td>\n",
       "      <td>198000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[54087, 81223, 116712, 215342, 71028]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2256817</td>\n",
       "      <td>144</td>\n",
       "      <td>218000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[9]</td>\n",
       "      <td>[54087, 109806, 189631, 49166, 116712]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2561768</td>\n",
       "      <td>928</td>\n",
       "      <td>223000</td>\n",
       "      <td>249.0</td>\n",
       "      <td>[26]</td>\n",
       "      <td>[50764, 4425, 11056, 205245, 81223]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>474864</td>\n",
       "      <td>928</td>\n",
       "      <td>193000</td>\n",
       "      <td>73.0</td>\n",
       "      <td>[22]</td>\n",
       "      <td>[205245, 81223, 11056, 267, 3982]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1378455</td>\n",
       "      <td>928</td>\n",
       "      <td>304000</td>\n",
       "      <td>73.0</td>\n",
       "      <td>[22]</td>\n",
       "      <td>[11056, 205245, 81223, 189631, 84597]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1523190</td>\n",
       "      <td>928</td>\n",
       "      <td>206000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[22]</td>\n",
       "      <td>[205245, 11056, 81223, 4425, 189631]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   track_id  artist_id  duration  playcount   album  \\\n",
       "0   2972914        144    224000       49.0     [7]   \n",
       "1   2750239        246    157000        1.0     [8]   \n",
       "2   1550729        144    217000      554.0     [9]   \n",
       "3   2169950        144    207000      200.0     [9]   \n",
       "4   1903709        144    198000        5.0  [None]   \n",
       "5   2256817        144    218000        2.0     [9]   \n",
       "6   2561768        928    223000      249.0    [26]   \n",
       "7    474864        928    193000       73.0    [22]   \n",
       "8   1378455        928    304000       73.0    [22]   \n",
       "9   1523190        928    206000       10.0    [22]   \n",
       "\n",
       "                                     tags  \n",
       "0     [54087, 1757, 1718, 116712, 189631]  \n",
       "1   [189631, 3424, 177424, 46208, 205245]  \n",
       "2   [54087, 109806, 46869, 183258, 54337]  \n",
       "3  [54087, 70618, 207003, 109806, 116712]  \n",
       "4   [54087, 81223, 116712, 215342, 71028]  \n",
       "5  [54087, 109806, 189631, 49166, 116712]  \n",
       "6     [50764, 4425, 11056, 205245, 81223]  \n",
       "7       [205245, 81223, 11056, 267, 3982]  \n",
       "8   [11056, 205245, 81223, 189631, 84597]  \n",
       "9    [205245, 11056, 81223, 4425, 189631]  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks_final[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track 0 of 100000\n",
      "Track 500 of 100000\n",
      "Track 1000 of 100000\n",
      "Track 1500 of 100000\n",
      "Track 2000 of 100000\n",
      "Track 2500 of 100000\n",
      "Track 3000 of 100000\n",
      "Track 3500 of 100000\n",
      "Track 4000 of 100000\n",
      "Track 4500 of 100000\n",
      "Track 5000 of 100000\n",
      "Track 5500 of 100000\n",
      "Track 6000 of 100000\n",
      "Track 6500 of 100000\n",
      "Track 7000 of 100000\n",
      "Track 7500 of 100000\n",
      "Track 8000 of 100000\n",
      "Track 8500 of 100000\n",
      "Track 9000 of 100000\n",
      "Track 9500 of 100000\n",
      "Track 10000 of 100000\n",
      "Track 10500 of 100000\n",
      "Track 11000 of 100000\n",
      "Track 11500 of 100000\n",
      "Track 12000 of 100000\n",
      "Track 12500 of 100000\n",
      "Track 13000 of 100000\n",
      "Track 13500 of 100000\n",
      "Track 14000 of 100000\n",
      "Track 14500 of 100000\n",
      "Track 15000 of 100000\n",
      "Track 15500 of 100000\n",
      "Track 16000 of 100000\n",
      "Track 16500 of 100000\n",
      "Track 17000 of 100000\n",
      "Track 17500 of 100000\n",
      "Track 18000 of 100000\n",
      "Track 18500 of 100000\n",
      "Track 19000 of 100000\n",
      "Track 19500 of 100000\n",
      "Track 20000 of 100000\n",
      "Track 20500 of 100000\n",
      "Track 21000 of 100000\n",
      "Track 21500 of 100000\n",
      "Track 22000 of 100000\n",
      "Track 22500 of 100000\n",
      "Track 23000 of 100000\n",
      "Track 23500 of 100000\n",
      "Track 24000 of 100000\n",
      "Track 24500 of 100000\n",
      "Track 25000 of 100000\n",
      "Track 25500 of 100000\n",
      "Track 26000 of 100000\n",
      "Track 26500 of 100000\n",
      "Track 27000 of 100000\n",
      "Track 27500 of 100000\n",
      "Track 28000 of 100000\n",
      "Track 28500 of 100000\n",
      "Track 29000 of 100000\n",
      "Track 29500 of 100000\n",
      "Track 30000 of 100000\n",
      "Track 30500 of 100000\n",
      "Track 31000 of 100000\n",
      "Track 31500 of 100000\n",
      "Track 32000 of 100000\n",
      "Track 32500 of 100000\n",
      "Track 33000 of 100000\n",
      "Track 33500 of 100000\n",
      "Track 34000 of 100000\n",
      "Track 34500 of 100000\n",
      "Track 35000 of 100000\n",
      "Track 35500 of 100000\n",
      "Track 36000 of 100000\n",
      "Track 36500 of 100000\n",
      "Track 37000 of 100000\n",
      "Track 37500 of 100000\n",
      "Track 38000 of 100000\n",
      "Track 38500 of 100000\n",
      "Track 39000 of 100000\n",
      "Track 39500 of 100000\n",
      "Track 40000 of 100000\n",
      "Track 40500 of 100000\n",
      "Track 41000 of 100000\n",
      "Track 41500 of 100000\n",
      "Track 42000 of 100000\n",
      "Track 42500 of 100000\n",
      "Track 43000 of 100000\n",
      "Track 43500 of 100000\n",
      "Track 44000 of 100000\n",
      "Track 44500 of 100000\n",
      "Track 45000 of 100000\n",
      "Track 45500 of 100000\n",
      "Track 46000 of 100000\n",
      "Track 46500 of 100000\n",
      "Track 47000 of 100000\n",
      "Track 47500 of 100000\n",
      "Track 48000 of 100000\n",
      "Track 48500 of 100000\n",
      "Track 49000 of 100000\n",
      "Track 49500 of 100000\n",
      "Track 50000 of 100000\n",
      "Track 50500 of 100000\n",
      "Track 51000 of 100000\n",
      "Track 51500 of 100000\n",
      "Track 52000 of 100000\n",
      "Track 52500 of 100000\n",
      "Track 53000 of 100000\n",
      "Track 53500 of 100000\n",
      "Track 54000 of 100000\n",
      "Track 54500 of 100000\n",
      "Track 55000 of 100000\n",
      "Track 55500 of 100000\n",
      "Track 56000 of 100000\n",
      "Track 56500 of 100000\n",
      "Track 57000 of 100000\n",
      "Track 57500 of 100000\n",
      "Track 58000 of 100000\n",
      "Track 58500 of 100000\n",
      "Track 59000 of 100000\n",
      "Track 59500 of 100000\n",
      "Track 60000 of 100000\n",
      "Track 60500 of 100000\n",
      "Track 61000 of 100000\n",
      "Track 61500 of 100000\n",
      "Track 62000 of 100000\n",
      "Track 62500 of 100000\n",
      "Track 63000 of 100000\n",
      "Track 63500 of 100000\n",
      "Track 64000 of 100000\n",
      "Track 64500 of 100000\n",
      "Track 65000 of 100000\n",
      "Track 65500 of 100000\n",
      "Track 66000 of 100000\n",
      "Track 66500 of 100000\n",
      "Track 67000 of 100000\n",
      "Track 67500 of 100000\n",
      "Track 68000 of 100000\n",
      "Track 68500 of 100000\n",
      "Track 69000 of 100000\n",
      "Track 69500 of 100000\n",
      "Track 70000 of 100000\n",
      "Track 70500 of 100000\n",
      "Track 71000 of 100000\n",
      "Track 71500 of 100000\n",
      "Track 72000 of 100000\n",
      "Track 72500 of 100000\n",
      "Track 73000 of 100000\n",
      "Track 73500 of 100000\n",
      "Track 74000 of 100000\n",
      "Track 74500 of 100000\n",
      "Track 75000 of 100000\n",
      "Track 75500 of 100000\n",
      "Track 76000 of 100000\n",
      "Track 76500 of 100000\n",
      "Track 77000 of 100000\n",
      "Track 77500 of 100000\n",
      "Track 78000 of 100000\n",
      "Track 78500 of 100000\n",
      "Track 79000 of 100000\n",
      "Track 79500 of 100000\n",
      "Track 80000 of 100000\n",
      "Track 80500 of 100000\n",
      "Track 81000 of 100000\n",
      "Track 81500 of 100000\n",
      "Track 82000 of 100000\n",
      "Track 82500 of 100000\n",
      "Track 83000 of 100000\n",
      "Track 83500 of 100000\n",
      "Track 84000 of 100000\n",
      "Track 84500 of 100000\n",
      "Track 85000 of 100000\n",
      "Track 85500 of 100000\n",
      "Track 86000 of 100000\n",
      "Track 86500 of 100000\n",
      "Track 87000 of 100000\n",
      "Track 87500 of 100000\n",
      "Track 88000 of 100000\n",
      "Track 88500 of 100000\n",
      "Track 89000 of 100000\n",
      "Track 89500 of 100000\n",
      "Track 90000 of 100000\n",
      "Track 90500 of 100000\n",
      "Track 91000 of 100000\n",
      "Track 91500 of 100000\n",
      "Track 92000 of 100000\n",
      "Track 92500 of 100000\n",
      "Track 93000 of 100000\n",
      "Track 93500 of 100000\n",
      "Track 94000 of 100000\n",
      "Track 94500 of 100000\n",
      "Track 95000 of 100000\n",
      "Track 95500 of 100000\n",
      "Track 96000 of 100000\n",
      "Track 96500 of 100000\n",
      "Track 97000 of 100000\n",
      "Track 97500 of 100000\n",
      "Track 98000 of 100000\n",
      "Track 98500 of 100000\n",
      "Track 99000 of 100000\n",
      "Track 99500 of 100000\n",
      "Built ICM matrix with 656745 interactions\n"
     ]
    }
   ],
   "source": [
    "#So let's fill the ICM with our data.\n",
    "\n",
    "def build_ICM():\n",
    "    tracks_matrix = tracks_final.as_matrix()\n",
    "    rows = np.array([], dtype = int)\n",
    "    cols = np.array([], dtype = int)\n",
    "    #val[i] = value of row[i] col[i]\n",
    "    #val = []\n",
    "    counter = 0\n",
    "    starttime = time.time()\n",
    "    lasttime = starttime\n",
    "    for track in tracks_matrix: \n",
    "        track_id, artist_id, duration, playcount, album, tags = np.split(track, 6)\n",
    "\n",
    "        #Get track index\n",
    "        track_index = track_to_index[int(track_id[0])]\n",
    "\n",
    "\n",
    "        #add artist\n",
    "        artist_index = content_to_index[\"ar\"+str(artist_id[0])]\n",
    "\n",
    "        rows = np.append(rows, track_index)\n",
    "        cols = np.append(cols, artist_index)\n",
    "\n",
    "        #add album\n",
    "        album = album[0].strip(\"[ ]\")\n",
    "        if album != None and len(album) > 0 and not album == (\"None\"):\n",
    "            album_index = content_to_index[\"al\"+album]\n",
    "\n",
    "            rows = np.append(rows, track_index)\n",
    "            cols = np.append(cols, album_index)\n",
    "\n",
    "        #add tags\n",
    "        tags = tags[0].strip('[ ]').split(', ')\n",
    "\n",
    "        for tag in tags: \n",
    "            if len(tag) > 0:\n",
    "                tag = \"t\"+tag\n",
    "                tag_index = content_to_index[tag]\n",
    "\n",
    "                rows = np.append(rows, track_index)\n",
    "                cols = np.append(cols, tag_index)\n",
    "\n",
    "        if counter%5000 == 0:\n",
    "            print(\"Track %s of %s. %s ms per track.\" %(counter, tracks_matrix.shape[0], (time.time()-lasttime)/5000)  \n",
    "            lasttime = time.time()-lasttime\n",
    "        counter += 1\n",
    "\n",
    "        #add duration\n",
    "        duration = int(duration)\n",
    "        if duration > 0:\n",
    "            duration_bucket = duration_to_bucket(duration)\n",
    "            duration_index = content_to_index[\"d\"+duration_bucket]\n",
    "\n",
    "            rows = np.append(rows, track_index)\n",
    "            cols = np.append(cols, duration_index)\n",
    "\n",
    "        #add playcount\n",
    "        playcount = int(playcount)\n",
    "        if playcount > 0:\n",
    "            playcount_bucket = playcount_to_bucket(playcount)\n",
    "            playcount_index = content_to_index[\"p\"+playcount_bucket]\n",
    "\n",
    "            rows = np.append(rows, track_index)\n",
    "            cols = np.append(cols, playcount_index)\n",
    "\n",
    "    #Implicit ratings: all ratings are 1.             \n",
    "    val = np.ones(rows.shape, dtype = int)\n",
    "\n",
    "    #Build ICM matrix. \n",
    "    ICM_all = sps.coo_matrix((val, (rows, cols)), dtype = int)\n",
    "    \n",
    "    return ICM_all\n",
    "    print(\"Built ICM matrix with %s content values.\" %(val.shape[0]))\n",
    "\n",
    "#Build new ICM\n",
    "#ICM_all = build_ICM()\n",
    "                  \n",
    "#Get old ICM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ICM!\n"
     ]
    }
   ],
   "source": [
    "#Save the ICM\n",
    "\n",
    "sps.save_npz(\"Saved Matrixes/ICM_all_coo\", ICM_all)\n",
    "print(\"Saved ICM!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted\n"
     ]
    }
   ],
   "source": [
    "#Let's convert to csr. \n",
    "ICM_all = ICM_all.tocsr()\n",
    "print(\"Converted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Lets build a URM matrix. Should be nofplaylists x nofitems\n",
    "\n",
    "item_playlist_matrix = np.zeros([playlists_final.shape[0], tracks_final.shape[0]],int) \n",
    "\n",
    "interactions = train_final.as_matrix()\n",
    "for row in interactions:\n",
    "    #Lets get the info\n",
    "    playlist_id = row[0]\n",
    "    track_id = row[1]\n",
    "    \n",
    "    #Now lets get the proper indexes. \n",
    "    playlist_index = playlist_to_index[playlist_id]\n",
    "    track_index = track_to_index[track_id]\n",
    "    \n",
    "    #And now lets add it to the matrix\n",
    "    item_playlist_matrix[playlist_index][track_index] = 1\n",
    "    \n",
    "\n",
    "print(item_playlist_matrix.shape)\n",
    "print(\"hej1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated ids to indexes.\n",
      "Built URM_train\n",
      "Built URM_test\n"
     ]
    }
   ],
   "source": [
    "def build_URM(train_test_split = 0.80):\n",
    "    #Builds urm \n",
    "    \n",
    "    numInteractions = train_final.shape[0]\n",
    "\n",
    "\n",
    "    train_mask = np.random.choice([True,False], numInteractions, [train_test_split, 1-train_test_split])\n",
    "\n",
    "    playlistList = train_final['playlist_id'].values\n",
    "    itemList = train_final['track_id'].values\n",
    "\n",
    "    #Translate ids\n",
    "    playlistList_translated = np.zeros(playlistList.shape)\n",
    "    itemList_translated = np.zeros(itemList.shape)\n",
    "    ratingList = np.ones((playlistList.shape), int)\n",
    "    \n",
    "    for i in range(train_final.shape[0]):\n",
    "        playlistList_translated[i] = playlist_to_index[playlistList[i]]\n",
    "        itemList_translated[i] = track_to_index[itemList[i]]\n",
    "    print(\"Translated ids to indexes.\")\n",
    "    \n",
    "    #Build URM matrix. \n",
    "    URM_train = sps.coo_matrix((ratingList[train_mask], (playlistList_translated[train_mask], itemList_translated[train_mask])))\n",
    "    URM_train = URM_train.tocsr()\n",
    "    print(\"Built URM_train\")\n",
    "    \n",
    "    \n",
    "    #Build URM_test\n",
    "    test_mask = np.logical_not(train_mask)\n",
    "    URM_test = sps.coo_matrix((ratingList[test_mask], (playlistList[test_mask], itemList[test_mask])))\n",
    "    URM_test = URM_test.tocsr()\n",
    "    print(\"Built URM_test\")\n",
    "    \n",
    "    return URM_train, URM_test\n",
    "\n",
    "URM_train, URM_test = build_URM(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Evaluation functions\n",
    "\n",
    "def precision(recommended_items, relevant_items):\n",
    "    \n",
    "    is_relevant = np.in1d(recommended_items, relevant_items, assume_unique=True)\n",
    "    \n",
    "    precision_score = np.sum(is_relevant, dtype=np.float32) / len(is_relevant)\n",
    "    \n",
    "    return precision_score\n",
    "\n",
    "def recall(recommended_items, relevant_items):\n",
    "    \n",
    "    is_relevant = np.in1d(recommended_items, relevant_items, assume_unique=True)\n",
    "    \n",
    "    recall_score = np.sum(is_relevant, dtype=np.float32) / relevant_items.shape[0]\n",
    "    \n",
    "    return recall_score\n",
    "\n",
    "def MAP(recommended_items, relevant_items):\n",
    "   \n",
    "    is_relevant = np.in1d(recommended_items, relevant_items, assume_unique=True)\n",
    "    \n",
    "    # Cumulative sum: precision at 1, at 2, at 3 ...\n",
    "    p_at_k = is_relevant * np.cumsum(is_relevant, dtype=np.float32) / (1 + np.arange(is_relevant.shape[0]))\n",
    "    \n",
    "    map_score = np.sum(p_at_k) / np.min([relevant_items.shape[0], is_relevant.shape[0]])\n",
    "\n",
    "    return map_score\n",
    "\n",
    "def evaluate_algorithm(URM_test, recommender_object, recommendations, at=5):\n",
    "    \n",
    "    cumulative_precision = 0.0\n",
    "    cumulative_recall = 0.0\n",
    "    cumulative_MAP = 0.0\n",
    "    \n",
    "    num_eval = 0\n",
    "    \n",
    "    playlists = target_playlists['playlist_id']\n",
    "\n",
    "    for i,user_id in  enumerate(playlists):\n",
    "        \n",
    "        if i % 500 == 0:\n",
    "            print(\"User %d of %d\" % (i, len(playlists)))\n",
    "\n",
    "        relevant_items = URM_test[user_id].indices\n",
    "        \n",
    "        if len(relevant_items)>0:\n",
    "            \n",
    "            recommended_items = recommender_object.recommend(user_id, at=at)\n",
    "            num_eval+=1\n",
    "\n",
    "            cumulative_precision += precision(recommended_items, relevant_items)\n",
    "            cumulative_recall += recall(recommended_items, relevant_items)\n",
    "            cumulative_MAP += MAP(recommended_items, relevant_items)\n",
    "\n",
    "\n",
    "    cumulative_precision /= num_eval\n",
    "    cumulative_recall /= num_eval\n",
    "    cumulative_MAP /= num_eval\n",
    "    \n",
    "    print(\"Recommender performance is: Precision = {:.4f}, Recall = {:.4f}, MAP = {:.4f}\".format(\n",
    "        cumulative_precision, cumulative_recall, cumulative_MAP))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class myRecommender(object):\n",
    "    def __init__(self, URM, k=50, shrinkage=100, similarity='cosine'):\n",
    "        self.dataset = URM\n",
    "        self.k = k\n",
    "        self.shrinkage = shrinkage\n",
    "        self.similarity_name = similarity\n",
    "        if similarity == 'cosine':\n",
    "            self.distance = Cosine(shrinkage=self.shrinkage)\n",
    "        elif similarity == 'pearson':\n",
    "            self.distance = Pearson(shrinkage=self.shrinkage)\n",
    "        elif similarity == 'adj-cosine':\n",
    "            self.distance = AdjustedCosine(shrinkage=self.shrinkage)\n",
    "        else:\n",
    "            raise NotImplementedError('Distance {} not implemented'.format(similarity))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "class BasicItemKNNRecommender(object):\n",
    "    \"\"\" ItemKNN recommender with cosine similarity and no shrinkage\"\"\"\n",
    "\n",
    "    def __init__(self, URM, k=50, shrinkage=100, similarity='cosine'):\n",
    "        self.dataset = URM\n",
    "        self.k = k\n",
    "        self.shrinkage = shrinkage\n",
    "        self.similarity_name = similarity\n",
    "        if similarity == 'cosine':\n",
    "            self.distance = Cosine(shrinkage=self.shrinkage)\n",
    "        elif similarity == 'pearson':\n",
    "            self.distance = Pearson(shrinkage=self.shrinkage)\n",
    "        elif similarity == 'adj-cosine':\n",
    "            self.distance = AdjustedCosine(shrinkage=self.shrinkage)\n",
    "        else:\n",
    "            raise NotImplementedError('Distance {} not implemented'.format(similarity))\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"ItemKNN(similarity={},k={},shrinkage={})\".format(\n",
    "            self.similarity_name, self.k, self.shrinkage)\n",
    "\n",
    "    def fit(self, X):\n",
    "        item_weights = self.distance.compute(X)\n",
    "        \n",
    "        item_weights = check_matrix(item_weights, 'csr') # nearly 10 times faster\n",
    "        print(\"Converted to csr\")\n",
    "        \n",
    "        # for each column, keep only the top-k scored items\n",
    "        # THIS IS THE SLOW PART, FIND A BETTER SOLUTION        \n",
    "        values, rows, cols = [], [], []\n",
    "        nitems = self.dataset.shape[1]\n",
    "        for i in range(nitems):\n",
    "            if (i % 10000 == 0):\n",
    "                print(\"Item %d of %d\" % (i, nitems))\n",
    "                \n",
    "            this_item_weights = item_weights[i,:].toarray()[0]\n",
    "            top_k_idx = np.argsort(this_item_weights) [-self.k:]\n",
    "                       #This shit is wrong \n",
    "            values.extend(this_item_weights[top_k_idx])\n",
    "            rows.extend(np.arange(nitems)[top_k_idx])\n",
    "            cols.extend(np.ones(self.k) * i)\n",
    "            \n",
    "        self.W_sparse = sps.csc_matrix((values, (rows, cols)), shape=(nitems, nitems), dtype=np.float32)\n",
    "\n",
    "    def recommend(self, user_id, at=None, exclude_seen=True):\n",
    "        # compute the scores using the dot product\n",
    "        user_profile = self.dataset[user_id]\n",
    "        scores = user_profile.dot(self.W_sparse).toarray().ravel()\n",
    "\n",
    "        # rank items\n",
    "        ranking = scores.argsort()[::-1]\n",
    "        if exclude_seen:\n",
    "            ranking = self._filter_seen(user_id, ranking)\n",
    "            \n",
    "        export = [0,0,0,0,0]\n",
    "        for i in range(5):\n",
    "            t_id = track_to_id[ranking[i]]\n",
    "            export[i] = t_id\n",
    "            \n",
    "        return export\n",
    "    def _filter_seen(self, user_id, ranking):\n",
    "        user_profile = self.dataset[user_id]\n",
    "        seen = user_profile.indices\n",
    "        unseen_mask = np.in1d(ranking, seen, assume_unique=True, invert=True)\n",
    "        return ranking[unseen_mask]\n",
    "    \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_matrix(X, format='csc', dtype=np.float32):\n",
    "    if format == 'csc' and not isinstance(X, sps.csc_matrix):\n",
    "        return X.tocsc().astype(dtype)\n",
    "    elif format == 'csr' and not isinstance(X, sps.csr_matrix):\n",
    "        return X.tocsr().astype(dtype)\n",
    "    elif format == 'coo' and not isinstance(X, sps.coo_matrix):\n",
    "        return X.tocoo().astype(dtype)\n",
    "    elif format == 'dok' and not isinstance(X, sps.dok_matrix):\n",
    "        return X.todok().astype(dtype)\n",
    "    elif format == 'bsr' and not isinstance(X, sps.bsr_matrix):\n",
    "        return X.tobsr().astype(dtype)\n",
    "    elif format == 'dia' and not isinstance(X, sps.dia_matrix):\n",
    "        return X.todia().astype(dtype)\n",
    "    elif format == 'lil' and not isinstance(X, sps.lil_matrix):\n",
    "        return X.tolil().astype(dtype)\n",
    "    else:\n",
    "        return X.astype(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "class ISimilarity(object):\n",
    "    \"\"\"Abstract interface for the similarity metrics\"\"\"\n",
    "\n",
    "    def __init__(self, shrinkage=10):\n",
    "        self.shrinkage = shrinkage\n",
    "\n",
    "    def compute(self, X):\n",
    "        pass\n",
    "\n",
    "\n",
    "class Cosine(ISimilarity):\n",
    "    def compute(self, X):\n",
    "        # convert to csc matrix for faster column-wise operations\n",
    "        X = check_matrix(X, 'csc', dtype=np.float32)\n",
    "\n",
    "        # 1) normalize the columns in X\n",
    "        # compute the column-wise norm\n",
    "        # NOTE: this is slightly inefficient. We must copy X to compute the column norms.\n",
    "        # A faster solution is to  normalize the matrix inplace with a Cython function.\n",
    "        Xsq = X.copy()\n",
    "        Xsq.data **= 2\n",
    "        norm = np.sqrt(Xsq.sum(axis=0))\n",
    "        norm = np.asarray(norm).ravel()\n",
    "        norm += 1e-6\n",
    "        # compute the number of non-zeros in each column\n",
    "        # NOTE: this works only if X is instance of sparse.csc_matrix\n",
    "        col_nnz = np.diff(X.indptr)\n",
    "        # then normalize the values in each column\n",
    "        X.data /= np.repeat(norm, col_nnz)\n",
    "        print(\"Normalized\")\n",
    "\n",
    "        # 2) compute the cosine similarity using the dot-product\n",
    "        dist = X * X.T\n",
    "        print(\"Computed\")\n",
    "        \n",
    "        # zero out diagonal values\n",
    "        dist = dist - sps.dia_matrix((dist.diagonal()[scipy.newaxis, :], [0]), shape=dist.shape)\n",
    "        print(\"Removed diagonal\")\n",
    "        \n",
    "        # and apply the shrinkage\n",
    "        if self.shrinkage > 0:\n",
    "            dist = self.apply_shrinkage(X, dist)\n",
    "            print(\"Applied shrinkage\")    \n",
    "        \n",
    "        return dist\n",
    "\n",
    "    def apply_shrinkage(self, X, dist):\n",
    "        # create an \"indicator\" version of X (i.e. replace values in X with ones)\n",
    "        X_ind = X.copy()\n",
    "        X_ind.data = np.ones_like(X_ind.data)\n",
    "        # compute the co-rated counts\n",
    "        co_counts = X_ind * X_ind.T\n",
    "        # remove the diagonal\n",
    "        co_counts = co_counts - sps.dia_matrix((co_counts.diagonal()[scipy.newaxis, :], [0]), shape=co_counts.shape)\n",
    "        # compute the shrinkage factor as co_counts_ij / (co_counts_ij + shrinkage)\n",
    "        # then multiply dist with it\n",
    "        co_counts_shrink = co_counts.copy()\n",
    "        co_counts_shrink.data += self.shrinkage\n",
    "        co_counts.data /= co_counts_shrink.data\n",
    "        dist.data *= co_counts.data\n",
    "        return dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57560, 100000)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URM_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: Can we create a \"better\" URM by matrix factorization? \n",
    "from lightfm import LightFM\n",
    "\n",
    "model = LightFM(no_components=5)\n",
    "\n",
    "model.fit(URM_train, epochs=20)\n",
    "\n",
    "predictions = model.predict(target_playlists[0:10], target_tracks[0:1000])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized\n",
      "Computed\n",
      "Removed diagonal\n",
      "Converted to csr\n",
      "Item 0 of 100000\n",
      "Item 10000 of 100000\n",
      "Item 20000 of 100000\n",
      "Item 30000 of 100000\n",
      "Item 40000 of 100000\n",
      "Item 50000 of 100000\n",
      "Item 60000 of 100000\n",
      "Item 70000 of 100000\n",
      "Item 80000 of 100000\n",
      "Item 90000 of 100000\n",
      "Done in 683.4752779006958 seconds\n"
     ]
    }
   ],
   "source": [
    "starttime = time.time()\n",
    "rec = BasicItemKNNRecommender(URM=URM_train, shrinkage=0.0, k=50)\n",
    "rec.fit(ICM_all)\n",
    "print(\"Done in %s seconds\" %(time.time()-starttime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 31900)\n",
      "(31900,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/philipclaesson/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "num_tot_items = ICM_all.shape[0]\n",
    "\n",
    "# let's count how many items have a certain feature\n",
    "items_per_feature = (ICM_all > 0).sum(axis=0)\n",
    "\n",
    "IDF = np.array(np.log(num_tot_items / items_per_feature))[0]\n",
    "\n",
    "print(ICM_all.shape)\n",
    "print(IDF.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31900,)\n",
      "float64\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "ICM_idf = sps.csr_matrix(ICM_all, dtype=np.float64)\n",
    "# compute the number of non-zeros in each col\n",
    "# NOTE: this works only if X is instance of sparse.csc_matrix\n",
    "col_nnz = np.diff(check_matrix(ICM_idf, 'csc').indptr)\n",
    "print(col_nnz.shape)\n",
    "print(ICM_idf.shape)\n",
    "print(IDF.shape)\n",
    "# then normalize the values in each col\n",
    "ICM_idf.data *= np.repeat(IDF, col_nnz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized\n",
      "Computed\n",
      "Removed diagonal\n",
      "Converted to csr\n",
      "Item 0 of 100000\n",
      "Item 10000 of 100000\n",
      "Item 20000 of 100000\n",
      "Item 30000 of 100000\n",
      "Item 40000 of 100000\n",
      "Item 50000 of 100000\n",
      "Item 60000 of 100000\n",
      "Item 70000 of 100000\n",
      "Item 80000 of 100000\n",
      "Item 90000 of 100000\n"
     ]
    }
   ],
   "source": [
    "rec_idf = BasicItemKNNRecommender(URM=URM_train, shrinkage=0.0, k=50)\n",
    "rec_idf.fit(ICM_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 10000 playlists, 0.0018591880798339844 sec.\n",
      "1000 out of 10000 playlists, 103.81256532669067 sec.\n",
      "2000 out of 10000 playlists, 207.41671419143677 sec.\n",
      "3000 out of 10000 playlists, 309.9324781894684 sec.\n",
      "4000 out of 10000 playlists, 412.0452392101288 sec.\n",
      "5000 out of 10000 playlists, 515.3428280353546 sec.\n",
      "6000 out of 10000 playlists, 618.8582541942596 sec.\n",
      "7000 out of 10000 playlists, 721.2632591724396 sec.\n",
      "8000 out of 10000 playlists, 820.9152603149414 sec.\n",
      "9000 out of 10000 playlists, 923.4950971603394 sec.\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "zeros = np.zeros((target_playlists.size, 6), dtype = int)\n",
    "recommendations = pd.DataFrame(zeros)\n",
    "recommendations.columns = ['playlist_id', 1, 2, 3, 4, 5]\n",
    "\n",
    "counter = 0\n",
    "starttime = time.time()\n",
    "for playlist_id in target_playlists['playlist_id']:\n",
    "    \n",
    "    if counter % 1000 == 0: \n",
    "        print (\"%s out of 10000 playlists, %s sec.\" %(counter, time.time()-starttime))\n",
    "    \n",
    "    \n",
    "    playlist_id_translated = playlist_to_index[int(playlist_id)]\n",
    "    #print(rec.recommend(playlist_id_translated, at=5))\n",
    "    recommendations.iloc[counter, 1:6] = rec.recommend(playlist_id_translated, at=5)\n",
    "    recommendations.iloc[counter, 0] = playlist_id\n",
    "    counter += 1\n",
    "    \n",
    "#print(recommendations)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 0 of 10000\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index (10024884) out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-150-b5367490e339>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate_algorithm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mURM_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-149-62b55034a358>\u001b[0m in \u001b[0;36mevaluate_algorithm\u001b[0;34m(URM_test, recommender_object, at)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelevant_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mrecommended_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecommender_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecommend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0mnum_eval\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-125-d8617ea2b388>\u001b[0m in \u001b[0;36mrecommend\u001b[0;34m(self, user_id, at, exclude_seen)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecommend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude_seen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# compute the scores using the dot product\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0muser_profile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser_profile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_sparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/sparse/csr.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0;31m# [i, 1:2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_row_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m             \u001b[0;31m# [i, [1, 2]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0missequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/sparse/csr.py\u001b[0m in \u001b[0;36m_get_row_slice\u001b[0;34m(self, i, cslice)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'index (%d) out of range'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcslice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index (10024884) out of range"
     ]
    }
   ],
   "source": [
    "evaluate_algorithm(URM_test, rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of       playlist_id        1        2        3        4        5\n",
      "0        10024884  1637241  1432851  3789197   820484   435345\n",
      "1        10624787  2969077  3719846  1629279  1980691   680692\n",
      "2         4891851  2089117   301240  2724257  1371741   193077\n",
      "3         4267369  2950102  1838583  1820820  1461310  3276967\n",
      "4           65078   949178  1492640  3276761   631238  2863566\n",
      "5        10637124  2340644  3846549  2582934   273502  3032626\n",
      "6         3223162  2967703  3610791  1254269   681739  1526301\n",
      "7         7541503   956454  1480755  4591425  1825510  1825990\n",
      "8         6189367  1675280     8795  1510163  1729189  3205586\n",
      "9         8459943  2222883   802763  2214075  2752335  1334909\n",
      "10       10138804  1155458  2935861  3866159  1887656  2137341\n",
      "11       10562075  4420433  3299694  1308886  1210562  3624009\n",
      "12       10184821  1056611  2127102   377629  3781394  1868817\n",
      "13        4189678  2664733   362133  1402667  2664942  2215412\n",
      "14        6299524   195778  1344229  3302962  3511462  1527961\n",
      "15        8515028  1440124  3375738  1767226   536085  3711077\n",
      "16       10631638  2899063  2842248   360800  3670757  1831605\n",
      "17       10947423  3191588  2330141  3349911   611428  2274205\n",
      "18       11295404   830634   219919  1605470  1797663  1669793\n",
      "19        3884714  3557796  3362015   369033  1201182  2491418\n",
      "20       10680851   826418  1563133  2785283  2676381  1030713\n",
      "21        3228268  2958044  1639903   425244  3554713  3085539\n",
      "22        7850055  2830527  3550406  2758872  3019845  3286648\n",
      "23       10864017  1804337  2983185  2522691  2575762   307738\n",
      "24        5660760  1325599  2856374  2918163  2937064   202544\n",
      "25        4157419  2807557  3079025  3796145  2293484  3534170\n",
      "26        3304833  1432964  1280489   673880  1130644  2929285\n",
      "27        1911645   644831  1498469  2798810  3075374   911131\n",
      "28        4902536  3581227  1216683   193133    80619  3794784\n",
      "29        1140304  2872197  3837471  2977159  3013763  2127241\n",
      "...           ...      ...      ...      ...      ...      ...\n",
      "9970     11381473   264241  2041519  2843676   679604   520226\n",
      "9971      3520121  2366797  2561312  1034094  2301705    42671\n",
      "9972      6612439  3392573  3505126  1709479    87352  1156134\n",
      "9973      6218231  3298612   503063   133036  2637827  2334485\n",
      "9974      8344678  1352567   683239  3779363  3030934  2339622\n",
      "9975      7470841  1595157  3792998    64209  1758146    77100\n",
      "9976      6423094  1439363  2331857  2435862  1909662  3203913\n",
      "9977      8139437  2622979  1341708  3501999  1672588   611370\n",
      "9978      8227203   798900  2955603   683975  2574235  1608143\n",
      "9979      5903507  3469795  1850609  2333066  3747916  2331038\n",
      "9980      3778920   573494   254401  3737793  2621488  1558791\n",
      "9981      1061175  1700970  1423194   319731   676985  2674387\n",
      "9982      8572406  3885598   351102  2550734  2498769  3532585\n",
      "9983     10413491  1531164  3890124  3087297  1915451  2052975\n",
      "9984      8868869  3440842   279683   704737  1096151  3199853\n",
      "9985      8202309   153171   166974   879552  2163301  1303340\n",
      "9986      7784396   621684  2160644  2542909  2828710  2727320\n",
      "9987      4622927  2841460  3305678  2279185  1686177  3438028\n",
      "9988     11542825   813943  2670309  1090144   251931  1935713\n",
      "9989      7138440  2822285  2248261   849916  2008442  2988391\n",
      "9990      5146771  1104131  1775890  1867423   568987   301360\n",
      "9991      4506918  2698883  3225767  3169143   104517   416162\n",
      "9992     10337087  3588711  1085651  1145938  1791685   860987\n",
      "9993      5608217  2146828  1340455  1823023  2805023   616811\n",
      "9994      7697108  3343909  3750086  1839142  3102375  1736577\n",
      "9995     11616286  4585032   809970   727234  1711595  4891510\n",
      "9996        53201  2895090  1475613  2940576  1278274  2208245\n",
      "9997     11369546  1134195   878297  2120528  1626372  2354563\n",
      "9998      7939535   143443  3749464  2933793   126113  1795800\n",
      "9999       297021  3841976  1735331  3611454  2280075  3703942\n",
      "\n",
      "[10000 rows x 6 columns]>\n"
     ]
    }
   ],
   "source": [
    "def save_to_file():\n",
    "    #Saves the recommendations dataframe to the .csv-file. \n",
    "    np.savetxt(\"output/recommendations_more_content.csv\",recommendations, fmt = '%s,%s %s %s %s %s', header = \"playlist_id,track_ids\", newline = \"\\n\")\n",
    "    \n",
    "    \n",
    "def test():\n",
    "    #Do something\n",
    "    print(\"Result: \")\n",
    "    pass\n",
    "\n",
    "\n",
    "save_to_file()\n",
    "print(recommendations.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
